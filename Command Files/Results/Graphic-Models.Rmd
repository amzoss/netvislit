---
title: "Models for Combined NetVisLit Data"
author: "Angela Zoss"
date: "January 17, 2018"
output: github_document
---

Notes:

These command files should contain commands that open up your analysis data files, and then use those data to generate the output upon which your results are based.

Every command that generates any of your results should be preceded by a comyt that states which result the command generates.  A few Hypothetical examples illustrate what these comments might look like:

* The following command generates the first column of Table 6.

The command files for your analysis phase should not contain any commands that generate new variables or process your data in any way.  All the procedures required to prepare your data for analysis should be executed by the command files you wrote for the processing phase.

It is often convenient to write all the commands for the analysis phase in a single command file. However, if the nature of your project or the structure of your data are such that you think it would make sense to divide the code that generates the results into two or more command files, you should feel free to do so.  No matter how you organize your analysis command files, your Read Me file will include an explanation of how to use them to reproduce your results.

Save the command files you write for the analysis phase in the Command Files folder.

```{r setup}
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
```


## Detach previous packages

```{r}

detachAllPackages <- function() {

  basic.packages <- c("package:stats","package:graphics","package:grDevices","package:utils","package:datasets","package:methods","package:base")

  package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]

  package.list <- setdiff(package.list,basic.packages)

  if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)

}

detachAllPackages()

```

## Load packages

```{r, message=FALSE}

require(tidyverse)
library(stringr)
#require(igraph)
library(ggraph)
library(tidygraph)

# mixed modeling

library(nlme)
library(lme4)
#library(car)
library(lmerTest)
#library(lsmeans)
library(emmeans)
library(multcompView)

require(lattice)
source(system.file("utils", "allFit.R", package="lme4"))

# negative binomial

require(foreign)
require(MASS)

# mixed effects logistic

require(GGally)
require(reshape2)
require(compiler)
require(parallel)
require(boot)

# output

#library(officer)
#library(rvg)
#library(devEMF)

```

## Environmental Variables

```{r}

originalDataDir <- "../../Original Data"
analysisDataDir <- "../../Analysis Data"

generatedDataDir <- file.path(originalDataDir, "Generated data")

figureDir <- "../../Documents/"

```

## Loading analysis data files

```{r, message=FALSE}

orig.graphics <- read_csv(file.path(analysisDataDir, "Graphics.csv"))

layoutfac <- read_csv(file.path(analysisDataDir, "LayoutFac.csv"))

```


## Slight processing for analysis

```{r}

graphics <- set_tidy_names(orig.graphics, syntactic=TRUE)

graphics$ClustConf <- factor(graphics$ClustConf,
                             levels = c("Very confident (76-100%)", 
                                        "Somewhat confident (51-75%)", 
                                        "Somewhat doubtful (26-50%)", 
                                        "Very doubtful (0-25%)"),
                             ordered = TRUE)

graphics$Dataset <- factor(graphics$Dataset, ordered = TRUE)

#Make control the reference group
#TO DO: decide on reference group for task??

graphics <- graphics %>% mutate(ConditionPhrasing = case_when(
  Condition == "Ctrl" ~ "1-Technical",
  Condition == "Phr" ~ "2-Informal",
  Condition == "Col" ~ "1-Technical",
  Condition == "Siz" ~ "1-Technical"
)
)

graphics <- graphics %>% mutate(ConditionGraphics = case_when(
  Condition == "Ctrl" ~ "1-Default",
  Condition == "Phr" ~ "1-Default",
  Condition == "Col" ~ "2-Color",
  Condition == "Siz" ~ "3-Size"
)
)

graphics <- graphics %>% mutate(ConditionColor = case_when(
  Condition == "Col" ~ "1-Color",
  Condition == "Phr" ~ "2-Other",
  Condition == "Ctrl" ~ "2-Other",
  Condition == "Siz" ~ "2-Other"
)
)


graphics <- graphics %>% mutate(Condition1 = factor(
  case_when(
  Condition == "Ctrl" ~ 0,
  Condition == "Phr" ~ 1,
  Condition == "Col" ~ 2,
  Condition == "Siz" ~ 3)
  )
)

graphics$Condition <- factor(graphics$Condition)

graphics$Condition <- relevel(graphics$Condition, ref = "Ctrl")

graphics <- graphics %>% mutate(Ctrl_dummy = 
                                  case_when(
                                    Condition == "Ctrl" ~ 1,
                                    Condition != "Ctrl" ~ 2)
                                )

graphics$ClustConf <- factor(graphics$ClustConf, levels=c("Very doubtful (0-25%)","Somewhat doubtful (26-50%)","Somewhat confident (51-75%)","Very confident (76-100%)"))

graphics$Demo.lang <- factor(graphics$Demo.lang)

graphics$Demo.educ <- factor(graphics$Demo.educ, 
                             levels = c("High School diploma",
                                        "Bachelor’s degree",
                                        "Master’s degree",
                                        "Professional degree",
                                        "Doctorate degree",
                                        "Other"),
                             ordered = TRUE)

freq4 <- c("None", "A little", "Some", "A lot", "Skipped")

graphics$Demo.expdataanal <- factor(graphics$Demo.expdataanal,
                                    levels = c(freq4),
                                    ordered = TRUE)

graphics$Demo.expdatavis <- factor(graphics$Demo.expdatavis,
                                    levels = c(freq4),
                                    ordered = TRUE)

graphics$Demo.expreadnetvis <- factor(graphics$Demo.expreadnetvis,
                                    levels = c(freq4),
                                    ordered = TRUE)

graphics <- graphics %>% mutate(Demo.expreadnetvis.alot = ifelse(Demo.expreadnetvis == "A lot",1,0))

graphics$Demo.expreadnetvis.alot <- factor(graphics$Demo.expreadnetvis.alot)

graphics$Demo.expcreatenetvis <- factor(graphics$Demo.expcreatenetvis,
                                    levels = c(freq4),
                                    ordered = TRUE)

graphics <- graphics %>% mutate(Demo.expcreatenetvis.alot = ifelse(Demo.expcreatenetvis == "A lot",1,0))

graphics$Demo.expcreatenetvis.alot <- factor(graphics$Demo.expcreatenetvis.alot)


graphics <- graphics %>% mutate(Stats.OperatingSystemCombined = case_when(
  str_detect(Stats.OperatingSystem, "Android") ~ "Android",
  str_detect(Stats.OperatingSystem, "Windows") ~ "Windows",
  str_detect(Stats.OperatingSystem, "CrOS") ~ "CrOS",
  str_detect(Stats.OperatingSystem, "Linux") | str_detect(Stats.OperatingSystem, "Ubuntu") ~ "Linux/Ubuntu",
  TRUE ~ Stats.OperatingSystem)
)

graphics <- graphics %>% mutate(Stats.OperatingSystemCombined2 = case_when(
  str_detect(Stats.OperatingSystemCombined, "Android") | str_detect(Stats.OperatingSystemCombined, "iPhone") ~ "Android/iPhone",
  TRUE ~ Stats.OperatingSystemCombined)
)

graphics <- graphics %>% mutate(Stats.OperatingSystemCombined3 = case_when(
  str_detect(Stats.OperatingSystemCombined2, "Macintosh") | str_detect(Stats.OperatingSystemCombined2, "Windows") ~ Stats.OperatingSystemCombined2,
  TRUE ~ "Other")
)

graphics <- graphics %>% mutate(Stats.OperatingSystemCombined4 = case_when(
  str_detect(Stats.OperatingSystem, "Macintosh") | str_detect(Stats.OperatingSystem, "Windows") ~ "Mac/Windows",
  TRUE ~ "Other")
)

graphics <- graphics %>% mutate(Stats.OperatingSystemCombined5 = case_when(
  str_detect(Stats.OperatingSystem, "Macintosh") | str_detect(Stats.OperatingSystem, "Windows") | str_detect(Stats.OperatingSystem, "CrOS") ~ "Mac/Windows/CrOS",
  TRUE ~ "Other")
)

graphics <- graphics %>% mutate(Stats.OperatingSystemWindows = case_when(
  str_detect(Stats.OperatingSystem, "Windows") ~ "Windows",
  TRUE ~ "Other")
)

graphics <- graphics %>% mutate(Stats.OperatingSystemMacintosh = case_when(
  str_detect(Stats.OperatingSystem, "Windows") ~ "Macintosh",
  TRUE ~ "Other")
)

graphics <- graphics %>% mutate(Stats.OperatingSystemAndroid = case_when(
  str_detect(Stats.OperatingSystem, "Windows") ~ "Android",
  TRUE ~ "Other")
)

graphics <- graphics %>% mutate(Stats.OperatingSystemiPhone = case_when(
  str_detect(Stats.OperatingSystem, "Windows") ~ "iPhone",
  TRUE ~ "Other")
)

graphics <- graphics %>%  mutate(Stats.OperatingSystemNumClust = case_when(
  str_detect(Stats.OperatingSystem, "Android 6.0.1") ~ "1-HighSig", 
  str_detect(Stats.OperatingSystem, "CrOS x86_64 9592.96.0") ~ "1-HighSig", 
  str_detect(Stats.OperatingSystem, "Linux x86_64") ~ "1-HighSig", 
  str_detect(Stats.OperatingSystem, "Ubuntu") ~ "1-HighSig", 
  str_detect(Stats.OperatingSystem, "Windows NT 10.0") ~ "1-HighSig",
  str_detect(Stats.OperatingSystem, "Windows NT 5.1") ~ "1-HighSig", 
  str_detect(Stats.OperatingSystem, "Windows NT 6.0") ~ "1-HighSig", 
  str_detect(Stats.OperatingSystem, "Windows NT 6.1") ~ "1-HighSig",
  TRUE ~ "Other"))

graphics <- graphics %>% mutate(Demo.acfieldGrouped = case_when(
  Demo.acfield %in% c("Anthropology","Arts","Classics","History","Languages","Literature","Philosophy","Religion") ~ "Humanities",
  Demo.acfield %in% c("Archaeology","Communication studies","Cultural and ethnic studies","Economics","Geography","Information science","Linguistics","Political science","Psychology","Sociology") ~ "Social sciences",
  Demo.acfield %in% c("Biology","Chemistry","Earth sciences","Physics","Space sciences") ~ "Life sciences",
  Demo.acfield %in% c("Mathematics","Computer sciences","Logic","Statistics","Systems science") ~ "Formal sciences",
  Demo.acfield %in% c("Architecture and design","Business","Divinity","Education","Engineering","Human physical performance and recreation","Journalism, media studies and communication","Law","Library and museum studies","Medicine","Military sciences","Public administration") ~ "Professional",
  TRUE ~ Demo.acfield
))

graphics <- graphics %>% mutate(Demo.acfieldGrouped2 = case_when(
  Demo.acfield %in% c("Architecture and design", "Arts", "Business","Earth sciences","Information science","Languages","Library and museum studies","Other","Political science","Psychology") ~ "SignificantGroup",
  TRUE ~ "ZZ-Etc."
))

graphics <- graphics %>% mutate(Demo.acfieldGrouped3 = case_when(
  Demo.acfield %in% c("Business", "Arts", "Computer sciences", "Economics", "Information science", "Law", "Linguistics", "Medicine", "Other", "Political science", "Skipped", "Sociology") ~ "SignificantGroup",
  TRUE ~ "ZZ-Etc."
))

graphics <- graphics %>% mutate(Overestimated = case_when(
  Underestimated == "over" ~ "1-Overestimated",
  Underestimated %in% c("correct","under") ~ "2-CorrectOrUnder"
))

```


```{r}

# separate datasets for each Task

graphics_avgdeg <- graphics %>% filter(Task == "AvgDeg")

graphics_bc <- graphics %>% filter(Task == "BC")

graphics_clickhighdeg <- graphics %>% filter(Task == "ClickHighDeg")

graphics_lgclust <- graphics %>% filter(Task == "LargeClust1")

graphics_numclust <- graphics %>% filter(Task == "NumClust")

graphics_numhighdeg <- graphics %>% filter(Task == "NumHighDegree")

graphics_numlinks <- graphics %>% filter(Task == "NumLinks")

graphics_numnodes <- graphics %>% filter(Task == "NumNodes")


```

```{r}

# Setting up colors, etc., for lsmeans plots

sig.level.names <- c("p < .0001","p < .001","p < .01","p < .05","NS")
sig.colors <- c("gray20", "gray35", "gray50", "gray65", "white")
names(sig.colors) <- sig.level.names


```

## Mixed Models

### Average Degree

#### nlme

```{r, cache=TRUE}

# https://iucat.iu.edu/catalog/14518998, chapters 3 and 5
# data at http://www-personal.umich.edu/~bwest/almmussp.html

# testing models, no nesting/grouping

# Repeated measures, tasks and datasets (crossed)

# starting with older package (nlme), with function lme()

# R by default treats the lowest category (alphabetically or numerically) of a
# categorical fixed factor as the reference category in a model

# We don't really have reference categories for the repeated measures factors, 
# though, so I guess it doesn't matter?  Maybe want to exclude training dataset

# Note about syntax; can use either ":" or "*" for interaction, but using "*" automatically adds
# the main effects of each factor into the model, too, instead of just the interaction

graph.avgdeg.lme <- lme(LogError ~ Dataset, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg)

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)


# Dataset is not significant for AvgDeg; try Condition

graph.avgdeg.lme <- lme(LogError ~ Condition, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg)

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# Condition is not significant; try ConditionPhrasing

graph.avgdeg.lme <- lme(LogError ~ ConditionPhrasing, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg)

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# ConditionPhrasing is not significant; try ConditionGraphics

graph.avgdeg.lme <- lme(LogError ~ ConditionGraphics, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg)

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# ConditionGraphics is not significant; try TaskOrder

graph.avgdeg.lme <- lme(LogError ~ TaskOrder, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg)

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# TaskOrder is not significant; try DatasetOrder

graph.avgdeg.lme <- lme(LogError ~ DatasetOrder, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg)

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# DatasetOrder is not significant; try DatasetDuration

graph.avgdeg.lme <- lme(LogError ~ DatasetDuration, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg %>% filter(!(is.na(DatasetDuration))))

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# DatasetDuration is not significant; try Stats.Q_TotalDuration

graph.avgdeg.lme <- lme(LogError ~ Stats.Q_TotalDuration, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg)

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# Stats.Q_TotalDuration is not significant; try Stats.OperatingSystem

graph.avgdeg.lme <- lme(LogError ~ Stats.OperatingSystem, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg)

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# Stats.OperatingSystem is not significant; try StatsNumPixels

graph.avgdeg.lme <- lme(LogError ~ StatsNumPixels, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg)

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# StatsNumPixels is not significant; try Demo.age

graph.avgdeg.lme <- lme(LogError ~ Demo.age, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg %>% filter(!(is.na(Demo.age))))

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# Demo.age is not significant; try Demo.gender

graph.avgdeg.lme <- lme(LogError ~ Demo.gender, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg %>% filter(!(is.na(Demo.gender))))

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# Demo.gender is not significant; try Demo.lang

graph.avgdeg.lme <- lme(LogError ~ Demo.lang, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg %>% filter(!(is.na(Demo.lang))))

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# Demo.lang is not significant; try Demo.educ

graph.avgdeg.lme <- lme(LogError ~ Demo.educ, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg %>% filter(!(is.na(Demo.educ))))

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# Demo.educ is not significant; try Demo.acfield

graph.avgdeg.lme <- lme(LogError ~ Demo.acfield, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg %>% filter(!(is.na(Demo.acfield))))

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# Demo.acfield is not significant; try Demo.dailytech_Computer

graph.avgdeg.lme <- lme(LogError ~ Demo.dailytech_Computer, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg %>% filter(!(is.na(Demo.dailytech_Computer))))

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# Demo.dailytech_Computer is not significant; try Demo.dailytech_Tablet

graph.avgdeg.lme <- lme(LogError ~ Demo.dailytech_Tablet, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg %>% filter(!(is.na(Demo.dailytech_Tablet))))

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# Demo.dailytech_Tablet is not significant; try Demo.dailytech_SmartPhone

graph.avgdeg.lme.SP <- lme(LogError ~ Demo.dailytech_SmartPhone, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg %>% filter(!(is.na(Demo.dailytech_SmartPhone))))

# TO DO : figure out if SmartPhone should be a factor

summary(graph.avgdeg.lme.SP)

anova(graph.avgdeg.lme.SP)

## Demo.dailytech_SmartPhone *is* significant

ggplot(graphics_avgdeg) +
  geom_point(aes(Demo.dailytech_SmartPhone, LogError)) +
  geom_smooth(aes(Demo.dailytech_SmartPhone, LogError), method="lm")

# try Demo.weeklygaming

graph.avgdeg.lme <- lme(LogError ~ Demo.weeklygaming, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg %>% filter(!(is.na(Demo.weeklygaming))))

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# Demo.weeklygaming not significant; try Demo.expdataanal

graph.avgdeg.lme <- lme(LogError ~ Demo.expdataanal, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg %>% filter(!(is.na(Demo.expdataanal))))

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# Demo.expdataanal not significant; try Demo.expdatavis

graph.avgdeg.lme <- lme(LogError ~ Demo.expdatavis, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg %>% filter(!(is.na(Demo.expdatavis))))

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# Demo.expdatavis not significant; try Demo.expreadnetvis

graph.avgdeg.lme.RNV <- lme(LogError ~ Demo.expreadnetvis, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg %>% filter(!(is.na(Demo.expreadnetvis))))

summary(graph.avgdeg.lme.RNV)

anova(graph.avgdeg.lme.RNV)

# Demo.expreadnetvis barely significant (p=0.0494); try just the experts (only 1, actually)

graph.avgdeg.lme.RNVAL <- lme(LogError ~ Demo.expreadnetvis.alot, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg %>% filter(!(is.na(Demo.expreadnetvis.alot))))

summary(graph.avgdeg.lme.RNVAL)

anova(graph.avgdeg.lme.RNVAL)

# better, but still barely significant; p = 0.0106

# try Demo.expcreatenetvis

graph.avgdeg.lme <- lme(LogError ~ Demo.expcreatenetvis, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg %>% filter(!(is.na(Demo.expcreatenetvis))))

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# Demo.expcreatenetvis not significant; try AvgDeg

graph.avgdeg.lme <- lme(LogError ~ AvgDeg, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg)

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# AvgDeg not significant; try Density

graph.avgdeg.lme <- lme(LogError ~ Density, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg)

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# Density not significant; try LargeClust1

graph.avgdeg.lme <- lme(LogError ~ LargeClust1, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg)

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# LargeClust1 not significant; try Modularity

graph.avgdeg.lme <- lme(LogError ~ Modularity, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg)

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# Modularity not significant; try NumClust

graph.avgdeg.lme <- lme(LogError ~ NumClust, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg)

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# NumClust not significant; try NumHighDegree

graph.avgdeg.lme <- lme(LogError ~ NumHighDegree, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg)

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# NumHighDegree not significant; try NumLinks

graph.avgdeg.lme <- lme(LogError ~ NumLinks, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg)

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# NumLinks not significant; try NumNodes

graph.avgdeg.lme <- lme(LogError ~ NumNodes, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg)

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# NumNodes not significant; try NumNodesClust1

graph.avgdeg.lme <- lme(LogError ~ NumNodesClust1, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg)

summary(graph.avgdeg.lme)

anova(graph.avgdeg.lme)

# Final; try both significant factors

graph.avgdeg.lme.SP.RNVAL <- lme(LogError ~ Demo.dailytech_SmartPhone + Demo.expreadnetvis.alot, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg %>% filter(!(is.na(Demo.dailytech_SmartPhone))) %>% filter(!(is.na(Demo.expreadnetvis.alot))))

summary(graph.avgdeg.lme.SP.RNVAL)

anova(graph.avgdeg.lme.SP.RNVAL)

# Better than just one predictor?

anova(graph.avgdeg.lme.SP.RNVAL, graph.avgdeg.lme.SP)

# no significant difference

graph.avgdeg.lme.RNVAL <- lme(LogError ~ Demo.expreadnetvis.alot, random = ~ 1 | Demo.ResponseID, method="REML", data=graphics_avgdeg %>% filter(!(is.na(Demo.dailytech_SmartPhone))) %>% filter(!(is.na(Demo.expreadnetvis.alot))))

anova(graph.avgdeg.lme.SP.RNVAL, graph.avgdeg.lme.RNVAL)

# no significant difference; guess we can use both predictors? or maybe should just use stronger
# predictor, SmartPhone?


random.effects(graph.avgdeg.lme.SP)

# do we really need random effects?  test model without random effects using gls

graph.avgdeg.gls <- gls(LogError ~ Demo.dailytech_SmartPhone, data=graphics_avgdeg %>% filter(!(is.na(Demo.dailytech_SmartPhone))))

anova(graph.avgdeg.lme.SP, graph.avgdeg.gls)

# result of anova is significant (p=0.0019), indicating that there is a significant difference when
# you remove random effects, so should leave them in

```

```{r, eval=FALSE}

# NOTE: nesting is not appropriate, but syntax for tests might be useful in future

# model with nesting; takes *forever* but does finish
# can nest when I recode Condition as 0, 1, 2, 3 (Condition1), 
# but if I just list Ctrl as the ref (Condition), won't converge

model.lme.update.nest <- update(model.lme, random = ~ Condition1 | Demo.ResponseID)

summary(model.lme.update.nest)

anova(model.lme.update.nest)

# might want to check whether nesting makes a difference, but can't run anova because 
# "the test statistic has a null distribution that is a mixture of X12 and X22 distributions
# with equal weights of 0.5, so the anova() function cannot be used for the p-value." (p.220)

# Check summary of each model for -2 REML log-likelihood values 

# "logLik" value for unnested: -14415.3
# "logLik" value for nested: -14441
# -2 REML logLik is just -2 * the logLik value

# test statistics = unnested - nested
test.stat <- abs((-2*-14415.3) - (-2*-14441)) # ~51.4

# note: when test.stat was negative, p-value was not significant, but highly significant when
# positive
p.val <- 0.5*(1-pchisq(test.stat,1)) + 0.5*(1-pchisq(test.stat,2))

# p-value is < 0.001, so nesting is significantly different


```

```{r, cache=TRUE}

# adding weights to have a separate residual variance for each treatment group
# TO DO: are these the only weights I need to consider???  check that these weights make sense

graph.avgdeg.weight <- lme(LogError ~ Demo.dailytech_SmartPhone, 
                 random = ~ 1 | Demo.ResponseID, 
                 method="REML", 
                 data=graphics_avgdeg %>% filter(!(is.na(Demo.dailytech_SmartPhone))),
                 weights = varIdent(form = ~1 | Condition))

summary(graph.avgdeg.weight)

# Parameter estimates are:
#    Ctrl      Siz      Phr      Col 
#1.000000 1.486356 1.409153 1.436532 

anova(graph.avgdeg.lme.SP, graph.avgdeg.weight)

# result is significant (p<.0001), which suggests that we should retain the second model with the 
# weights,  otherwise known as the "heterogeneous variances model" (p. 94)


```

```{r, cache=TRUE}

graph.avgdeg.weight.pooled <- lme(LogError ~ Demo.dailytech_SmartPhone, 
                 random = ~ 1 | Demo.ResponseID, 
                 method="REML", 
                 data=graphics_avgdeg %>% filter(!(is.na(Demo.dailytech_SmartPhone))),
                 weights = varIdent(form = ~1 | Ctrl_dummy))

anova(graph.avgdeg.weight, graph.avgdeg.weight.pooled)

# test is not significant, so should not keep the weights pooled? p. 95 not clear, since in 
# example difference is not significant but pooled model is retained anyway

summary(graph.avgdeg.weight)
anova(graph.avgdeg.weight)

```

```{r, cache=TRUE}

# TO DO: need to conduct Type I F-test (section 5.7)? to try to remove nonsignficant fixed effects?
# note p. 223 explains that large F-statistics can indicate significance, even when you don't compute
# p-values

# another way to test if each additional item is significant:
# create two models, one with and one without the fixed effect
# use ML estimation (REML = F for lmer()) for each
# use anova() to compare the models (see 4.4.3.2)

# On p. 238, talks about needing to be careful about interpretation because an interaction is
# also significant; can investigate "estimated marginal means" of the combinations of levels in the
# interaction (needs to be pairwise for the interaction?)

# On p. 133, "Post-hoc comparisons can also be computed in R with 
# some additional programming (Faraway, 2005)"

# From Faraway, 2015, p. 20:
# https://search.library.duke.edu/search?id=DUKE008022150

# "We can extract the regression quantities we need from the model object. Commonly used are residuals(),
# fitted(), df.residual() which gives the degrees of freedon, deviance() which gives the RSS and
# coef() which gives the ^Beta."

modsum <- summary(graph.avgdeg.weight)
names(modsum)
modsum$logLik * -2

modsum$sigma # 0.711... what is sigma, exactly?

```


```{r, cache=TRUE}

# Residuals plot
plot(graph.avgdeg.weight)

# Residuals vs. SmartPhone, scatterplot
plot(graph.avgdeg.weight, Demo.dailytech_SmartPhone ~ resid(.))

# Predicted vs. SmartPhone
plot(graph.avgdeg.weight, Demo.dailytech_SmartPhone ~ fitted(.))


# Predicted vs. Actual LogError
plot(graph.avgdeg.weight, LogError ~ fitted(.), abline = c(0,1))

qqnorm(graph.avgdeg.weight, abline = c(0,1))

qqnorm(graph.avgdeg.weight, ~ resid(., type = "p") | Demo.dailytech_SmartPhone, abline = c(0,1))

qqnorm(graph.avgdeg.weight, ~ resid(., type = "p") | Condition, abline = c(0,1))

qqnorm(graph.avgdeg.weight, ~ranef(.))


```

#### lme4

```{r, cache=TRUE}

# Trying dataset first

graph.avgdeg.lmer <- lmer(LogError ~ Dataset + (1|Demo.ResponseID), data = graphics_avgdeg, REML = T)

lmsum <- summary(graph.avgdeg.lmer)
lmsum
#names(lmsum)

anova(graph.avgdeg.lmer)

# Dataset not significant; trying SmortPhone

graph.avgdeg.lmer.SP <- lmer(LogError ~ Demo.dailytech_SmartPhone + (1|Demo.ResponseID), data=graphics_avgdeg %>% filter(!(is.na(Demo.dailytech_SmartPhone))), REML = T)

summary(graph.avgdeg.lmer.SP)

anova(graph.avgdeg.lmer.SP)

# Smartphone is significant; trying readnetvisalot

graph.avgdeg.lmer.RNVAL <- lmer(LogError ~ Demo.expreadnetvis.alot + (1|Demo.ResponseID), data=graphics_avgdeg %>% filter(!(is.na(Demo.expreadnetvis.alot))), REML = T)

summary(graph.avgdeg.lmer.RNVAL)

anova(graph.avgdeg.lmer.RNVAL)

# slightly significant; trying both

graph.avgdeg.lmer.SP.RNVAL <- lmer(LogError ~ Demo.dailytech_SmartPhone + Demo.expreadnetvis.alot + (1|Demo.ResponseID), data=graphics_avgdeg %>% filter(!(is.na(Demo.dailytech_SmartPhone))) %>% filter(!(is.na(Demo.expreadnetvis.alot))), REML = T)

summary(graph.avgdeg.lmer.SP.RNVAL)

anova(graph.avgdeg.lmer.SP.RNVAL)

```

```{r, eval=FALSE}

# Try adding condition as a nesting variable for random participant effects; ultimately not appropriate to do so

#model.fit.lmer.nest <- lmer(LogError ~ Dataset + Task + Task:Dataset + (Condition1|Demo.ResponseID), data = graphics_avgdeg, REML = T)

# error: 
# unable to evaluate scaled gradientModel failed to converge: degenerate  Hessian with 1 negative eigenvalues 

model.fit.lmer.nest <- lmer(LogError ~ Dataset + Task + Task:Dataset + (Condition|Demo.ResponseID), data = graphics_avgdeg, REML = T)

# warning 
# Model is nearly unidentifiable: large eigenvalue ratio - Rescale variables?

nestsum <- summary(model.fit.lmer.nest)
nestsum

# want to compare unnested and nested; not supposed to do anova, so should
# create test statistic by subtracting -2 REML log-likelihood values from
# each model

# "logLik" value for unnested: -14441.77
# "logLik" value for nested: -14440.5
# -2 REML logLik is just -2 * the logLik value

# test statistics = unnested - nested
test.stat <- (-2*as.numeric(lmsum$logLik)) - (-2*as.numeric(nestsum$logLik)) # ~2.53


p.val <- 0.5*(1-pchisq(test.stat,1)) + 0.5*(1-pchisq(test.stat,2))

# p-value ~ 0.1969, so nesting is not significantly different

```

```{r, cache=TRUE}

rand(graph.avgdeg.lmer.SP)

# result shows that random effects of participant are significant (p=0.002)

anova(graph.avgdeg.lmer.SP)

# SmartPhone significant, < 0.01

#ranef(graph.avgdeg.lmer.SP)

# displays the random effects; not that useful

# unlike lme(), lmer() doesn't allow for heterogeneous error variance structures (the "weights")


```

```{r, eval=FALSE}

# From Faraway (2015), p. 156 - use step() to start with a complex model and 
# systematically remove each effects

graph.avgdeg.full.lmer <- lmer(LogError ~ Dataset + Condition + 
                           QuestionOrder + (1|Demo.ResponseID), 
                         data = graphics_avgdeg, REML = T)

step(graph.avgdeg.full.lmer)

# not sure this is useful

```

```{r, eval=FALSE}

# Clustered Longitudinal Data (Chapter 7)
# Data are not clustered, so can skip

#model7.1.fit <- lme(gcf ~ time + 
#                   base_gcf + cda + 
#                   age + 
#                   time:base_gcf + time:cda + 
#                   time:age, 
#                   random = list(patient = ~time, tooth = ~1), 
#                   data = veneer, 
#                   method = "REML")

clust.model.fit <- lme(LogError ~ Task + TaskOrder +
                         Dataset + DatasetOrder +
                         Task:TaskOrder + 
                         Task:Dataset + Task:DatasetOrder,
                       random = list(`Demo.ResponseID` = ~Condition),
                       data = graphics_avgdeg,
                       method = "REML")

summary(clust.model.fit)

intervals(clust.model.fit, which="fixed")

random.effects(clust.model.fit)

```

```{r}

plot(graph.avgdeg.lmer.SP)

plot(graph.avgdeg.lmer.SP, resid(., scaled=TRUE) ~ fitted(.), abline = 0)

plot(graph.avgdeg.lmer.SP, resid(.) ~ fitted(.) | Task, abline = 0)

plot(graph.avgdeg.lmer.SP, resid(., scaled=TRUE) ~ fitted(.) | Task, abline = 0)

plot(graph.avgdeg.lmer.SP, LogError ~ fitted(.), abline = c(0,1))



```

```{r}

graph.avgdeg.lmer.SP.f <- fortify(graph.avgdeg.lmer.SP)

ggplot(graph.avgdeg.lmer.SP.f, aes(.fitted,.resid)) + 
  geom_point() +
  #facet_grid(.~Sex) + 
  geom_hline(yintercept=0)

ggplot(graph.avgdeg.lmer.SP.f, aes(.fitted,LogError)) + 
  geom_point() +
  geom_abline(aes(slope = 1, intercept = 0))


```

```{r}

# TO DO: check out interpretation for these plots??

library(lattice)

prof <-  profile(graph.avgdeg.lmer.SP, optimizer="Nelder_Mead", which="beta_")

prof.CI <- confint(prof)

#CI2 <- confint(graph.avgdeg.lmer.SP, maxpts = 8)

xyplot(prof)

xyplot(prof, absVal = TRUE)

xyplot(prof, conf = c(0.95, 0.99), main = "95% and 99% profile() intervals")

# can also apply logProf() and varianceProf() to profile object

densityplot(prof)

splom(prof)

```

```{r, eval=FALSE}

# doesn't make sense for continuous predictor???

lsm.task <- lsmeansLT(model.fit.lmer, test.effs = "Task")

plot(lsm.task)

lsm.task.df <- as_data_frame(lsm.task$lsmeans.table)

lsm.task.df

lsm.task.df$Task <- factor(lsm.task.df$Task, levels=lsm.task.df %>% arrange(desc(Estimate)) %>% select(Task) %>% unlist())

lsm.task.df %>% arrange(desc(Estimate))


ggplot(lsm.task.df) +
  geom_point(aes(x=Task,y=Estimate, color=`p-value`<.01)) +
  geom_errorbar(aes(x=Task,ymax=`Upper CI`,ymin=`Lower CI`), width=.2) +
  coord_flip()

# TO DO: add a color scale so TRUE/FALSE values are always same color across all plots


```



```{r, eval=FALSE}

# doesn't make sense for continuous predictor???

difflsm.task <- difflsmeans(model.fit.lmer, test.effs = "Task")

plot(difflsm.task)

difflsm.task.df <- as_data_frame(difflsm.task$diffs.lsmeans.table)

difflsm.task.df

difflsm.task.df <- difflsm.task.df %>% mutate(Pair=rownames(.)) %>% separate(Pair, c("del","Pair"), sep=5) %>% select(-del) %>% separate(Pair, c("From", "del", "To"), sep="[ ]", remove=FALSE) %>% select(-del)

difflsm.task.df$Pair <- factor(difflsm.task.df$Pair, levels=difflsm.task.df %>% arrange(desc(Estimate)) %>% select(Pair) %>% unlist())

difflsm.task.df %>% arrange(desc(Estimate))

ggplot(difflsm.task.df) +
  geom_point(aes(x=Pair,y=Estimate, color=`p-value`<.01)) +
  geom_errorbar(aes(x=Pair,ymax=`Upper CI`,ymin=`Lower CI`), width=.5) +
  geom_hline(aes(yintercept=0)) +
  coord_flip()

ggplot(difflsm.task.df) +
  geom_tile(aes(x=To,y=From,fill=Estimate)) +
    scale_fill_distiller(type="div", palette=4)

ggplot(difflsm.task.df) +
  geom_count(aes(x=To,y=From,size=abs(Estimate),fill=Estimate, color=`p-value`<.01), shape=21) +
  scale_fill_distiller(type="div", palette=4) +
  scale_color_manual(values=c("grey90","black"))
  



```


#### Logistic regression for over/underestimation with mixed effects (lme4, glmer)

```{r, eval=FALSE}

# https://stats.idre.ucla.edu/r/dae/mixed-effects-logistic-regression/

#ggpairs(graphics_avgdeg %>% dplyr::select(Response, DatasetDuration, CorrectAnswer, AbsDifference, Stats.Q_TotalDuration, StatsNumPixels, Demo.age, Demo.dailytech_Computer, Demo.dailytech_Tablet, Demo.dailytech_SmartPhone, Demo.weeklygaming, AvgDeg, Density, LargeClust1, Modularity, NumClust, NumHighDegree, NumLinks, NumNodes, NumNodes))

```

```{r, eval=FALSE}

graphics_avgdeg_incorrect <- graphics_avgdeg %>% filter(Underestimated != "correct")

graphics_avgdeg_incorrect$Underestimated <- factor(graphics_avgdeg_incorrect$Underestimated)

graph.avgdeg.logit <- glmer(Underestimated ~ Dataset + Condition +
    (1 | Demo.ResponseID), data = graphics_avgdeg_incorrect, family = binomial, control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10)

print(graph.avgdeg.logit, corr = FALSE)

se <- sqrt(diag(vcov(graph.avgdeg.logit)))

# table of estimates with 95% CI using coefficients
(tab <- cbind(Est = fixef(graph.avgdeg.logit), LL = fixef(graph.avgdeg.logit) - 1.96 * se, UL = fixef(graph.avgdeg.logit) + 1.96 * se))

# odds ratios instead of coefficients
exp(tab)

```

```{r, eval=FALSE}

# bootstrapping, but sampling function isn't working

sampler <- function(dat, clustervar, replace = TRUE, reps = 1) {
    cid <- unique(dat[, clustervar[1]])
    ncid <- length(cid)
    recid <- sample(cid, size = ncid * reps, replace = TRUE)
    if (replace) {
        rid <- lapply(seq_along(recid), function(i) {
            cbind(NewID = i, RowID = sample(which(dat[, clustervar] == recid[i]),
                size = length(which(dat[, clustervar] == recid[i])), replace = TRUE))
        })
    } else {
        rid <- lapply(seq_along(recid), function(i) {
            cbind(NewID = i, RowID = which(dat[, clustervar] == recid[i]))
        })
    }
    dat <- as.data.frame(do.call(rbind, rid))
    dat$Replicate <- factor(cut(dat$NewID, breaks = c(1, ncid * 1:reps), include.lowest = TRUE,
        labels = FALSE))
    dat$NewID <- factor(dat$NewID)
    return(dat)
}

set.seed(20)
tmp <- sampler(graphics_avgdeg_incorrect, "Demo.ResponseID", reps = 1000)
bigdata <- cbind(tmp, graphics_avgdeg_incorrect[tmp$RowID, ])

# sampler throws an error:
# "Error in Ops.data.frame(dat[, clustervar], recid[i]) : ‘==’ only defined for equally-sized data frames"

f <- fixef(graph.avgdeg.logit)
r <- getME(graph.avgdeg.logit, "theta")

cl <- makeCluster(4)
clusterExport(cl, c("bigdata", "f", "r"))
clusterEvalQ(cl, require(lme4))

myboot <- function(i) {
    object <- try(glmer(remission ~ IL6 + CRP + CancerStage + LengthofStay +
        Experience + (1 | NewID), data = bigdata, subset = Replicate == i, family = binomial,
        nAGQ = 1, start = list(fixef = f, theta = r)), silent = TRUE)
    if (class(object) == "try-error")
        return(object)
    c(fixef(object), getME(object, "theta"))
}

start <- proc.time()
res <- parLapplyLB(cl, X = levels(bigdata$Replicate), fun = myboot)
end <- proc.time()

# shut down the cluster
stopCluster(cl)

# calculate proportion of models that successfully converged
success <- sapply(res, is.numeric)
mean(success)

# combine successful results
bigres <- do.call(cbind, res[success])

# calculate 2.5th and 97.5th percentiles for 95% CI
(ci <- t(apply(bigres, 1, quantile, probs = c(0.025, 0.975))))

# All results
finaltable <- cbind(Est = c(f, r), SE = c(se, NA), BootMean = rowMeans(bigres),
    ci)
# round and print
round(finaltable, 3)

```

```{r, eval=FALSE}

# temporary data
tmpdat <- graphics_avgdeg_incorrect %>% filter(!is.na(DatasetDuration))

jvalues <- with(graphics_avgdeg_incorrect, seq(from = min(DatasetDuration), to = max(DatasetDuration), length.out = 100))

# calculate predicted probabilities and store in a list
pp <- lapply(jvalues, function(j) {
    tmpdat$LengthofStay <- j
    predict(m, newdata = tmpdat, type = "response")
})


```

```{r, eval=FALSE}

# OLD CODE, NOT MIXED EFFECTS

graphics.est <- graphics_avgdeg %>% mutate(underest = ifelse(RawDifference<0,1,0)) 

graphics.est$underest <- factor(graphics.est$underest, levels=c(1,0), labels = c("underestimated","overestimated"))

graphics.est$Task <- factor(graphics.est$Task)

xtabs(~underest + Task, data = graphics.est)

# difference between family="binomial" and family=binomial(link='logit') ?

#log.model <- glm(underest ~ Task, family=binomial(link='logit'), data=graphics.est)

log.model <- glm(underest ~ Task, family="binomial", data=graphics.est)

summary(log.model)
# Interpretation of Estimate: compared to reference task (AvgDegree), each task changes
# the log odds of underestimation by the estimate shown; negative estimates reduce
# log odds of underestimation compared to AvgDegree

## CIs using profiled log-likelihood
confint(log.model)

## CIs using standard errors
confint.default(log.model)

## Wald test for effect of Task, which is terms 2:8 in the model
wald.test(b = coef(log.model), Sigma = vcov(log.model), Terms = 2:8)

## test two specific tasks against each other (NumHighDegree and NumNodes)
l <- cbind(0,0,0,0,0,1,0,-1)
wald.test(b = coef(log.model), Sigma = vcov(log.model), L = l)
# p = 0.015, so only marginally significant

## odds ratios only
exp(coef(log.model))

## odds ratios and 95% CI
exp(cbind(OR = coef(log.model), confint(log.model)))

# https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/ 

## testing fit

# likelihood ratio test
with(log.model, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
# p-value is 0, so model with predictor definitely fits better than the null model

# testing the quality of the variable, is this the best model we can get?

# is this a good fitting model?  check % accuracy; split data into training test, check accuracy on test

anova(log.model, test="Chisq")

pR2(log.model)

# don't know how to interpret; should be looking at McFadden as a sort of pseudo R^2?

# https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-what-are-pseudo-r-squareds/
# "If comparing two models on the same data, McFadden’s would be higher for the model with the greater likelihood."

```

#### Negative binomial model for responses

Responses are basically count data, so using a negative binomial distribution to model. Negative binomial is especially useful for over-dispersed data - data where the conditional variances exceed conditional means. 

```{r, eval=FALSE}

# https://stats.idre.ucla.edu/r/dae/negative-binomial-regression/ for non-mixed version

# Test for overdispersion

with(graphics_avgdeg, tapply(Response, Condition, function(x) {
    sprintf("M (SD) = %1.2f (%1.2f)", mean(x), sd(x))
}))

# variances in each condition are much larger than means in the conditions

```

```{r, cache=TRUE, eval=FALSE}



graph.avgdeg.nb.null <- glmer.nb(Response ~ (1|Demo.ResponseID), data=graphics_avgdeg, verbose=TRUE)



graph.avgdeg.nb <- glmer.nb(Response ~ Condition + (1|Demo.ResponseID), data=graphics_avgdeg, verbose=TRUE)

summary(graph.avgdeg.nb)

anova(graph.avgdeg.nb, graph.avgdeg.nb.null)

# model is not significantly different from null model (p=0.4081), so Condition isn't a
# significant predictor

graph.avgdeg.nb.dataset <- glmer.nb(Response ~ Dataset + (1|Demo.ResponseID), data=graphics_avgdeg, verbose=TRUE)

summary(graph.avgdeg.nb.dataset)

anova(graph.avgdeg.nb.dataset, graph.avgdeg.nb.null)

# model is significantly different from null model (p < 2.2e-16), so Dataset is a
# significant predictor

graph.avgdeg.nb <- glmer.nb(Response ~ DatasetOrder + (1|Demo.ResponseID), data=graphics_avgdeg, verbose=TRUE)

summary(graph.avgdeg.nb)

anova(graph.avgdeg.nb, graph.avgdeg.nb.null)

# model is not significantly different from null model (p = 0.2556), so DatasetOrder is not a
# significant predictor

#graph.avgdeg.nb <- glmer.nb(Response ~ DatasetDuration + (1|Demo.ResponseID), data=graphics_avgdeg, verbose=TRUE)

#summary(graph.avgdeg.nb)

#anova(graph.avgdeg.nb, graph.avgdeg.nb.null)

# error trying to run model: 
#"Error in pwrssUpdate(pp, resp, tol = tolPwrss, GQmat = GQmat, compDev = compDev, : pwrssUpdate did not converge in (maxit) iterations"

graph.avgdeg.nb.taskorder <- glmer.nb(Response ~ TaskOrder + (1|Demo.ResponseID), data=graphics_avgdeg, verbose=TRUE)

summary(graph.avgdeg.nb.taskorder)

anova(graph.avgdeg.nb.taskorder, graph.avgdeg.nb.null)

# model is significantly different from null model (p = 0.01659), so TaskOrder is a
# significant predictor

#graph.avgdeg.nb <- glmer.nb(Response ~ QuestionOrder + (1|Demo.ResponseID), data=graphics_avgdeg, verbose=TRUE)

#summary(graph.avgdeg.nb)

#anova(graph.avgdeg.nb, graph.avgdeg.nb.null)

# error trying to run model:
#"Error in pwrssUpdate(pp, resp, tol = tolPwrss, GQmat = GQmat, compDev = compDev, : (maxstephalfit) PIRLS step-halvings failed to reduce deviance in pwrssUpdate"

graph.avgdeg.nb.correct <- glmer.nb(Response ~ CorrectAnswer + (1|Demo.ResponseID), data=graphics_avgdeg, verbose=TRUE)

summary(graph.avgdeg.nb.correct)

anova(graph.avgdeg.nb.correct, graph.avgdeg.nb.null)

# model is significantly different from null model (p < 2.2e-16), so CorrectAnswer is a
# significant predictor

#graph.avgdeg.nb <- glmer.nb(Response ~ Stats.Q_TotalDuration + (1|Demo.ResponseID), data=graphics_avgdeg, verbose=TRUE)

#summary(graph.avgdeg.nb)

#anova(graph.avgdeg.nb, graph.avgdeg.nb.null)

# error trying to run model:
#"Error in pwrssUpdate(pp, resp, tol = tolPwrss, GQmat = GQmat, compDev = compDev, : pwrssUpdate did not converge in (maxit) iterations"

graph.avgdeg.nb <- glmer.nb(Response ~ Stats.OperatingSystem + (1|Demo.ResponseID), data=graphics_avgdeg, verbose=TRUE)

summary(graph.avgdeg.nb)

anova(graph.avgdeg.nb, graph.avgdeg.nb.null)

# model is not significantly different from null model (p = 0.5602), so Stats.OperatingSystems is not a
# significant predictor

#graph.avgdeg.nb <- glmer.nb(Response ~ StatsNumPixels + (1|Demo.ResponseID), data=graphics_avgdeg, verbose=TRUE)

#summary(graph.avgdeg.nb)

#anova(graph.avgdeg.nb, graph.avgdeg.nb.null)

# error trying to run model:
#"Error in pwrssUpdate(pp, resp, tol = tolPwrss, GQmat = GQmat, compDev = compDev, : Downdated VtV is not positive definite"

# TO DO: try to fix errors? try different negative binomial model syntax?

graph.avgdeg.nb <- glmer.nb(Response ~ Demo.age + (1|Demo.ResponseID), data=graphics_avgdeg %>% filter(!is.na(Demo.age)), verbose=TRUE)

summary(graph.avgdeg.nb)

graph.avgdeg.nb.null.2 <- update(graph.avgdeg.nb, . ~ . - Demo.age)

summary(graph.avgdeg.nb.null.2)

anova(graph.avgdeg.nb, graph.avgdeg.nb.null.2)

# model is not significantly different from null model (p = 0.07795), so Demo.age is not a
# significant predictor
# also, model summary says "Model failed to converge with max|grad| = 0.00119421 (tol = 0.001, component 1)"

# TO DO : keep going with predictors, try combinations of the significant ones? do some prediction to check how good model is?

graph.avgdeg.nb <- glmer.nb(Response ~ Demo.gender + (1|Demo.ResponseID), data=graphics_avgdeg %>% filter(!is.na(Demo.gender)), verbose=TRUE)

summary(graph.avgdeg.nb)

graph.avgdeg.nb.null.2 <- update(graph.avgdeg.nb, . ~ . - Demo.gender)

summary(graph.avgdeg.nb.null.2)

anova(graph.avgdeg.nb, graph.avgdeg.nb.null.2)

# model is not significantly different from null model (p = 0.7306), so Demo.gender is not a
# significant predictor

graph.avgdeg.nb <- glmer.nb(Response ~ Demo.lang + (1|Demo.ResponseID), data=graphics_avgdeg %>% filter(!is.na(Demo.lang)), verbose=TRUE)

summary(graph.avgdeg.nb)

graph.avgdeg.nb.null.2 <- update(graph.avgdeg.nb, . ~ . - Demo.lang)

summary(graph.avgdeg.nb.null.2)

anova(graph.avgdeg.nb, graph.avgdeg.nb.null.2)

# null model failed to converge
# "Model failed to converge with max|grad| = 0.0291884 (tol = 0.001, component 1)"

# model is not significantly different from null model (p = 0.1938), so Demo.lang is not a
# significant predictor

graph.avgdeg.nb <- glmer.nb(Response ~ Demo.educ + (1|Demo.ResponseID), data=graphics_avgdeg %>% filter(!is.na(Demo.educ)), verbose=TRUE)

summary(graph.avgdeg.nb)

graph.avgdeg.nb.null.2 <- update(graph.avgdeg.nb, . ~ . - Demo.educ)

summary(graph.avgdeg.nb.null.2)

anova(graph.avgdeg.nb, graph.avgdeg.nb.null.2)

# null model failed to converge

# model is not significantly different from null model (p = 0.7197), so Demo.educ is not a
# significant predictor

# takes forever, not significant
#graph.avgdeg.nb <- glmer.nb(Response ~ Demo.acfield + (1|Demo.ResponseID), data=graphics_avgdeg %>% filter(!is.na(Demo.acfield)), verbose=TRUE)

#summary(graph.avgdeg.nb)

# no categories significant

#graph.avgdeg.nb.null.2 <- update(graph.avgdeg.nb, . ~ . - Demo.acfield)

#summary(graph.avgdeg.nb.null.2)

# model failed to converge

#anova(graph.avgdeg.nb, graph.avgdeg.nb.null.2)

# not significant

# TO DO : test acfield group

graph.avgdeg.nb <- glmer.nb(Response ~ Demo.dailytech_Computer + (1|Demo.ResponseID), data=graphics_avgdeg %>% filter(!is.na(Demo.dailytech_Computer)), verbose=TRUE)

summary(graph.avgdeg.nb)

# not significant

graph.avgdeg.nb.null.2 <- update(graph.avgdeg.nb, . ~ . - Demo.dailytech_Computer)

summary(graph.avgdeg.nb.null.2)

# model failed to converge

anova(graph.avgdeg.nb, graph.avgdeg.nb.null.2)

# not significant

graph.avgdeg.nb <- glmer.nb(Response ~ Demo.dailytech_Tablet + (1|Demo.ResponseID), data=graphics_avgdeg %>% filter(!is.na(Demo.dailytech_Tablet)), verbose=TRUE)

summary(graph.avgdeg.nb)

# not significant

graph.avgdeg.nb.null.2 <- update(graph.avgdeg.nb, . ~ . - Demo.dailytech_Tablet)

summary(graph.avgdeg.nb.null.2)

anova(graph.avgdeg.nb, graph.avgdeg.nb.null.2)

# not significant

graph.avgdeg.nb.sp <- glmer.nb(Response ~ Demo.dailytech_SmartPhone + (1|Demo.ResponseID), data=graphics_avgdeg %>% filter(!is.na(Demo.dailytech_SmartPhone)), verbose=TRUE)

summary(graph.avgdeg.nb.sp)

# significant (p = 0.00253)

graph.avgdeg.nb.null.sp <- update(graph.avgdeg.nb.sp, . ~ . - Demo.dailytech_SmartPhone)

summary(graph.avgdeg.nb.null.sp)

# model failed to converge

anova(graph.avgdeg.nb.sp, graph.avgdeg.nb.null.sp)

# significant (p = 0.002548)

graph.avgdeg.nb <- glmer.nb(Response ~ Demo.weeklygaming + (1|Demo.ResponseID), data=graphics_avgdeg %>% filter(!is.na(Demo.weeklygaming)), verbose=TRUE)

summary(graph.avgdeg.nb)

# not significant

graph.avgdeg.nb.null.2 <- update(graph.avgdeg.nb, . ~ . - Demo.weeklygaming)

summary(graph.avgdeg.nb.null.2)

# model failed to converge

anova(graph.avgdeg.nb, graph.avgdeg.nb.null.2)

# not significant

graph.avgdeg.nb <- glmer.nb(Response ~ Demo.expdataanal + (1|Demo.ResponseID), data=graphics_avgdeg %>% filter(!is.na(Demo.expdataanal)), verbose=TRUE)

summary(graph.avgdeg.nb)

# not significant

graph.avgdeg.nb.null.2 <- update(graph.avgdeg.nb, . ~ . - Demo.expdataanal)

summary(graph.avgdeg.nb.null.2)

# model failed to converge

anova(graph.avgdeg.nb, graph.avgdeg.nb.null.2)

# not significant

graph.avgdeg.nb <- glmer.nb(Response ~ Demo.expdatavis + (1|Demo.ResponseID), data=graphics_avgdeg %>% filter(!is.na(Demo.expdatavis)), verbose=TRUE)

summary(graph.avgdeg.nb)

# not significant

graph.avgdeg.nb.null.2 <- update(graph.avgdeg.nb, . ~ . - Demo.expdatavis)

summary(graph.avgdeg.nb.null.2)

# model failed to converge

anova(graph.avgdeg.nb, graph.avgdeg.nb.null.2)

# not significant

graph.avgdeg.nb <- glmer.nb(Response ~ Demo.expreadnetvis + (1|Demo.ResponseID), data=graphics_avgdeg %>% filter(!is.na(Demo.expreadnetvis)), verbose=TRUE)

summary(graph.avgdeg.nb)

# some categories significant; not sure what the reference category is though!
# TO DO : set reference level to None?

graph.avgdeg.nb.null.2 <- update(graph.avgdeg.nb, . ~ . - Demo.expreadnetvis)

summary(graph.avgdeg.nb.null.2)

# model failed to converge

anova(graph.avgdeg.nb, graph.avgdeg.nb.null.2)

# just over significance (p = 0.06055)

# TO DO : figure out which categories are significant and make some groups to increase
# significance?


graph.avgdeg.nb <- glmer.nb(Response ~ Demo.expcreatenetvis + (1|Demo.ResponseID), data=graphics_avgdeg %>% filter(!is.na(Demo.expcreatenetvis)), verbose=TRUE)

summary(graph.avgdeg.nb)

# one categories significant; not sure what the reference category is though!
# TO DO : set reference level to None?

graph.avgdeg.nb.null.2 <- update(graph.avgdeg.nb, . ~ . - Demo.expcreatenetvis)

summary(graph.avgdeg.nb.null.2)

# model failed to converge

anova(graph.avgdeg.nb, graph.avgdeg.nb.null.2)

# just over significance (p = 0.05901)

# TO DO : figure out which categories are significant and make some groups to increase
# significance?

graph.avgdeg.nb.avgdeg <- glmer.nb(Response ~ AvgDeg + (1|Demo.ResponseID), data=graphics_avgdeg, verbose=TRUE)

summary(graph.avgdeg.nb.avgdeg)

anova(graph.avgdeg.nb.avgdeg, graph.avgdeg.nb.null)

# model is significantly different from null model (p < 2.2e-16), so AvgDeg is a
# significant predictor

graph.avgdeg.nb.density <- glmer.nb(Response ~ Density + (1|Demo.ResponseID), data=graphics_avgdeg, verbose=TRUE)

summary(graph.avgdeg.nb.density)

anova(graph.avgdeg.nb.density, graph.avgdeg.nb.null)

# model is significantly different from null model (p < 2.2e-16), so Density is a
# significant predictor

graph.avgdeg.nb.largeclust <- glmer.nb(Response ~ LargeClust1 + (1|Demo.ResponseID), data=graphics_avgdeg, verbose=TRUE)

summary(graph.avgdeg.nb.largeclust)

anova(graph.avgdeg.nb.largeclust, graph.avgdeg.nb.null)

# model is significantly different from null model (p < 2.2e-16), so LargeClust1 is a
# significant predictor

graph.avgdeg.nb.mod <- glmer.nb(Response ~ Modularity + (1|Demo.ResponseID), data=graphics_avgdeg, verbose=TRUE)

summary(graph.avgdeg.nb.mod)

anova(graph.avgdeg.nb.mod, graph.avgdeg.nb.null)

# model is significantly different from null model (p < 2.2e-16), so Modularity is a
# significant predictor

graph.avgdeg.nb.numclust <- glmer.nb(Response ~ NumClust + (1|Demo.ResponseID), data=graphics_avgdeg, verbose=TRUE)

summary(graph.avgdeg.nb.numclust)

anova(graph.avgdeg.nb.numclust, graph.avgdeg.nb.null)

# model is significantly different from null model (p = 1.174e-12), so NumClust is a
# significant predictor

graph.avgdeg.nb <- glmer.nb(Response ~ NumHighDegree + (1|Demo.ResponseID), data=graphics_avgdeg, verbose=TRUE)

summary(graph.avgdeg.nb)

anova(graph.avgdeg.nb, graph.avgdeg.nb.null)

# model is not significantly different from null model (p = 0.2065), so NumHighDegree is not
# a significant predictor

graph.avgdeg.nb.numlinks <- glmer.nb(Response ~ NumLinks + (1|Demo.ResponseID), data=graphics_avgdeg, verbose=TRUE)

summary(graph.avgdeg.nb.numlinks)

# Error:
# Model failed to converge with max|grad| = 0.0063552 (tol = 0.001, component 1)
# Model is nearly unidentifiable: very large eigenvalue
# - Rescale variables?
# Model is nearly unidentifiable: large eigenvalue ratio
# - Rescale variables?

anova(graph.avgdeg.nb.numlinks, graph.avgdeg.nb.null)

# model is not significantly different from null model (p = 1.875e-06), so NumLinks is 
# a significant predictor

graph.avgdeg.nb.numnodes <- glmer.nb(Response ~ NumNodes + (1|Demo.ResponseID), data=graphics_avgdeg, verbose=TRUE)

summary(graph.avgdeg.nb.numnodes)

# Error:
#  failed to converge with max|grad| = 0.00178473 (tol = 0.001, component 1)
# Model is nearly unidentifiable: very large eigenvalue
#  - Rescale variables?

anova(graph.avgdeg.nb.numnodes, graph.avgdeg.nb.null)

# model is not significantly different from null model (p = 0.0004385), so NumNodes is 
# a significant predictor

graph.avgdeg.nb <- glmer.nb(Response ~ NumNodesClust1 + (1|Demo.ResponseID), data=graphics_avgdeg, verbose=TRUE)

summary(graph.avgdeg.nb)

# Error:
#Model failed to converge with max|grad| = 0.00187437 (tol = 0.001, component 1)
# Model is nearly unidentifiable: very large eigenvalue
# - Rescale variables?

anova(graph.avgdeg.nb, graph.avgdeg.nb.null)

# model is not significantly different from null model (p = 0.4105), so NumNodesClust1 is 
# not a significant predictor

#---------------------------------
# Multiple predictors
#---------------------------------

temp <- graphics_avgdeg %>% drop_na(Response, Dataset, TaskOrder, CorrectAnswer, Demo.dailytech_SmartPhone, AvgDeg, Density, LargeClust1, Modularity, NumClust, NumLinks, NumNodes)

graph.avgdeg.nb.full <- glmer.nb(Response ~ Dataset + TaskOrder + Demo.dailytech_SmartPhone + (1|Demo.ResponseID), 
                            data=temp, verbose=TRUE)

summary(graph.avgdeg.nb.full)
# still significant - Dataset, TaskOrder, SmartPhone

graph.avgdeg.nb.full.2 <- glmer.nb(Response ~ TaskOrder + CorrectAnswer + Demo.dailytech_SmartPhone + LargeClust1 + Modularity + NumNodes + (1|Demo.ResponseID), 
                            data=temp, verbose=TRUE)

summary(graph.avgdeg.nb.full.2)
# still significant: TaskOrder, CorrectAnswer, SmartPhone, LargeClust1, Modularity, NumNodes

# Error:
# Model failed to converge with max|grad| = 0.00841304 (tol = 0.001, component 1)
# Model is nearly unidentifiable: very large eigenvalue
#  - Rescale variables?
# Model is nearly unidentifiable: large eigenvalue ratio
#  - Rescale variables?

anova(graph.avgdeg.nb.full, graph.avgdeg.nb.full.2)
# two models not significantly different

graph.avgdeg.nb.full.3 <- glmer.nb(Response ~ TaskOrder + CorrectAnswer + Demo.dailytech_SmartPhone + LargeClust1 + (1|Demo.ResponseID), 
                            data=temp, verbose=TRUE)

summary(graph.avgdeg.nb.full.3)
# still significant: TaskOrder, CorrectAnswer, SmartPhone, LargeClust1

# Model is nearly unidentifiable: very large eigenvalue
#  - Rescale variables?

anova(graph.avgdeg.nb.full, graph.avgdeg.nb.full.3)

# model is not significantly different from original full model, so probably just keep graph.avgdeg.nb.full

#---------------------------------
# Interactions
#---------------------------------

graph.avgdeg.nb.full.int <- glmer.nb(Response ~ Dataset + 
                                       TaskOrder + Demo.dailytech_SmartPhone + 
                                       Dataset:TaskOrder + 
                                       TaskOrder:Demo.dailytech_SmartPhone + 
                                       Dataset:Demo.dailytech_SmartPhone +
                                       (1|Demo.ResponseID), 
                            data=temp, verbose=TRUE)

summary(graph.avgdeg.nb.full.int)

anova(graph.avgdeg.nb.full, graph.avgdeg.nb.full.int)
# yes, interaction is significantly different from just main effects

# TO DO : check lmer results again after factoring


```

```{r, eval=FALSE}

graph.avgdeg.nb.full.f <- fortify(graph.avgdeg.nb.full)

ggplot(graph.avgdeg.nb.full.f, aes(.fitted,.resid)) + 
  geom_point() +
  geom_hline(yintercept=0)

ggplot(graph.avgdeg.nb.full.f, aes(.fitted,Response)) + 
  geom_point() +
  geom_hline(yintercept=0) +
  scale_y_log10()

ggplot(graph.avgdeg.nb.full.f, aes(.fitted,Response, color=Dataset)) + 
  geom_point() +
  geom_hline(yintercept=0) +
  scale_y_log10()

ggplot(graph.avgdeg.nb.full.f, aes(.fitted,Response)) + 
  geom_point() +
  geom_hline(yintercept=0) +
  scale_y_log10() +
  facet_wrap(~Dataset)

graph.avgdeg.nb.full.int.f <- fortify(graph.avgdeg.nb.full.int)

ggplot(graph.avgdeg.nb.full.int.f, aes(.fitted,.resid)) + 
  geom_point() +
  geom_hline(yintercept=0)

ggplot(graph.avgdeg.nb.full.int.f, aes(.fitted,Response)) + 
  geom_point() +
  geom_hline(yintercept=0) +
  scale_y_log10()


```



```{r, eval=FALSE}

# is negative binomial different from poisson?  if so, indicates over-dispersion is true
# and negative binomial is necessary

graph.avgdeg.pois <- glmer(Response ~ Dataset + 
                                       TaskOrder + Demo.dailytech_SmartPhone + 
                                       Dataset:TaskOrder + 
                                       TaskOrder:Demo.dailytech_SmartPhone + 
                                       Dataset:Demo.dailytech_SmartPhone +
                                       (1|Demo.ResponseID), data=temp, family="poisson")

pchisq(2 * (logLik(graph.avgdeg.nb.full.int) - logLik(graph.avgdeg.pois)), df=1, lower.tail = FALSE)

# value = 0, so keep the negative binomial

```

```{r, eval = FALSE}

# To fit a negative binomial model with known overdispersion parameter (e.g. as part of a model
#comparison exercise), use glmer with the negative.binomial family from the MASS package, e.g.
#glmer(...,family=MASS::negative.binomial(theta=1.75)).

graph.avgdeg.nb2 <- glmer(Response ~ Condition + (1|Demo.ResponseID), data=graphics_avgdeg, family=MASS::negative.binomial(theta=1.75))

graph.avgdeg.nb3 <- glmer(Response ~ Condition + (1|Demo.ResponseID), data=graphics_avgdeg, family=negative.binomial(2))


#graph.avgdeg.nb

summary(graph.avgdeg.nb2)
summary(graph.avgdeg.nb3)

```

```{r, eval=FALSE}
# run without mixed effects to validate

m.glm <- glm.nb(Response ~ Dataset + TaskOrder + Demo.dailytech_SmartPhone + 
                                       Dataset:TaskOrder + 
                                       TaskOrder:Demo.dailytech_SmartPhone + 
                                       Dataset:Demo.dailytech_SmartPhone, data=temp, trace=TRUE)
summary(m.glm)

## The neg.binomial theta parameter:
getME(graph.avgdeg.nb.full.int, "glmer.nb.theta")

#1.567446

## mixed model has 1 additional parameter (RE variance)
stopifnot(attr(logLik(graph.avgdeg.nb.full.int),"df")==attr(logLik(m.glm),"df")+1) # not sure what this does

anova(graph.avgdeg.nb.full.int,m.glm) # can I use anova to compare mixed and fixed effects?
# p < 2.2e-16, so definitely random effects

plot(graph.avgdeg.nb.full.int, resid(.) ~ Response)# works, as long as data 'dd' is found


# TO DO : check if this is all right

```

```{r, eval=FALSE}

par(mfrow=c(2,2))
qqnorm(resid(graph.avgdeg.nb.full.int), main="normal qq-plot, residuals")
qqline(resid(graph.avgdeg.nb.full.int))

qqnorm(ranef(graph.avgdeg.nb.full.int)$Demo.ResponseID[,1])
qqline(ranef(graph.avgdeg.nb.full.int)$Demo.ResponseID[,1])


plot(fitted(graph.avgdeg.nb.full.int), resid(graph.avgdeg.nb.full.int)) #residuals vs fitted
abline(h=0)

#graph.avgdeg.nb2.f <- fortify(graph.avgdeg.nb2)

#ggplot(graph.avgdeg.nb2.f, aes(.fitted,.resid)) + 
#  geom_point() +
#  geom_hline(yintercept=0)

#temp <- graphics_avgdeg

temp$fitted <- fitted(graph.avgdeg.nb.full.int) 
plot(temp$fitted, jitter(temp$Response,0.1)) #fitted vs observed
abline(0,1)

#ggplot(graph.avgdeg.nb2.f, aes(.fitted,Response)) + 
#  geom_point() +
#  geom_abline(aes(slope = 1, intercept = 0))


```

```{r, cache=TRUE, eval=FALSE}

# Confidence Intervals, using coefficients

(est <- cbind(Estimate = coef(graph.avgdeg.nb.full.int), confint(graph.avgdeg.nb.full.int)))

# exponentiate model to look at incident rate ratios instead of coefficients

exp(est)

```

```{r, eval=FALSE}

# predictions

# model: Response ~ Dataset + TaskOrder + Demo.dailytech_SmartPhone + Dataset:TaskOrder + TaskOrder:Demo.dailytech_SmartPhone + Dataset:Demo.dailytech_SmartPhone + (1 | Demo.ResponseID)

newdata1 <- data.frame(Demo.dailytech_SmartPhone = rep(mean(temp$Demo.dailytech_SmartPhone),54), 
                       Dataset = factor(rep(c(1,3,5,7,8,9),9), levels = levels(temp$Dataset),ordered = TRUE),
                       TaskOrder = rep(1:9,6),
                       Demo.ResponseID = sample(temp$Demo.ResponseID,54))
newdata1$phat <- predict(graph.avgdeg.nb.full.int, newdata1, type = "response")
#newdata1

newdata2 <- data.frame(
  Demo.dailytech_SmartPhone = rep(seq(from = min(temp$Demo.dailytech_SmartPhone), to = max(temp$Demo.dailytech_SmartPhone), length.out = 100), 6),
  Dataset = factor(rep(c(1,3,5,7,8,9), each = 100), levels = levels(temp$Dataset),ordered = TRUE),
  TaskOrder = rep(1:9,len=600),
  Demo.ResponseID = sample(temp$Demo.ResponseID,600)
  )

#predict(graph.avgdeg.nb.full.int, newdata2, type = "link", se.fit=TRUE)
newdata2 <- cbind(newdata2, predict(graph.avgdeg.nb.full.int, newdata2, type = "link", se.fit=TRUE))

# not sure about this; asking for "fit", but that's not recognized. should the new column be called "fit"? what about se.fit?

#newdata2 <- within(newdata2, {
#  Response <- exp(fit)
#  LL <- exp(fit - 1.96 * se.fit)
#  UL <- exp(fit + 1.96 * se.fit)
#})

#ggplot(newdata2, aes(math, DaysAbsent)) +
#  geom_ribbon(aes(ymin = LL, ymax = UL, fill = prog), alpha = .25) +
#  geom_line(aes(colour = prog), size = 2) +
#  labs(x = "Math Score", y = "Predicted Days Absent")

# note on negative binomial:

# TO DO : If the data generating process does not allow for any 0s (such as the number of days spent in the hospital), then a zero-truncated model may be more appropriate.

# TO DO : Count data often have an exposure variable, which indicates the number of times the event could have happened (i.e. a max). This variable should be incorporated into your negative binomial regression model with the use of the offset option. See the glm documentation for details.  (so, that would make sense for click data???)

# other info:
# Cameron, A. C. and Trivedi, P. K. 1998. Regression Analysis of Count Data. New York: Cambridge Press.
# Dupont, W. D. 2002. Statistical Modeling for Biomedical Researchers: A Simple Introduction to the Analysis of Complex Data. New York: Cambridge Press.

```

### Betweenness Centrality

#### Negative binomial model for click questions Node Rank

Ranks are like count data, in that they are nonnegative integers, so using a negative binomial distribution to model. Negative binomial is especially useful for over-dispersed data - data where the conditional variances exceed conditional means. 

```{r}

# https://stats.idre.ucla.edu/r/dae/negative-binomial-regression/ for non-mixed version

# Test for overdispersion

with(graphics_bc, tapply(NodeRank, Condition, function(x) {
    sprintf("M (SD) = %1.2f (%1.2f)", mean(x), sd(x))
}))

# variances in each condition (except Size) are larger than means in the conditions

```

```{r, cache=TRUE, eval=FALSE}

# negative binomial models - no offset, first single fixed effects, then multiple, then interactions

graph.bc.nb.null <- glmer.nb(NodeRank ~ (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE)

# Model failed to converge with max|grad| = 0.040352 (tol = 0.001, component 1) --> dev.= -2*logLik(.) = 5486.616 

graph.bc.nb.null <- glmer.nb(NodeRank ~ (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE, control=glmerControl(optimizer = "nlminbw"))

graph.bc.nb <- glmer.nb(NodeRank ~ Condition + (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE)

summary(graph.bc.nb)

anova(graph.bc.nb, graph.bc.nb.null)

# model is not significantly different from null model (p=0.232), so Condition isn't a
# significant predictor

graph.bc.nb <- glmer.nb(NodeRank ~ factor(Ctrl_dummy) + (1|Demo.ResponseID), 
                        data=graphics_bc, verbose=TRUE, control=glmerControl(optimizer = "nlminbw"))

summary(graph.bc.nb)

anova(graph.bc.nb, graph.bc.nb.null)

# Ctrl_dummy is not significant

graph.bc.nb <- glmer.nb(NodeRank ~ ConditionPhrasing + (1|Demo.ResponseID), 
                        data=graphics_bc, verbose=TRUE)

summary(graph.bc.nb)

anova(graph.bc.nb, graph.bc.nb.null)

# ConditionPhrasing is not significant

graph.bc.nb <- glmer.nb(NodeRank ~ ConditionGraphics + (1|Demo.ResponseID), 
                        data=graphics_bc, verbose=TRUE)

summary(graph.bc.nb)

anova(graph.bc.nb, graph.bc.nb.null)

# ConditionPhrasing is not significant


#graph.bc.nb.dataset <- glmer.nb(NodeRank ~ Dataset + (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE)

# model failed to converge

graph.bc.nb.dataset <- glmer.nb(NodeRank ~ Dataset + (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE, control=glmerControl(optimizer = "nlminbw"))

summary(graph.bc.nb.dataset)

anova(graph.bc.nb.dataset, graph.bc.nb.null)

# model is significantly different from null model (p < 2.2e-16)

#graph.bc.nb.dataOrder <- glmer.nb(NodeRank ~ DatasetOrder + (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE)

# model failed to converge

graph.bc.nb.dataOrder <- glmer.nb(NodeRank ~ DatasetOrder + (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE, control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb.dataOrder)

anova(graph.bc.nb.dataOrder, graph.bc.nb.null)

# model is significantly different from null model (p = 0.005009)

#graph.bc.nb <- glmer.nb(NodeRank ~ DatasetDuration + (1|Demo.ResponseID), data=graphics_bc %>% filter(!is.na(DatasetDuration)), verbose=TRUE)

# major error: PIRLS step-halvings failed to reduce deviance in pwrssUpdate; rescale data

graphics_bc.CS <- graphics_bc %>% mutate(DatasetDuration=scale(DatasetDuration))

graph.bc.nb <- glmer.nb(NodeRank ~ DatasetDuration + (1|Demo.ResponseID), 
                        data=graphics_bc.CS %>% filter(!is.na(DatasetDuration)), verbose=TRUE)

# get an error about model convergence; trying suggestions from lme4 documentation

# try fitting with all optimizers; if all converge to about the same values, convergence warning can be ignored

#source(system.file("utils", "allFit.R", package="lme4"))

#graph.bc.nb.all <- allFit(graph.bc.nb)
#ss <- summary(graph.bc.nb.all)
#ss$fixef
#ss$llik
#ss$sdcor
#ss$theta
#ss$which.OK

# or can restart fit from apparent optimum
#graph.bc.nb.restart <- update(graph.bc.nb, start=pars)
#summary(graph.bc.nb.restart)

# trying just manually changing optimizer

graph.bc.nb <- glmer.nb(NodeRank ~ DatasetDuration + (1|Demo.ResponseID), 
                        data=graphics_bc.CS %>% filter(!is.na(DatasetDuration)), verbose=TRUE, 
                        control=glmerControl(optimizer = "nlminbw"))

#seems okay; don't see any errors

summary(graph.bc.nb)

graph.bc.nb.null2 <- glmer.nb(NodeRank ~ (1|Demo.ResponseID), data=graphics_bc.CS %>% filter(!is.na(DatasetDuration)), verbose=TRUE, control=glmerControl(optimizer = "nlminbw"))

anova(graph.bc.nb, graph.bc.nb.null2)

# DatasetDuration is not significant 

#graph.bc.nb.taskorder <- glmer.nb(NodeRank ~ TaskOrder + (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE)

# failed to converge

graph.bc.nb <- glmer.nb(NodeRank ~ TaskOrder + (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE, control=glmerControl(optimizer = "Nelder_Mead"))

# still have a failed to converge warning, but results seem similar with different optimizers

summary(graph.bc.nb)

anova(graph.bc.nb, graph.bc.nb.null)

# TaskOrder is not significant

#graph.bc.nb <- glmer.nb(NodeRank ~ QuestionOrder + (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE)

# warnings about rescaling variables

graphics_bc.CS <- graphics_bc %>% mutate(QuestionOrder=scale(QuestionOrder))

graph.bc.nb <- glmer.nb(NodeRank ~ QuestionOrder + (1|Demo.ResponseID), 
                        data=graphics_bc.CS, verbose=TRUE, control=glmerControl(optimizer = "nlminbw"))

summary(graph.bc.nb)

graph.bc.nb.null2 <- glmer.nb(NodeRank ~ (1|Demo.ResponseID), data=graphics_bc.CS, verbose=TRUE, control=glmerControl(optimizer = "nlminbw"))

anova(graph.bc.nb, graph.bc.nb.null2)

# QuestionOrder is not significant


#graph.bc.nb <- glmer.nb(NodeRank ~ CorrectAnswer + (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE)

# error about rescaling

graphics_bc.CS <- graphics_bc %>% mutate(CorrectAnswer=scale(CorrectAnswer))

graph.bc.nb.correct <- glmer.nb(NodeRank ~ CorrectAnswer + (1|Demo.ResponseID), 
                        data=graphics_bc.CS, verbose=TRUE)

summary(graph.bc.nb.correct)

graph.bc.nb.null2 <- glmer.nb(NodeRank ~ (1|Demo.ResponseID), data=graphics_bc.CS, verbose=TRUE, control=glmerControl(optimizer = "nlminbw"))

anova(graph.bc.nb.correct, graph.bc.nb.null2)

# CorrectAnswer is significant (p=9.358e-09)

#graph.bc.nb <- glmer.nb(NodeRank ~ Stats.Q_TotalDuration + (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE)

# warnings about rescaling variables

graphics_bc.CS <- graphics_bc %>% mutate(Stats.Q_TotalDuration=scale(Stats.Q_TotalDuration))

graph.bc.nb.totdur <- glmer.nb(NodeRank ~ Stats.Q_TotalDuration + (1|Demo.ResponseID), data=graphics_bc.CS, verbose=TRUE, control=glmerControl(optimizer = "nlminbw"))

summary(graph.bc.nb.totdur)

graph.bc.nb.null2 <- glmer.nb(NodeRank ~ (1|Demo.ResponseID), data=graphics_bc.CS, verbose=TRUE, control=glmerControl(optimizer = "nlminbw"))

anova(graph.bc.nb.totdur, graph.bc.nb.null2)

# Stats.Q_TotalDuration is significant (p=0.003248)


graph.bc.nb <- glmer.nb(NodeRank ~ Stats.OperatingSystem + (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE, control=glmerControl(optimizer = "bobyqa"))
# very slooooooow, but no errors

summary(graph.bc.nb) # nothing significant

anova(graph.bc.nb, graph.bc.nb.null)

# Stats.OperatingSystems is not significant

graph.bc.nb <- glmer.nb(NodeRank ~ Stats.OperatingSystemCombined + (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE, control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb) # iPhone significantly different from Android

anova(graph.bc.nb, graph.bc.nb.null)

# Stats.OperatingSystemCombined is not significant

graph.bc.nb <- glmer.nb(NodeRank ~ Stats.OperatingSystemCombined2 + (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE, control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb)

anova(graph.bc.nb, graph.bc.nb.null)

# Stats.OperatingSystemCombined2 is not significant

graph.bc.nb <- glmer.nb(NodeRank ~ Stats.OperatingSystemCombined3 + (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE, control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb)

anova(graph.bc.nb, graph.bc.nb.null)

# Stats.OperatingSystemCombined3 is not significant

graph.bc.nb <- glmer.nb(NodeRank ~ Stats.OperatingSystemCombined4 + (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE, control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb)

anova(graph.bc.nb, graph.bc.nb.null)

# Stats.OperatingSystemCombined4 is not significant

graph.bc.nb <- glmer.nb(NodeRank ~ Stats.OperatingSystemCombined5 + (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE, control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb)

anova(graph.bc.nb, graph.bc.nb.null)

# Stats.OperatingSystemCombined5 is not significant

graph.bc.nb <- glmer.nb(NodeRank ~ Stats.OperatingSystemWindows + (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE, control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb)

anova(graph.bc.nb, graph.bc.nb.null)

# Stats.OperatingSystemWindows is not significant

graph.bc.nb <- glmer.nb(NodeRank ~ Stats.OperatingSystemMacintosh + (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE, control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb)

anova(graph.bc.nb, graph.bc.nb.null)

# Stats.OperatingSystemMacintosh is not significant

graph.bc.nb <- glmer.nb(NodeRank ~ Stats.OperatingSystemAndroid + (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE, control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb)

anova(graph.bc.nb, graph.bc.nb.null)

# Stats.OperatingSystemAndroid is not significant

graph.bc.nb <- glmer.nb(NodeRank ~ Stats.OperatingSystemiPhone + (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE, control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb)

anova(graph.bc.nb, graph.bc.nb.null)

# Stats.OperatingSystemiPhone is not significant


#graph.bc.nb <- glmer.nb(NodeRank ~ StatsNumPixels + (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE)

# need to rescale

graphics_bc.CS <- graphics_bc %>% mutate(StatsNumPixels=scale(StatsNumPixels))

graph.bc.nb <- glmer.nb(NodeRank ~ StatsNumPixels + (1|Demo.ResponseID), 
                        data=graphics_bc.CS, verbose=TRUE, 
                        control=glmerControl(optimizer = "nlminbw"))

summary(graph.bc.nb)

graph.bc.nb.null2 <- glmer.nb(NodeRank ~ (1|Demo.ResponseID), data=graphics_bc.CS, verbose=TRUE, control=glmerControl(optimizer = "nlminbw"))

anova(graph.bc.nb, graph.bc.nb.null2)

# StatsNumPixels not significant

#graph.bc.nb <- glmer.nb(NodeRank ~ Demo.age + (1|Demo.ResponseID), data=graphics_bc %>% filter(!is.na(Demo.age)), verbose=TRUE)

# need to rescale

graphics_bc.CS <- graphics_bc %>% mutate(Demo.age=scale(Demo.age))

graph.bc.nb <- glmer.nb(NodeRank ~ Demo.age + (1|Demo.ResponseID), 
                        data=graphics_bc.CS %>% filter(!is.na(Demo.age)), verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))


summary(graph.bc.nb)

graph.bc.nb.null2 <- glmer.nb(NodeRank ~ (1|Demo.ResponseID), 
                        data=graphics_bc.CS %>% filter(!is.na(Demo.age)), verbose=TRUE, 
                        control=glmerControl(optimizer = "nlminbw"))

anova(graph.bc.nb, graph.bc.nb.null2)

# Demo.age is not significant

graph.bc.nb <- glmer.nb(NodeRank ~ Demo.gender + (1|Demo.ResponseID), 
                        data=graphics_bc %>% filter(!is.na(Demo.gender)), verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb)

graph.bc.nb.null.2 <- update(graph.bc.nb, . ~ . - Demo.gender)

summary(graph.bc.nb.null.2)

anova(graph.bc.nb, graph.bc.nb.null.2)

# Demo.gender is not significant (p=0.09937)

graph.bc.nb <- glmer.nb(NodeRank ~ Demo.lang + (1|Demo.ResponseID), 
                        data=graphics_bc %>% filter(!is.na(Demo.lang)), verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb)

graph.bc.nb.null.2 <- update(graph.bc.nb, . ~ . - Demo.lang)

summary(graph.bc.nb.null.2)

anova(graph.bc.nb, graph.bc.nb.null.2)

# Demo.lang is not a significant predictor

graph.bc.nb <- glmer.nb(NodeRank ~ Demo.educ + (1|Demo.ResponseID), 
                        data=graphics_bc %>% filter(!is.na(Demo.educ)), verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb)

graph.bc.nb.null.2 <- update(graph.bc.nb, . ~ . - Demo.educ)

anova(graph.bc.nb, graph.bc.nb.null.2)

# Demo.educ is not significant

graph.bc.nb <- glmer.nb(NodeRank ~ Demo.acfield + (1|Demo.ResponseID), 
                        data=graphics_bc %>% filter(!is.na(Demo.acfield)), verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb)

# several categories significantly different from Anthropology:
# Architecture and design, Arts, Business, Earth sciences, Information science, Library and museum studies, Other, Political science
# marginal: Computer sciences, History, Languages, Psychology, Skipped, Sociology

graph.bc.nb.null.2 <- update(graph.bc.nb, . ~ . - Demo.acfield)

anova(graph.bc.nb, graph.bc.nb.null.2)

# almost significant (p=0.07284)

graph.bc.nb <- glmer.nb(NodeRank ~ Demo.acfieldGrouped + (1|Demo.ResponseID), 
                        data=graphics_bc %>% filter(!is.na(Demo.acfieldGrouped)), verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))

graph.bc.nb.null.2 <- update(graph.bc.nb, . ~ . - Demo.acfieldGrouped)

anova(graph.bc.nb, graph.bc.nb.null.2)

# Demo.acfieldGrouped is not significant

graph.bc.nb.acfield2 <- glmer.nb(NodeRank ~ Demo.acfieldGrouped2 + (1|Demo.ResponseID), 
                        data=graphics_bc %>% filter(!is.na(Demo.acfieldGrouped2)), verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))

graph.bc.nb.null.2 <- update(graph.bc.nb.acfield2, . ~ . - Demo.acfieldGrouped2)

anova(graph.bc.nb.acfield2, graph.bc.nb.null.2)

# Demo.acfieldGrouped2 (actually set up because of results of bc.lmer model) is 
# significant (p=2.861e-05)

graph.bc.nb <- glmer.nb(NodeRank ~ Demo.dailytech_Computer + (1|Demo.ResponseID), 
                        data=graphics_bc %>% filter(!is.na(Demo.dailytech_Computer)), verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb)

# almost significant

graph.bc.nb.null.2 <- update(graph.bc.nb, . ~ . - Demo.dailytech_Computer)

anova(graph.bc.nb, graph.bc.nb.null.2)

# almost significant (p=0.06008)

graph.bc.nb <- glmer.nb(NodeRank ~ Demo.dailytech_Tablet + (1|Demo.ResponseID), 
                        data=graphics_bc %>% filter(!is.na(Demo.dailytech_Tablet)), verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb)

graph.bc.nb.null.2 <- update(graph.bc.nb, . ~ . - Demo.dailytech_Tablet)

anova(graph.bc.nb, graph.bc.nb.null.2)

# not significant

graph.bc.nb <- glmer.nb(NodeRank ~ Demo.dailytech_SmartPhone + (1|Demo.ResponseID), 
                        data=graphics_bc %>% filter(!is.na(Demo.dailytech_SmartPhone)), verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb)

graph.bc.nb.null.2 <- update(graph.bc.nb, . ~ . - Demo.dailytech_SmartPhone)

anova(graph.bc.nb, graph.bc.nb.null.2)

# not significant (p = 0.1108)

graph.bc.nb <- glmer.nb(NodeRank ~ Demo.weeklygaming + (1|Demo.ResponseID), 
                        data=graphics_bc %>% filter(!is.na(Demo.weeklygaming)), verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb)

graph.bc.nb.null.2 <- update(graph.bc.nb, . ~ . - Demo.weeklygaming)

anova(graph.bc.nb, graph.bc.nb.null.2)

# not significant

graph.bc.nb <- glmer.nb(NodeRank ~ Demo.expdataanal + (1|Demo.ResponseID), 
                        data=graphics_bc %>% filter(!is.na(Demo.expdataanal)), verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb)

graph.bc.nb.null.2 <- update(graph.bc.nb, . ~ . - Demo.expdataanal)

anova(graph.bc.nb, graph.bc.nb.null.2)

# not significant

graph.bc.nb <- glmer.nb(NodeRank ~ Demo.expdatavis + (1|Demo.ResponseID), 
                        data=graphics_bc %>% filter(!is.na(Demo.expdatavis)), verbose=TRUE)

summary(graph.bc.nb)

graph.bc.nb.null.2 <- update(graph.bc.nb, . ~ . - Demo.expdatavis)

anova(graph.bc.nb, graph.bc.nb.null.2)

# not significant

graph.bc.nb.readNV <- glmer.nb(NodeRank ~ Demo.expreadnetvis + (1|Demo.ResponseID), 
                        data=graphics_bc %>% filter(!is.na(Demo.expreadnetvis)), verbose=TRUE)

summary(graph.bc.nb.readNV)

# most categories significant; not sure what the reference category is though.  "None"?

graph.bc.nb.null.2 <- update(graph.bc.nb.readNV, . ~ . - Demo.expreadnetvis)

anova(graph.bc.nb.readNV, graph.bc.nb.null.2)

# significant (p = 0.007718)

graph.bc.nb.createNV <- glmer.nb(NodeRank ~ Demo.expcreatenetvis + (1|Demo.ResponseID), 
                        data=graphics_bc %>% filter(!is.na(Demo.expcreatenetvis)), verbose=TRUE)

summary(graph.bc.nb.createNV)

graph.bc.nb.null.2 <- update(graph.bc.nb.createNV, . ~ . - Demo.expcreatenetvis)

anova(graph.bc.nb.createNV, graph.bc.nb.null.2)

# significant (p = 0.003442)

graph.bc.nb.avgdeg <- glmer.nb(NodeRank ~ AvgDeg + (1|Demo.ResponseID), 
                               data=graphics_bc, verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb.avgdeg)

anova(graph.bc.nb.avgdeg, graph.bc.nb.null)

# AvgDeg is significant (p < 2.2e-16)

graph.bc.nb.density <- glmer.nb(NodeRank ~ Density + (1|Demo.ResponseID), 
                                data=graphics_bc, verbose=TRUE)

summary(graph.bc.nb.density)

anova(graph.bc.nb.density, graph.bc.nb.null)

# Density is a significant(p < 2.2e-16)

#graph.bc.nb.largeclust <- glmer.nb(NodeRank ~ LargeClust1 + (1|Demo.ResponseID), 
#                                   data=graphics_bc, verbose=TRUE)

# need to rescale

graphics_bc.CS <- graphics_bc %>% mutate(LargeClust1=scale(LargeClust1))

graph.bc.nb.largeclust <- glmer.nb(NodeRank ~ LargeClust1 + (1|Demo.ResponseID), 
                        data=graphics_bc.CS, verbose=TRUE)

summary(graph.bc.nb.largeclust)

graph.bc.nb.null.2 <- update(graph.bc.nb.largeclust, . ~ . - LargeClust1)

anova(graph.bc.nb.largeclust, graph.bc.nb.null.2)

# LargeClust1 is significant (p < 2.2e-16)

graph.bc.nb.mod <- glmer.nb(NodeRank ~ Modularity + (1|Demo.ResponseID), 
                            data=graphics_bc, verbose=TRUE)

summary(graph.bc.nb.mod)

anova(graph.bc.nb.mod, graph.bc.nb.null)

# Modularity is significant(p < 2.2e-16)

graph.bc.nb.numclust <- glmer.nb(NodeRank ~ NumClust + (1|Demo.ResponseID), 
                                 data=graphics_bc, verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb.numclust)

anova(graph.bc.nb.numclust, graph.bc.nb.null)

# NumClust is significant (p = 1.91e-11)

#graph.bc.nb <- glmer.nb(NodeRank ~ NumHighDegree + (1|Demo.ResponseID), 
#                        data=graphics_bc, verbose=TRUE)

# need to rescale

graphics_bc.CS <- graphics_bc %>% mutate(NumHighDegree=scale(NumHighDegree))

graph.bc.nb.numhighdeg <- glmer.nb(NodeRank ~ NumHighDegree + (1|Demo.ResponseID), 
                        data=graphics_bc.CS, verbose=TRUE)

summary(graph.bc.nb.numhighdeg)

graph.bc.nb.null.2 <- update(graph.bc.nb.numhighdeg, . ~ . - NumHighDegree)

anova(graph.bc.nb.numhighdeg, graph.bc.nb.null.2)

# NumHighDegree is significant (p=0.003951)

#graph.bc.nb.numlinks <- glmer.nb(NodeRank ~ NumLinks + (1|Demo.ResponseID), 
#                                 data=graphics_bc, verbose=TRUE)

# need to rescale

graphics_bc.CS <- graphics_bc %>% mutate(NumLinks=scale(NumLinks))

graph.bc.nb.numlinks <- glmer.nb(NodeRank ~ NumLinks + (1|Demo.ResponseID), 
                        data=graphics_bc.CS, verbose=TRUE)

summary(graph.bc.nb.numlinks)

graph.bc.nb.null.2 <- update(graph.bc.nb.numlinks, . ~ . - NumLinks)

anova(graph.bc.nb.numlinks, graph.bc.nb.null.2)

# NumLinks is significant (p=1.533e-08)

#graph.bc.nb.numnodes <- glmer.nb(NodeRank ~ NumNodes + (1|Demo.ResponseID), 
#                                 data=graphics_bc, verbose=TRUE)

# need to rescale

graphics_bc.CS <- graphics_bc %>% mutate(NumNodes=scale(NumNodes))

graph.bc.nb.numnodes <- glmer.nb(NodeRank ~ NumNodes + (1|Demo.ResponseID), 
                        data=graphics_bc.CS, verbose=TRUE)

summary(graph.bc.nb.numnodes)

graph.bc.nb.null.2 <- update(graph.bc.nb.numnodes, . ~ . - NumNodes)

anova(graph.bc.nb.numnodes, graph.bc.nb.null.2)

# NumNodes is significant (p=1.075e-14)

#graph.bc.nb <- glmer.nb(NodeRank ~ NumNodesClust1 + (1|Demo.ResponseID), 
#                        data=graphics_bc, verbose=TRUE)

# need to rescale

graphics_bc.CS <- graphics_bc %>% mutate(NumNodesClust1=scale(NumNodesClust1))

graph.bc.nb.numnodesclust1 <- glmer.nb(NodeRank ~ NumNodesClust1 + (1|Demo.ResponseID), 
                        data=graphics_bc.CS, verbose=TRUE)

summary(graph.bc.nb.numnodesclust1)

graph.bc.nb.null.2 <- update(graph.bc.nb.numnodesclust1, . ~ . - NumNodesClust1)

anova(graph.bc.nb.numnodesclust1, graph.bc.nb.null.2)

# NumNodesClust1 is significant (p=1.08e-10)
```

```{r, cache=TRUE, eval=FALSE}

# Trying offset, since NodeRank does have a maximum, and that changes by dataset

graph.bc.nb.null.offset <- glmer.nb(NodeRank ~ (1|Demo.ResponseID) + offset(log(MaxNodeRank)), data=graphics_bc, verbose=TRUE)

summary(graph.bc.nb.null.offset)

anova(graph.bc.nb.null, graph.bc.nb.null.offset)

# no significant difference with offset; try once with a significant predictor 

graph.bc.nb.dataset.offset <- glmer.nb(NodeRank ~ Dataset + offset(log(MaxNodeRank)) + (1|Demo.ResponseID), data=graphics_bc, verbose=TRUE, control=glmerControl(optimizer = "nlminbw"))

summary(graph.bc.nb.dataset.offset)

anova(graph.bc.nb.dataset, graph.bc.nb.dataset.offset)

# nope, offset didn't make any difference; proceeding with no-offset models

```


```{r}

#---------------------------------
# Multiple predictors
#---------------------------------

temp <- graphics_bc %>% dplyr::select(Demo.ResponseID, NodeRank, Dataset, DatasetOrder, CorrectAnswer, Stats.Q_TotalDuration, Demo.acfieldGrouped2, Demo.expreadnetvis, Demo.expcreatenetvis, AvgDeg, Density, LargeClust1, Modularity, NumClust, NumHighDegree, NumLinks, NumNodes, NumNodesClust1) %>% drop_na()

temp <- temp %>% mutate(Stats.Q_TotalDuration=scale(Stats.Q_TotalDuration),
                        NormRank=NodeRank/NumNodes)

graph.bc.nb.full <- glmer.nb(NodeRank ~ Dataset + Stats.Q_TotalDuration + 
                               Demo.acfieldGrouped2 + Demo.expcreatenetvis +
                               (1|Demo.ResponseID),
                             data=temp, verbose=TRUE,
                             control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb.full)
# still significant - Dataset, Stats.Q_TotalDuration, Demo.acfieldGrouped2, Demo.expcreatenetvis
```

```{r}
#---------------------------------
# Interactions
#---------------------------------

graph.bc.nb.full.int <- glmer.nb(NodeRank ~ Dataset + Stats.Q_TotalDuration + 
                                   Demo.acfieldGrouped2 + Demo.expcreatenetvis +
                                   Stats.Q_TotalDuration:Demo.acfieldGrouped2 +
                                   (1|Demo.ResponseID),
                                 data=temp, verbose=TRUE,
                                 control=glmerControl(optimizer = "bobyqa"))

summary(graph.bc.nb.full.int)

anova(graph.bc.nb.full, graph.bc.nb.full.int)
# yes, interaction is significantly different from just main effects (p = 0.02812)

```


```{r}

graph.bc.nb.full.int.f <- fortify(graph.bc.nb.full.int)

ggplot(graph.bc.nb.full.int.f, aes(.fitted,.resid)) + 
  geom_point() +
  geom_hline(yintercept=0)

ggplot(graph.bc.nb.full.int.f, aes(.resid)) +
  geom_histogram()

# not *quite* normally distributed...  but not too skewed?

ggplot(graph.bc.nb.full.int.f, aes(.fitted,NodeRank)) + 
  geom_point() +
  geom_hline(yintercept=0) +
  scale_y_log10()

ggplot(graph.bc.nb.full.int.f, aes(.fitted,NodeRank, color=Dataset)) + 
  geom_point() +
  geom_hline(yintercept=0) +
  scale_y_log10() +
  scale_color_brewer(palette = "Dark2")

ggplot(graph.bc.nb.full.int.f, aes(.fitted,NodeRank)) + 
  geom_point() +
  geom_hline(yintercept=0) +
  scale_y_log10() +
  facet_wrap(~Dataset)


```



```{r}

# is negative binomial different from poisson?  if so, indicates over-dispersion is true
# and negative binomial is necessary

graph.bc.pois <- glmer(NodeRank ~ Dataset + Stats.Q_TotalDuration + 
                                   Demo.acfieldGrouped2 + Demo.expcreatenetvis +
                                   Stats.Q_TotalDuration:Demo.acfieldGrouped2 +
                                   (1|Demo.ResponseID), data=temp, family="poisson")


pchisq(2 * (logLik(graph.bc.nb.full.int) - logLik(graph.bc.pois)), df=1, lower.tail = FALSE)

# value = 6.566148e-73, so keep the negative binomial

```

```{r}
# run without mixed effects to validate

m.glm <- glm.nb(NodeRank ~ Dataset + Stats.Q_TotalDuration + 
                                   Demo.acfieldGrouped2 + Demo.expcreatenetvis +
                                   Stats.Q_TotalDuration:Demo.acfieldGrouped2, data=temp, trace=TRUE)
summary(m.glm)

## The neg.binomial theta parameter:
getME(graph.bc.nb.full.int, "glmer.nb.theta")

#3.835875

## mixed model has 1 additional parameter (RE variance)
stopifnot(attr(logLik(graph.bc.nb.full.int),"df")==attr(logLik(m.glm),"df")+1) # not sure what this does

anova(graph.bc.nb.full.int,m.glm) # can I use anova to compare mixed and fixed effects?
# p < 2.2e-16, so definitely random effects

plot(graph.bc.nb.full.int, resid(.) ~ NodeRank)# works, as long as data 'dd' is found


# TO DO : check if this is all right

```

```{r}

par(mfrow=c(2,2))
qqnorm(resid(graph.bc.nb.full.int), main="normal qq-plot, residuals")
qqline(resid(graph.bc.nb.full.int))

qqnorm(ranef(graph.bc.nb.full.int)$Demo.ResponseID[,1])
qqline(ranef(graph.bc.nb.full.int)$Demo.ResponseID[,1])


plot(fitted(graph.bc.nb.full.int), resid(graph.bc.nb.full.int)) #residuals vs fitted
abline(h=0)

#graph.avgdeg.nb2.f <- fortify(graph.avgdeg.nb2)

#ggplot(graph.avgdeg.nb2.f, aes(.fitted,.resid)) + 
#  geom_point() +
#  geom_hline(yintercept=0)

#temp <- graphics_avgdeg

temp$fitted <- fitted(graph.bc.nb.full.int) 
plot(temp$fitted, jitter(temp$Response,0.1)) #fitted vs observed
abline(0,1)

#ggplot(graph.avgdeg.nb2.f, aes(.fitted,Response)) + 
#  geom_point() +
#  geom_abline(aes(slope = 1, intercept = 0))


```

```{r, cache=TRUE, eval=FALSE}

# Confidence Intervals, using coefficients

(est <- cbind(Estimate = coef(graph.avgdeg.nb.full.int), confint(graph.avgdeg.nb.full.int)))

# exponentiate model to look at incident rate ratios instead of coefficients

exp(est)

```

```{r, eval=FALSE}

# predictions

# model: Response ~ Dataset + TaskOrder + Demo.dailytech_SmartPhone + Dataset:TaskOrder + TaskOrder:Demo.dailytech_SmartPhone + Dataset:Demo.dailytech_SmartPhone + (1 | Demo.ResponseID)

newdata1 <- data.frame(Demo.dailytech_SmartPhone = rep(mean(temp$Demo.dailytech_SmartPhone),54), 
                       Dataset = factor(rep(c(1,3,5,7,8,9),9), levels = levels(temp$Dataset),ordered = TRUE),
                       TaskOrder = rep(1:9,6),
                       Demo.ResponseID = sample(temp$Demo.ResponseID,54))
newdata1$phat <- predict(graph.avgdeg.nb.full.int, newdata1, type = "response")
#newdata1

newdata2 <- data.frame(
  Demo.dailytech_SmartPhone = rep(seq(from = min(temp$Demo.dailytech_SmartPhone), to = max(temp$Demo.dailytech_SmartPhone), length.out = 100), 6),
  Dataset = factor(rep(c(1,3,5,7,8,9), each = 100), levels = levels(temp$Dataset),ordered = TRUE),
  TaskOrder = rep(1:9,len=600),
  Demo.ResponseID = sample(temp$Demo.ResponseID,600)
  )

#predict(graph.avgdeg.nb.full.int, newdata2, type = "link", se.fit=TRUE)
newdata2 <- cbind(newdata2, predict(graph.avgdeg.nb.full.int, newdata2, type = "link", se.fit=TRUE))

# not sure about this; asking for "fit", but that's not recognized. should the new column be called "fit"? what about se.fit?

#newdata2 <- within(newdata2, {
#  Response <- exp(fit)
#  LL <- exp(fit - 1.96 * se.fit)
#  UL <- exp(fit + 1.96 * se.fit)
#})

#ggplot(newdata2, aes(math, DaysAbsent)) +
#  geom_ribbon(aes(ymin = LL, ymax = UL, fill = prog), alpha = .25) +
#  geom_line(aes(colour = prog), size = 2) +
#  labs(x = "Math Score", y = "Predicted Days Absent")

# note on negative binomial:

# TO DO : If the data generating process does not allow for any 0s (such as the number of days spent in the hospital), then a zero-truncated model may be more appropriate.

# TO DO : Count data often have an exposure variable, which indicates the number of times the event could have happened (i.e. a max). This variable should be incorporated into your negative binomial regression model with the use of the offset option. See the glm documentation for details.  (so, that would make sense for click data???)

# other info:
# Cameron, A. C. and Trivedi, P. K. 1998. Regression Analysis of Count Data. New York: Cambridge Press.
# Dupont, W. D. 2002. Statistical Modeling for Biomedical Researchers: A Simple Introduction to the Analysis of Complex Data. New York: Cambridge Press.

```

### Select Highest Degree Node

#### Negative binomial model for click questions Node Rank

Ranks are like count data, in that they are nonnegative integers, so using a negative binomial distribution to model. Negative binomial is especially useful for over-dispersed data - data where the conditional variances exceed conditional means. 

```{r}

# https://stats.idre.ucla.edu/r/dae/negative-binomial-regression/ for non-mixed version

# Test for overdispersion

with(graphics_clickhighdeg, tapply(NodeRank, Condition, function(x) {
    sprintf("M (SD) = %1.2f (%1.2f)", mean(x), sd(x))
}))

# variances in each condition (except Control) are larger than means in the conditions

```


```{r, cache=TRUE, eval=FALSE}



graph.clickhd.nb.null <- glmer.nb(NodeRank ~ (1|Demo.ResponseID), data=graphics_clickhighdeg, verbose=TRUE)

graph.clickhd.nb <- glmer.nb(NodeRank ~ Condition + (1|Demo.ResponseID), data=graphics_clickhighdeg, verbose=TRUE)

summary(graph.clickhd.nb)

anova(graph.clickhd.nb, graph.clickhd.nb.null)

# model is not significantly different from null model (p=0.5654), so Condition isn't a
# significant predictor

graph.clickhd.nb <- glmer.nb(NodeRank ~ factor(Ctrl_dummy) + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg, verbose=TRUE)

summary(graph.clickhd.nb)

anova(graph.clickhd.nb, graph.clickhd.nb.null)

# Ctrl_dummy is not significant

graph.clickhd.nb <- glmer.nb(NodeRank ~ ConditionPhrasing + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg, verbose=TRUE)

summary(graph.clickhd.nb)

anova(graph.clickhd.nb, graph.clickhd.nb.null)

# ConditionPhrasing is not significant

graph.clickhd.nb <- glmer.nb(NodeRank ~ ConditionPhrasing + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg %>% filter(Condition %in% c("Ctrl","Phr")), verbose=TRUE)

summary(graph.clickhd.nb)

graph.clickhd.nb.null.2 <- update(graph.clickhd.nb, . ~ . - ConditionPhrasing)

anova(graph.clickhd.nb, graph.clickhd.nb.null.2)

# ConditionPhrasing is not significant


graph.clickhd.nb <- glmer.nb(NodeRank ~ ConditionGraphics + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg, verbose=TRUE)

summary(graph.clickhd.nb)

anova(graph.clickhd.nb, graph.clickhd.nb.null)

# ConditionGraphics is not significant


graph.clickhd.nb.dataset <- glmer.nb(NodeRank ~ Dataset + (1|Demo.ResponseID), data=graphics_clickhighdeg, verbose=TRUE)

summary(graph.clickhd.nb.dataset)

anova(graph.clickhd.nb.dataset, graph.clickhd.nb.null)

# model is significantly different from null model (p < 2.2e-16)

graph.clickhd.nb <- glmer.nb(NodeRank ~ DatasetOrder + (1|Demo.ResponseID), data=graphics_clickhighdeg, verbose=TRUE)

summary(graph.clickhd.nb)

anova(graph.clickhd.nb, graph.clickhd.nb.null)

# DatasetOrder is not significant

#graph.clickhd.nb <- glmer.nb(NodeRank ~ DatasetDuration + (1|Demo.ResponseID), data=graphics_clickhighdeg %>% filter(!is.na(DatasetDuration)), verbose=TRUE)

# major error: PIRLS step-halvings failed to reduce deviance in pwrssUpdate; rescale data

graphics_clickhighdeg.CS <- graphics_clickhighdeg %>% mutate(DatasetDuration=scale(DatasetDuration))

graph.clickhd.nb <- glmer.nb(NodeRank ~ DatasetDuration + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg.CS %>% filter(!is.na(DatasetDuration)), verbose=TRUE)

summary(graph.clickhd.nb)

graph.clickhd.nb.null2 <- update(graph.clickhd.nb, . ~ . - DatasetDuration)

anova(graph.clickhd.nb, graph.clickhd.nb.null2)

# DatasetDuration is not significant 

graph.clickhd.nb <- glmer.nb(NodeRank ~ TaskOrder + (1|Demo.ResponseID), data=graphics_clickhighdeg, verbose=TRUE)

summary(graph.clickhd.nb)

anova(graph.clickhd.nb, graph.clickhd.nb.null)

# TaskOrder is not significant

#graph.clickhd.nb <- glmer.nb(NodeRank ~ QuestionOrder + (1|Demo.ResponseID), data=graphics_clickhighdeg, verbose=TRUE)

# warnings about rescaling variables

graphics_clickhighdeg.CS <- graphics_clickhighdeg %>% mutate(QuestionOrder=scale(QuestionOrder))

graph.clickhd.nb <- glmer.nb(NodeRank ~ QuestionOrder + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg.CS, verbose=TRUE)

summary(graph.clickhd.nb)

graph.clickhd.nb.null2 <- update(graph.clickhd.nb, . ~ . - QuestionOrder)

anova(graph.clickhd.nb, graph.clickhd.nb.null2)

# QuestionOrder is not significant


#graph.clickhd.nb <- glmer.nb(NodeRank ~ CorrectAnswer + (1|Demo.ResponseID), data=graphics_clickhighdeg, verbose=TRUE)

# error about rescaling

graphics_clickhighdeg.CS <- graphics_clickhighdeg %>% mutate(CorrectAnswer=scale(CorrectAnswer))

graph.clickhd.nb.correct <- glmer.nb(NodeRank ~ CorrectAnswer + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg.CS, verbose=TRUE)

summary(graph.clickhd.nb.correct)

graph.clickhd.nb.null2 <- update(graph.clickhd.nb.correct, . ~ . - CorrectAnswer)

anova(graph.clickhd.nb.correct, graph.clickhd.nb.null2)

# CorrectAnswer is significant (p=4.931e-13)

#graph.clickhd.nb <- glmer.nb(NodeRank ~ Stats.Q_TotalDuration + (1|Demo.ResponseID), data=graphics_clickhighdeg, verbose=TRUE)

# warnings about rescaling variables

graphics_clickhighdeg.CS <- graphics_clickhighdeg %>% mutate(Stats.Q_TotalDuration=scale(Stats.Q_TotalDuration))

graph.clickhd.nb <- glmer.nb(NodeRank ~ Stats.Q_TotalDuration + (1|Demo.ResponseID), data=graphics_clickhighdeg.CS, verbose=TRUE, control=glmerControl(optimizer = "nlminbw"))

summary(graph.clickhd.nb)

graph.clickhd.nb.null2 <- update(graph.clickhd.nb, . ~ . - Stats.Q_TotalDuration)

anova(graph.clickhd.nb, graph.clickhd.nb.null2)

# Stats.Q_TotalDuration is not significant


graph.clickhd.nb <- glmer.nb(NodeRank ~ Stats.OperatingSystem + (1|Demo.ResponseID), data=graphics_clickhighdeg, verbose=TRUE, control=glmerControl(optimizer = "bobyqa"))
# very slooooooow, but no errors

summary(graph.clickhd.nb) # nothing significant

anova(graph.clickhd.nb, graph.clickhd.nb.null)

# Stats.OperatingSystems is not significant

graph.clickhd.nb <- glmer.nb(NodeRank ~ Stats.OperatingSystemCombined + (1|Demo.ResponseID), data=graphics_clickhighdeg, verbose=TRUE, control=glmerControl(optimizer = "bobyqa"))

summary(graph.clickhd.nb) # nothing significant

anova(graph.clickhd.nb, graph.clickhd.nb.null)

# Stats.OperatingSystemCombined is not significant

graph.clickhd.nb <- glmer.nb(NodeRank ~ Stats.OperatingSystemCombined2 + (1|Demo.ResponseID), data=graphics_clickhighdeg, verbose=TRUE, control=glmerControl(optimizer = "bobyqa"))

summary(graph.clickhd.nb)

anova(graph.clickhd.nb, graph.clickhd.nb.null)

# Stats.OperatingSystemCombined2 is not significant

graph.clickhd.nb <- glmer.nb(NodeRank ~ Stats.OperatingSystemCombined3 + (1|Demo.ResponseID), data=graphics_clickhighdeg, verbose=TRUE, control=glmerControl(optimizer = "bobyqa"))

summary(graph.clickhd.nb)

anova(graph.clickhd.nb, graph.clickhd.nb.null)

# Stats.OperatingSystemCombined3 is not significant

graph.clickhd.nb <- glmer.nb(NodeRank ~ Stats.OperatingSystemCombined4 + (1|Demo.ResponseID), data=graphics_clickhighdeg, verbose=TRUE, control=glmerControl(optimizer = "bobyqa"))

summary(graph.clickhd.nb)

anova(graph.clickhd.nb, graph.clickhd.nb.null)

# Stats.OperatingSystemCombined4 is not significant

graph.clickhd.nb <- glmer.nb(NodeRank ~ Stats.OperatingSystemCombined5 + (1|Demo.ResponseID), data=graphics_clickhighdeg, verbose=TRUE, control=glmerControl(optimizer = "bobyqa"))

summary(graph.clickhd.nb)

anova(graph.clickhd.nb, graph.clickhd.nb.null)

# Stats.OperatingSystemCombined5 is not significant

graph.clickhd.nb <- glmer.nb(NodeRank ~ Stats.OperatingSystemWindows + (1|Demo.ResponseID), data=graphics_clickhighdeg, verbose=TRUE, control=glmerControl(optimizer = "bobyqa"))

summary(graph.clickhd.nb)

anova(graph.clickhd.nb, graph.clickhd.nb.null)

# Stats.OperatingSystemWindows is not significant

graph.clickhd.nb <- glmer.nb(NodeRank ~ Stats.OperatingSystemMacintosh + (1|Demo.ResponseID), data=graphics_clickhighdeg, verbose=TRUE, control=glmerControl(optimizer = "bobyqa"))

summary(graph.clickhd.nb)

anova(graph.clickhd.nb, graph.clickhd.nb.null)

# Stats.OperatingSystemMacintosh is not significant

graph.clickhd.nb <- glmer.nb(NodeRank ~ Stats.OperatingSystemAndroid + (1|Demo.ResponseID), data=graphics_clickhighdeg, verbose=TRUE, control=glmerControl(optimizer = "bobyqa"))

summary(graph.clickhd.nb)

anova(graph.clickhd.nb, graph.clickhd.nb.null)

# Stats.OperatingSystemAndroid is not significant

graph.clickhd.nb <- glmer.nb(NodeRank ~ Stats.OperatingSystemiPhone + (1|Demo.ResponseID), data=graphics_clickhighdeg, verbose=TRUE, control=glmerControl(optimizer = "bobyqa"))

summary(graph.clickhd.nb)

anova(graph.clickhd.nb, graph.clickhd.nb.null)

# Stats.OperatingSystemiPhone is not significant


#graph.clickhd.nb <- glmer.nb(NodeRank ~ StatsNumPixels + (1|Demo.ResponseID), data=graphics_clickhighdeg, verbose=TRUE)

# need to rescale

graphics_clickhighdeg.CS <- graphics_clickhighdeg %>% mutate(StatsNumPixels=scale(StatsNumPixels))

graph.clickhd.nb <- glmer.nb(NodeRank ~ StatsNumPixels + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg.CS, verbose=TRUE, 
                        control=glmerControl(optimizer = "nlminbw"))

summary(graph.clickhd.nb)

graph.clickhd.nb.null2 <- update(graph.clickhd.nb, . ~ . - StatsNumPixels)

anova(graph.clickhd.nb, graph.clickhd.nb.null2)

# StatsNumPixels not significant

#graph.clickhd.nb <- glmer.nb(NodeRank ~ Demo.age + (1|Demo.ResponseID), data=graphics_clickhighdeg %>% filter(!is.na(Demo.age)), verbose=TRUE)

# need to rescale

graphics_clickhighdeg.CS <- graphics_clickhighdeg %>% mutate(Demo.age=scale(Demo.age))

graph.clickhd.nb <- glmer.nb(NodeRank ~ Demo.age + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg.CS %>% filter(!is.na(Demo.age)), verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))


summary(graph.clickhd.nb)

graph.clickhd.nb.null2 <- update(graph.clickhd.nb, . ~ . - Demo.age)

anova(graph.clickhd.nb, graph.clickhd.nb.null2)

# Demo.age is not significant

graph.clickhd.nb <- glmer.nb(NodeRank ~ Demo.gender + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg %>% filter(!is.na(Demo.gender)), verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))

summary(graph.clickhd.nb)

graph.clickhd.nb.null.2 <- update(graph.clickhd.nb, . ~ . - Demo.gender)

anova(graph.clickhd.nb, graph.clickhd.nb.null.2)

# Demo.gender is not significant 

graph.clickhd.nb <- glmer.nb(NodeRank ~ Demo.lang + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg %>% filter(!is.na(Demo.lang)), verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))

summary(graph.clickhd.nb)

graph.clickhd.nb.null.2 <- update(graph.clickhd.nb, . ~ . - Demo.lang)

anova(graph.clickhd.nb, graph.clickhd.nb.null.2)

# Demo.lang is not a significant predictor

graph.clickhd.nb <- glmer.nb(NodeRank ~ Demo.educ + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg %>% filter(!is.na(Demo.educ)), verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))

summary(graph.clickhd.nb)

graph.clickhd.nb.null.2 <- update(graph.clickhd.nb, . ~ . - Demo.educ)

anova(graph.clickhd.nb, graph.clickhd.nb.null.2)

# Demo.educ is not significant

graph.clickhd.nb <- glmer.nb(NodeRank ~ Demo.acfield + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg %>% filter(!is.na(Demo.acfield)), verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))
# tons of categories, very slow

summary(graph.clickhd.nb)

# many categories significantly different from Anthropology:
# ***: Business
# **: Arts, Computer sciences, Economics, Information science, Law, Linguistics, 
#     Medicine, Other, Political science, Skipped, Sociology
# *: Architecture and design, Biology, Education, Engineering, History, Journalism, 
#    media studies and communication, Languages, Library and museum studies, Literature, 
#    Mathematics, Philosophy, Psychology, Public administration

graph.clickhd.nb.null.2 <- update(graph.clickhd.nb, . ~ . - Demo.acfield)

anova(graph.clickhd.nb, graph.clickhd.nb.null.2)

# not significant

graph.clickhd.nb <- glmer.nb(NodeRank ~ Demo.acfieldGrouped + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg %>% filter(!is.na(Demo.acfieldGrouped)), verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))

summary(graph.clickhd.nb)

graph.clickhd.nb.null.2 <- update(graph.clickhd.nb, . ~ . - Demo.acfieldGrouped)

anova(graph.clickhd.nb, graph.clickhd.nb.null.2)

# Demo.acfieldGrouped is not significant

graph.clickhd.nb <- glmer.nb(NodeRank ~ Demo.acfieldGrouped2 + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg %>% filter(!is.na(Demo.acfieldGrouped2)), verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))

summary(graph.clickhd.nb)

graph.clickhd.nb.null.2 <- update(graph.clickhd.nb, . ~ . - Demo.acfieldGrouped2)

anova(graph.clickhd.nb, graph.clickhd.nb.null.2)

# Demo.acfieldGrouped2 is not significant

graph.clickhd.nb.acfield3 <- glmer.nb(NodeRank ~ Demo.acfieldGrouped3 + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg %>% filter(!is.na(Demo.acfieldGrouped3)), verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))

summary(graph.clickhd.nb.acfield3)

graph.clickhd.nb.null.2 <- update(graph.clickhd.nb.acfield3, . ~ . - Demo.acfieldGrouped3)

anova(graph.clickhd.nb.acfield3, graph.clickhd.nb.null.2)

# Demo.acfieldGrouped3 (made up of ** and *** fields from clickhd.nb - Demo.acfield) is significant

graph.clickhd.nb <- glmer.nb(NodeRank ~ Demo.dailytech_Computer + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg %>% filter(!is.na(Demo.dailytech_Computer)), verbose=TRUE)

summary(graph.clickhd.nb)

# almost significant

graph.clickhd.nb.null.2 <- update(graph.clickhd.nb, . ~ . - Demo.dailytech_Computer)

anova(graph.clickhd.nb, graph.clickhd.nb.null.2)

# not significant

graph.clickhd.nb <- glmer.nb(NodeRank ~ Demo.dailytech_Tablet + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg %>% filter(!is.na(Demo.dailytech_Tablet)), verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))

summary(graph.clickhd.nb)

graph.clickhd.nb.null.2 <- update(graph.clickhd.nb, . ~ . - Demo.dailytech_Tablet)

anova(graph.clickhd.nb, graph.clickhd.nb.null.2)

# almost significant (p=0.06001)

graph.clickhd.nb.SP <- glmer.nb(NodeRank ~ Demo.dailytech_SmartPhone + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg %>% filter(!is.na(Demo.dailytech_SmartPhone)), verbose=TRUE)

summary(graph.clickhd.nb.SP)

graph.clickhd.nb.null.2 <- update(graph.clickhd.nb.SP, . ~ . - Demo.dailytech_SmartPhone)

anova(graph.clickhd.nb.SP, graph.clickhd.nb.null.2)

# significant (p = 0.008337)

graph.clickhd.nb <- glmer.nb(NodeRank ~ Demo.weeklygaming + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg %>% filter(!is.na(Demo.weeklygaming)), verbose=TRUE)

summary(graph.clickhd.nb)

graph.clickhd.nb.null.2 <- update(graph.clickhd.nb, . ~ . - Demo.weeklygaming)

anova(graph.clickhd.nb, graph.clickhd.nb.null.2)

# not significant

graph.clickhd.nb <- glmer.nb(NodeRank ~ Demo.expdataanal + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg %>% filter(!is.na(Demo.expdataanal)), verbose=TRUE)

summary(graph.clickhd.nb)

graph.clickhd.nb.null.2 <- update(graph.clickhd.nb, . ~ . - Demo.expdataanal)

anova(graph.clickhd.nb, graph.clickhd.nb.null.2)

# not significant

graph.clickhd.nb <- glmer.nb(NodeRank ~ Demo.expdatavis + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg %>% filter(!is.na(Demo.expdatavis)), verbose=TRUE)

summary(graph.clickhd.nb)

graph.clickhd.nb.null.2 <- update(graph.clickhd.nb, . ~ . - Demo.expdatavis)

anova(graph.clickhd.nb, graph.clickhd.nb.null.2)

# not significant

graph.clickhd.nb <- glmer.nb(NodeRank ~ Demo.expreadnetvis + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg %>% filter(!is.na(Demo.expreadnetvis)), verbose=TRUE)

summary(graph.clickhd.nb)

graph.clickhd.nb.null.2 <- update(graph.clickhd.nb, . ~ . - Demo.expreadnetvis)

anova(graph.clickhd.nb, graph.clickhd.nb.null.2)

# not significant

graph.clickhd.nb <- glmer.nb(NodeRank ~ Demo.expcreatenetvis + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg %>% filter(!is.na(Demo.expcreatenetvis)), verbose=TRUE)

summary(graph.clickhd.nb)

graph.clickhd.nb.null.2 <- update(graph.clickhd.nb, . ~ . - Demo.expcreatenetvis)

anova(graph.clickhd.nb, graph.clickhd.nb.null.2)

# not significant

graph.clickhd.nb.avgdeg <- glmer.nb(NodeRank ~ AvgDeg + (1|Demo.ResponseID), 
                               data=graphics_clickhighdeg, verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))

summary(graph.clickhd.nb.avgdeg)

anova(graph.clickhd.nb.avgdeg, graph.clickhd.nb.null)

# AvgDeg is marginally significant (p < 0.02327)

graph.clickhd.nb <- glmer.nb(NodeRank ~ Density + (1|Demo.ResponseID), 
                                data=graphics_clickhighdeg, verbose=TRUE)

summary(graph.clickhd.nb)

anova(graph.clickhd.nb, graph.clickhd.nb.null)

# Density is not significant

#graph.clickhd.nb.largeclust <- glmer.nb(NodeRank ~ LargeClust1 + (1|Demo.ResponseID), 
#                                   data=graphics_clickhighdeg, verbose=TRUE)

# need to rescale

graphics_clickhighdeg.CS <- graphics_clickhighdeg %>% mutate(LargeClust1=scale(LargeClust1))

graph.clickhd.nb <- glmer.nb(NodeRank ~ LargeClust1 + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg.CS, verbose=TRUE)

summary(graph.clickhd.nb)

graph.clickhd.nb.null.2 <- update(graph.clickhd.nb, . ~ . - LargeClust1)

anova(graph.clickhd.nb, graph.clickhd.nb.null.2)

# LargeClust1 is not significant

graph.clickhd.nb <- glmer.nb(NodeRank ~ Modularity + (1|Demo.ResponseID), 
                            data=graphics_clickhighdeg, verbose=TRUE)

summary(graph.clickhd.nb)

anova(graph.clickhd.nb, graph.clickhd.nb.null)

# Modularity is not significant

graph.clickhd.nb.numclust <- glmer.nb(NodeRank ~ NumClust + (1|Demo.ResponseID), 
                                 data=graphics_clickhighdeg, verbose=TRUE, 
                        control=glmerControl(optimizer = "bobyqa"))

summary(graph.clickhd.nb.numclust)

anova(graph.clickhd.nb.numclust, graph.clickhd.nb.null)

# NumClust is significant (p = 0.0008861)

#graph.clickhd.nb <- glmer.nb(NodeRank ~ NumHighDegree + (1|Demo.ResponseID), 
#                        data=graphics_clickhighdeg, verbose=TRUE)

# need to rescale

graphics_clickhighdeg.CS <- graphics_clickhighdeg %>% mutate(NumHighDegree=scale(NumHighDegree))

graph.clickhd.nb.numhighdeg <- glmer.nb(NodeRank ~ NumHighDegree + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg.CS, verbose=TRUE)

summary(graph.clickhd.nb.numhighdeg)

graph.clickhd.nb.null.2 <- update(graph.clickhd.nb.numhighdeg, . ~ . - NumHighDegree)

anova(graph.clickhd.nb.numhighdeg, graph.clickhd.nb.null.2)

# NumHighDegree is significant (p=4.931e-13)

#graph.clickhd.nb.numlinks <- glmer.nb(NodeRank ~ NumLinks + (1|Demo.ResponseID), 
#                                 data=graphics_clickhighdeg, verbose=TRUE)

# need to rescale

graphics_clickhighdeg.CS <- graphics_clickhighdeg %>% mutate(NumLinks=scale(NumLinks))

graph.clickhd.nb <- glmer.nb(NodeRank ~ NumLinks + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg.CS, verbose=TRUE)

summary(graph.clickhd.nb)

graph.clickhd.nb.null.2 <- update(graph.clickhd.nb, . ~ . - NumLinks)

anova(graph.clickhd.nb, graph.clickhd.nb.null.2)

# NumLinks is barely not significant (p=0.05679)

#graph.clickhd.nb.numnodes <- glmer.nb(NodeRank ~ NumNodes + (1|Demo.ResponseID), 
#                                 data=graphics_clickhighdeg, verbose=TRUE)

# need to rescale

graphics_clickhighdeg.CS <- graphics_clickhighdeg %>% mutate(NumNodes=scale(NumNodes))

graph.clickhd.nb <- glmer.nb(NodeRank ~ NumNodes + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg.CS, verbose=TRUE)

summary(graph.clickhd.nb)

graph.clickhd.nb.null.2 <- update(graph.clickhd.nb, . ~ . - NumNodes)

anova(graph.clickhd.nb, graph.clickhd.nb.null.2)

# NumNodes is barely not significant (p=0.07374)

#graph.clickhd.nb <- glmer.nb(NodeRank ~ NumNodesClust1 + (1|Demo.ResponseID), 
#                        data=graphics_clickhighdeg, verbose=TRUE)

# need to rescale

graphics_clickhighdeg.CS <- graphics_clickhighdeg %>% mutate(NumNodesClust1=scale(NumNodesClust1))

graph.clickhd.nb.numnodesclust1 <- glmer.nb(NodeRank ~ NumNodesClust1 + (1|Demo.ResponseID), 
                        data=graphics_clickhighdeg.CS, verbose=TRUE)

summary(graph.clickhd.nb.numnodesclust1)

graph.clickhd.nb.null.2 <- update(graph.clickhd.nb.numnodesclust1, . ~ . - NumNodesClust1)

anova(graph.clickhd.nb.numnodesclust1, graph.clickhd.nb.null.2)

# NumNodesClust1 is significant (p=0.008985)
```

```{r}

#---------------------------------
# Multiple predictors
#---------------------------------

temp <- graphics_clickhighdeg %>% dplyr::select(Demo.ResponseID, NodeRank, Dataset, CorrectAnswer, Demo.acfieldGrouped3, Demo.dailytech_SmartPhone, AvgDeg, NumClust, NumHighDegree, NumNodesClust1) %>% drop_na()

#temp <- temp %>% mutate(Stats.Q_TotalDuration=scale(Stats.Q_TotalDuration))

graph.clickhd.nb.full <- glmer.nb(NodeRank ~ Dataset +
                                    Demo.acfieldGrouped3 + Demo.dailytech_SmartPhone +
                                    (1|Demo.ResponseID),
                                  data=temp, verbose=TRUE,
                                  control=glmerControl(optimizer = "bobyqa"))

# not every dataset is significant; should i be combining? TO DO

summary(graph.clickhd.nb.full)
# still significant - Dataset, Demo.acfieldGrouped3, Demo.dailytech_SmartPhone
```

```{r, eval=FALSE}
#---------------------------------
# Interactions
#---------------------------------

graph.clickhd.nb.full.int <- glmer.nb(NodeRank ~ Dataset +
                                        Demo.acfieldGrouped3 + Demo.dailytech_SmartPhone +
                                        Demo.acfieldGrouped3:Demo.dailytech_SmartPhone +
                                        (1|Demo.ResponseID),
                                      data=temp, verbose=TRUE,
                                      control=glmerControl(optimizer = "bobyqa"))

summary(graph.clickhd.nb.full.int)

anova(graph.clickhd.nb.full, graph.clickhd.nb.full.int)

# no significant interactions

```


```{r}

graph.clickhd.nb.full.f <- fortify(graph.clickhd.nb.full)

ggplot(graph.clickhd.nb.full.f, aes(.fitted,.resid)) + 
  geom_point() +
  geom_hline(yintercept=0)

ggplot(graph.clickhd.nb.full.f, aes(.resid)) +
  geom_histogram()

# not *quite* normally distributed...  but not too skewed?

ggplot(graph.clickhd.nb.full.f, aes(.fitted,NodeRank)) + 
  geom_point() +
  geom_hline(yintercept=0) +
  scale_y_log10()

ggplot(graph.clickhd.nb.full.f, aes(.fitted,NodeRank, color=Dataset)) + 
  geom_point() +
  geom_hline(yintercept=0) +
  scale_y_log10() +
  scale_color_brewer(palette = "Dark2")

ggplot(graph.clickhd.nb.full.f, aes(.fitted,NodeRank)) + 
  geom_point() +
  geom_hline(yintercept=0) +
  scale_y_log10() +
  facet_wrap(~Dataset)


```



```{r}

# is negative binomial different from poisson?  if so, indicates over-dispersion is true
# and negative binomial is necessary

graph.clickhd.pois <- glmer(NodeRank ~ Dataset + Demo.acfieldGrouped3 + Demo.dailytech_SmartPhone +
                                   (1|Demo.ResponseID), data=temp, family="poisson")

pchisq(2 * (logLik(graph.clickhd.nb.full) - logLik(graph.clickhd.pois)), df=1, lower.tail = FALSE)

# value = 2.926157e-08, so keep the negative binomial

```

```{r}
# run without mixed effects to validate

m.glm <- glm.nb(NodeRank ~ Dataset + Demo.acfieldGrouped3 + Demo.dailytech_SmartPhone, 
                data=temp, trace=TRUE)
summary(m.glm)

## The neg.binomial theta parameter:
getME(graph.clickhd.nb.full, "glmer.nb.theta")

#11.58727

## mixed model has 1 additional parameter (RE variance)
stopifnot(attr(logLik(graph.clickhd.nb.full),"df")==attr(logLik(m.glm),"df")+1) # not sure what this does

anova(graph.clickhd.nb.full,m.glm) # can I use anova to compare mixed and fixed effects?
# p < 5.213e-09, so definitely random effects

plot(graph.clickhd.nb.full, resid(.) ~ NodeRank)# works, as long as data 'dd' is found


# TO DO : check if this is all right

```

```{r}

par(mfrow=c(2,2))
qqnorm(resid(graph.clickhd.nb.full), main="normal qq-plot, residuals")
qqline(resid(graph.clickhd.nb.full))

qqnorm(ranef(graph.clickhd.nb.full)$Demo.ResponseID[,1])
qqline(ranef(graph.clickhd.nb.full)$Demo.ResponseID[,1])


plot(fitted(graph.clickhd.nb.full), resid(graph.clickhd.nb.full)) #residuals vs fitted
abline(h=0)

#graph.avgdeg.nb2.f <- fortify(graph.avgdeg.nb2)

#ggplot(graph.avgdeg.nb2.f, aes(.fitted,.resid)) + 
#  geom_point() +
#  geom_hline(yintercept=0)

#temp <- graphics_avgdeg

temp$fitted <- fitted(graph.clickhd.nb.full) 
plot(temp$fitted, jitter(temp$Response,0.1)) #fitted vs observed
abline(0,1)

#ggplot(graph.avgdeg.nb2.f, aes(.fitted,Response)) + 
#  geom_point() +
#  geom_abline(aes(slope = 1, intercept = 0))


```

```{r, cache=TRUE, eval=FALSE}

# Confidence Intervals, using coefficients

(est <- cbind(Estimate = coef(graph.avgdeg.nb.full.int), confint(graph.avgdeg.nb.full.int)))

# exponentiate model to look at incident rate ratios instead of coefficients

exp(est)

```

```{r, eval=FALSE}

# predictions

# model: Response ~ Dataset + TaskOrder + Demo.dailytech_SmartPhone + Dataset:TaskOrder + TaskOrder:Demo.dailytech_SmartPhone + Dataset:Demo.dailytech_SmartPhone + (1 | Demo.ResponseID)

newdata1 <- data.frame(Demo.dailytech_SmartPhone = rep(mean(temp$Demo.dailytech_SmartPhone),54), 
                       Dataset = factor(rep(c(1,3,5,7,8,9),9), levels = levels(temp$Dataset),ordered = TRUE),
                       TaskOrder = rep(1:9,6),
                       Demo.ResponseID = sample(temp$Demo.ResponseID,54))
newdata1$phat <- predict(graph.avgdeg.nb.full.int, newdata1, type = "response")
#newdata1

newdata2 <- data.frame(
  Demo.dailytech_SmartPhone = rep(seq(from = min(temp$Demo.dailytech_SmartPhone), to = max(temp$Demo.dailytech_SmartPhone), length.out = 100), 6),
  Dataset = factor(rep(c(1,3,5,7,8,9), each = 100), levels = levels(temp$Dataset),ordered = TRUE),
  TaskOrder = rep(1:9,len=600),
  Demo.ResponseID = sample(temp$Demo.ResponseID,600)
  )

#predict(graph.avgdeg.nb.full.int, newdata2, type = "link", se.fit=TRUE)
newdata2 <- cbind(newdata2, predict(graph.avgdeg.nb.full.int, newdata2, type = "link", se.fit=TRUE))

# not sure about this; asking for "fit", but that's not recognized. should the new column be called "fit"? what about se.fit?

#newdata2 <- within(newdata2, {
#  Response <- exp(fit)
#  LL <- exp(fit - 1.96 * se.fit)
#  UL <- exp(fit + 1.96 * se.fit)
#})

#ggplot(newdata2, aes(math, DaysAbsent)) +
#  geom_ribbon(aes(ymin = LL, ymax = UL, fill = prog), alpha = .25) +
#  geom_line(aes(colour = prog), size = 2) +
#  labs(x = "Math Score", y = "Predicted Days Absent")

# note on negative binomial:

# TO DO : If the data generating process does not allow for any 0s (such as the number of days spent in the hospital), then a zero-truncated model may be more appropriate.

# TO DO : Count data often have an exposure variable, which indicates the number of times the event could have happened (i.e. a max). This variable should be incorporated into your negative binomial regression model with the use of the offset option. See the glm documentation for details.  (so, that would make sense for click data???)

# other info:
# Cameron, A. C. and Trivedi, P. K. 1998. Regression Analysis of Count Data. New York: Cambridge Press.
# Dupont, W. D. 2002. Statistical Modeling for Biomedical Researchers: A Simple Introduction to the Analysis of Complex Data. New York: Cambridge Press.

```



### Percentage of Nodes in Largest Cluster

#### Beta regression for percentage

TO DO: should be able to use mgcv or glmmTMB

```{r, eval = FALSE}

#bm <- gam(y~s(x0)+s(x1)+s(x2)+s(x3),family=betar(link="logit"),data=dat)
#bm
#plot(bm,pages=1)

```

```{r}

#package glmmTMB:
#glmmTMB(y ~ 1 + (1|pond), df, family=list(family="beta",link="logit"))


```


### Number of Clusters

#### lme4

```{r, cache=TRUE}

# Individual fixed effects

graph.numclust.lmer.cond <- lmer(LogError ~ Condition + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer.cond) # Color significantly different from Control

anova(graph.numclust.lmer.cond)

# Condition is significant (p=5.234e-07)

graph.numclust.lmer.phr <- lmer(LogError ~ ConditionPhrasing + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer.phr)

anova(graph.numclust.lmer.phr)

# ConditionPhrasing is significant (p=0.003226)

graph.numclust.lmer.gr <- lmer(LogError ~ ConditionGraphics + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer.gr)

anova(graph.numclust.lmer.gr)

# ConditionGraphics is significant (p=1.653e-07)

graph.numclust.lmer.col <- lmer(LogError ~ ConditionColor + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer.col)

anova(graph.numclust.lmer.col)

# ConditionColor is significant (p=2.897e-08)

graph.numclust.lmer <- lmer(LogError ~ Ctrl_dummy + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# Ctrl_dummy not significant; trying Dataset

graph.numclust.lmer.dataset <- lmer(LogError ~ Dataset + (1|Demo.ResponseID), data = graphics_numclust, REML = T)

lmsum <- summary(graph.numclust.lmer.dataset)
lmsum
#names(lmsum)

anova(graph.numclust.lmer.dataset)

# Dataset is significant (p < 2.2e-16); trying QuestionOrder

graph.numclust.lmer <- lmer(LogError ~ QuestionOrder + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# QuestionOrder is not significant; trying DatasetOrder

graph.numclust.lmer <- lmer(LogError ~ DatasetOrder + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# DatasetOrder is barely not significant (p=0.0684); trying DatasetDuration

graph.numclust.lmer <- lmer(LogError ~ DatasetDuration + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# DatasetDuration is not significant; trying DatasetStartTime

graph.numclust.lmer <- lmer(LogError ~ DatasetStartTime + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# DatasetStartTime is not significant; trying TaskOrder

graph.numclust.lmer <- lmer(LogError ~ TaskOrder + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# TaskOrder is not significant; trying CorrectAnswer

graph.numclust.lmer.correct <- lmer(LogError ~ CorrectAnswer + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer.correct)

anova(graph.numclust.lmer.correct)

# CorrectAnswer is highly significant (p = 5.251e-07); trying Underestimated

graph.numclust.lmer.underest <- lmer(LogError ~ Underestimated + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer.underest)

anova(graph.numclust.lmer.underest)

# Underestimated is highly significant (p < 2.2e-16)

graph.numclust.lmer.overest <- lmer(LogError ~ Overestimated + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer.overest)

anova(graph.numclust.lmer.overest)

# Underestimated is highly significant (p < 2.2e-16)

graph.numclust.lmer <- lmer(LogError ~ ClustConf + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# ClustConf is not significant

graph.numclust.lmer <- lmer(LogError ~ Stats.Q_TotalDuration + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# Stats.Q_TotalDuration is not significant; trying Stats.dataset_count

graph.numclust.lmer <- lmer(LogError ~ Stats.dataset_count + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# Stats.dataset_count is not significant; trying Stats.OperatingSystem

graph.numclust.lmer <- lmer(LogError ~ Stats.OperatingSystem + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer)

# Various significant categories:
# *: Android 6.0.1, CrOS x86_64 9592.96.0, Linux x86_64, Ubuntu, Windows NT 10.0
#    Windows NT 5.1, Windows NT 6.0, Windows NT 6.1

anova(graph.numclust.lmer)

# Stats.OperatingSystem is not quite significant; trying Stats.OperatingSystemCombined

graph.numclust.lmer <- lmer(LogError ~ Stats.OperatingSystemCombined + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer) # no significant categories

anova(graph.numclust.lmer)

# Stats.OperatingSystemCombined is not significant; trying Stats.OperatingSystemCombined2

graph.numclust.lmer <- lmer(LogError ~ Stats.OperatingSystemCombined2 + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# Stats.OperatingSystemCombined2 is not significant; trying Stats.OperatingSystemCombined3

graph.numclust.lmer <- lmer(LogError ~ Stats.OperatingSystemCombined3 + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer) # Windows almost significantly different from Macintosh (0.0888)

anova(graph.numclust.lmer)

# Stats.OperatingSystemCombined3 is not significant; trying Stats.OperatingSystemCombined4

graph.numclust.lmer <- lmer(LogError ~ Stats.OperatingSystemCombined4 + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# Stats.OperatingSystemCombined4 is not significant; trying Stats.OperatingSystemCombined5

graph.numclust.lmer <- lmer(LogError ~ Stats.OperatingSystemCombined5 + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# Stats.OperatingSystemCombined5 is not significant; trying Stats.OperatingSystemWindows

graph.numclust.lmer <- lmer(LogError ~ Stats.OperatingSystemWindows + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# Stats.OperatingSystemWindows is not significant; trying Stats.OperatingSystemMacintosh

graph.numclust.lmer <- lmer(LogError ~ Stats.OperatingSystemMacintosh + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# Stats.OperatingSystemMacintosh is not significant

graph.numclust.lmer.OShighsig <- lmer(LogError ~ Stats.OperatingSystemNumClust + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer.OShighsig)

anova(graph.numclust.lmer.OShighsig)

# Stats.OperatingSystemNumClust is significant (p=0.0002445); trying StatsNumPixels

graph.numclust.lmer.pixels <- lmer(LogError ~ StatsNumPixels + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer.pixels)

anova(graph.numclust.lmer.pixels)

# StatsNumPixels is significant (p=0.02508); trying Demo.age

graph.numclust.lmer <- lmer(LogError ~ Demo.age + (1|Demo.ResponseID), data=graphics_numclust %>% filter(!(is.na(Demo.age))), REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# Demo.age is not significant; trying Demo.gender

graph.numclust.lmer <- lmer(LogError ~ Demo.gender + (1|Demo.ResponseID), data=graphics_numclust %>% filter(!(is.na(Demo.gender))), REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# Demo.gender is not significant; trying Demo.lang

graph.numclust.lmer <- lmer(LogError ~ Demo.lang + (1|Demo.ResponseID), data=graphics_numclust %>% filter(!(is.na(Demo.lang))), REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# Demo.lang is not significant; trying Demo.educ

graph.numclust.lmer <- lmer(LogError ~ Demo.educ + (1|Demo.ResponseID), data=graphics_numclust %>% filter(!(is.na(Demo.educ))), REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# Demo.educ is not significant; trying Demo.acfield

graph.numclust.lmer <- lmer(LogError ~ Demo.acfield + (1|Demo.ResponseID), data=graphics_numclust %>% filter(!(is.na(Demo.acfield))), REML = T)

summary(graph.numclust.lmer) # no significant categories

anova(graph.numclust.lmer)

# Demo.acfield is not significant; trying Demo.acfieldGrouped

graph.numclust.lmer <- lmer(LogError ~ Demo.acfieldGrouped + (1|Demo.ResponseID), data=graphics_numclust %>% filter(!(is.na(Demo.acfieldGrouped))), REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# Demo.acfieldGrouped is not significant; trying Demo.dailytech_Computer

graph.numclust.lmer <- lmer(LogError ~ Demo.dailytech_Computer + (1|Demo.ResponseID), data=graphics_numclust %>% filter(!(is.na(Demo.dailytech_Computer))), REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# Demo.dailytech_Computer is not quite significant (p=0.0655); trying Demo.dailytech_Tablet

graph.numclust.lmer <- lmer(LogError ~ Demo.dailytech_Tablet + (1|Demo.ResponseID), data=graphics_numclust %>% filter(!(is.na(Demo.dailytech_Tablet))), REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# Demo.dailytech_Tablet is not significant; trying Demo.dailytech_SmartPhone

graph.numclust.lmer.SP <- lmer(LogError ~ Demo.dailytech_SmartPhone + (1|Demo.ResponseID), data=graphics_numclust %>% filter(!(is.na(Demo.dailytech_SmartPhone))), REML = T)

summary(graph.numclust.lmer.SP)

anova(graph.numclust.lmer.SP)

# Demo.dailytech_SmartPhone is significant (p=0.01925); trying Demo.weeklygaming

graph.numclust.lmer <- lmer(LogError ~ Demo.weeklygaming + (1|Demo.ResponseID), data=graphics_numclust %>% filter(!(is.na(Demo.weeklygaming))), REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# Demo.weeklygaming is not significant; trying Demo.expdataanal

graph.numclust.lmer <- lmer(LogError ~ Demo.expdataanal + (1|Demo.ResponseID), data=graphics_numclust %>% filter(!(is.na(Demo.expdataanal))), REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# Demo.expdataanal is not significant; trying Demo.expdatavis

graph.numclust.lmer <- lmer(LogError ~ Demo.expdatavis + (1|Demo.ResponseID), data=graphics_numclust %>% filter(!(is.na(Demo.expdatavis))), REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# Demo.expdatavis is not significant; trying Demo.expreadnetvis

graph.numclust.lmer.ERNV <- lmer(LogError ~ Demo.expreadnetvis + (1|Demo.ResponseID), data=graphics_numclust %>% filter(!(is.na(Demo.expreadnetvis))), REML = T)

summary(graph.numclust.lmer.ERNV) # several levels significant

anova(graph.numclust.lmer.ERNV)

# Demo.expreadnetvis is significant (p=0.000261); trying Demo.expreadnetvis.alot

graph.numclust.lmer.ERNVAL <- lmer(LogError ~ Demo.expreadnetvis.alot + (1|Demo.ResponseID), data=graphics_numclust %>% filter(!(is.na(Demo.expreadnetvis.alot))), REML = T)

summary(graph.numclust.lmer.ERNVAL)

anova(graph.numclust.lmer.ERNVAL)

# Demo.expreadnetvis.alot is significant (p=4.177e-06); trying Demo.expcreatenetvis

graph.numclust.lmer.ECNV <- lmer(LogError ~ Demo.expcreatenetvis + (1|Demo.ResponseID), data=graphics_numclust %>% filter(!(is.na(Demo.expcreatenetvis))), REML = T)

summary(graph.numclust.lmer.ECNV) # a couple significant differences

anova(graph.numclust.lmer.ECNV)

# Demo.expcreatenetvis is marginally significant (p=0.02167); trying Demo.expcreatenetvis.alot

graph.numclust.lmer.ECNVAL <- lmer(LogError ~ Demo.expcreatenetvis.alot + (1|Demo.ResponseID), data=graphics_numclust %>% filter(!(is.na(Demo.expcreatenetvis.alot))), REML = T)

summary(graph.numclust.lmer.ECNVAL)

anova(graph.numclust.lmer.ECNVAL)

# Demo.expcreatenetvis.alot is significant (p=0.002181); trying AvgDeg

graph.numclust.lmer.avgdeg <- lmer(LogError ~ AvgDeg + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer.avgdeg)

anova(graph.numclust.lmer.avgdeg)

# AvgDeg is significant (p=2.351e-10); trying Density

graph.numclust.lmer.dens <- lmer(LogError ~ Density + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer.dens)

anova(graph.numclust.lmer.dens)

# Density is significant (p=7.012e-08); trying LargeClust1

graph.numclust.lmer.lgclust <- lmer(LogError ~ LargeClust1 + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer.lgclust)

anova(graph.numclust.lmer.lgclust)

# LargeClust1 is significant (p=6.648e-09); trying Modularity

graph.numclust.lmer.mod <- lmer(LogError ~ Modularity + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer.mod)

anova(graph.numclust.lmer.mod)

# Modularity is significant (p=6.408e-05); trying NumClust

graph.numclust.lmer.numclust <- lmer(LogError ~ NumClust + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer.numclust)

anova(graph.numclust.lmer.numclust)

# NumClust is significant (p=5.251e-07); trying NumHighDegree

graph.numclust.lmer <- lmer(LogError ~ NumHighDegree + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# NumHighDegree is not significant; trying NumLinks

graph.numclust.lmer <- lmer(LogError ~ NumLinks + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# NumLinks is not quite significant; trying NumNodes

graph.numclust.lmer.numnodes <- lmer(LogError ~ NumNodes + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer.numnodes)

anova(graph.numclust.lmer.numnodes)

# NumNodes is significant (p=0.0009575); trying NumNodesClust1

graph.numclust.lmer <- lmer(LogError ~ NumNodesClust1 + (1|Demo.ResponseID), data=graphics_numclust, REML = T)

summary(graph.numclust.lmer)

anova(graph.numclust.lmer)

# NumNodesClust1 is not significant 


```

```{r}

# combining individual predictors

temp <- graphics_numclust %>% dplyr::select(Demo.ResponseID, LogError, Condition, ConditionPhrasing, ConditionGraphics, ConditionColor, Dataset, CorrectAnswer, Underestimated, Overestimated, Stats.OperatingSystemNumClust, StatsNumPixels, Demo.dailytech_SmartPhone, Demo.expreadnetvis, Demo.expreadnetvis.alot, Demo.expcreatenetvis, Demo.expcreatenetvis.alot, AvgDeg, Density, LargeClust1, Modularity, NumClust, NumNodes) %>% drop_na()

#temp <- temp%>% mutate(StatsNumPixels=scale(StatsNumPixels))

graph.numclust.lmer.full <- lmer(LogError ~ ConditionColor + Dataset + 
                                   Overestimated + 
                                   Stats.OperatingSystemNumClust + 
                                   Demo.dailytech_SmartPhone +
                                   Demo.expreadnetvis +
                                   (1|Demo.ResponseID), data=temp, REML = T)

summary(graph.numclust.lmer.full)

anova(graph.numclust.lmer.full)

```

```{r}

# adding interactions

graph.numclust.lmer.full.int <- lmer(LogError ~ ConditionColor + Dataset + 
                                       Overestimated + 
                                       Stats.OperatingSystemNumClust + 
                                       Demo.expreadnetvis +
                                       ConditionColor:Dataset +
                                       (1|Demo.ResponseID), data=temp, REML = T)

summary(graph.numclust.lmer.full.int)

anova(graph.numclust.lmer.full.int)

graph.numclust.lmer.full.int.2 <- lmer(LogError ~ ConditionColor + Dataset + 
                                       Overestimated + 
                                       Stats.OperatingSystemNumClust + 
                                       Demo.expreadnetvis +
                                       ConditionColor:Dataset +
                                       #Dataset:Overestimated + 
                                        Dataset:Demo.expreadnetvis + 
                                       (1|Demo.ResponseID), data=temp, REML = T)

# Note: Dataset5CorrectUnder is diff from Dataset1CorrectUnder?

summary(graph.numclust.lmer.full.int.2)

anova(graph.numclust.lmer.full.int.2)

anova(graph.numclust.lmer.full.int.2,graph.numclust.lmer.full.int)

# keep int.2

graph.numclust.lmer.full.int.3 <- lmer(LogError ~ ConditionColor + Dataset + 
                                       Overestimated + 
                                       Stats.OperatingSystemNumClust + 
                                       Demo.expreadnetvis +
                                       ConditionColor:Dataset +
                                       Dataset:Overestimated + 
                                        Dataset:Demo.expreadnetvis + 
                                       (1|Demo.ResponseID), data=temp, REML = T)

summary(graph.numclust.lmer.full.int.3)

anova(graph.numclust.lmer.full.int.3)

anova(graph.numclust.lmer.full.int.2,graph.numclust.lmer.full.int.3)

# barely significant, but can keep int.3

graph.numclust.lmer.full.int.4 <- lmer(LogError ~ ConditionColor + Dataset + 
                                       Overestimated + 
                                       Stats.OperatingSystemNumClust + 
                                       Demo.expreadnetvis +
                                       ConditionColor:Dataset +
                                       Overestimated:Stats.OperatingSystemNumClust + 
                                       (1|Demo.ResponseID), data=temp, REML = T)

summary(graph.numclust.lmer.full.int.4)

anova(graph.numclust.lmer.full.int.4)

anova(graph.numclust.lmer.full.int.3,graph.numclust.lmer.full.int.4)

# keep int.3

graph.numclust.lmer.full.int.5 <- lmer(LogError ~ ConditionColor + Dataset + 
                                       Overestimated + 
                                       Stats.OperatingSystemNumClust + 
                                       Demo.expreadnetvis +
                                       ConditionColor:Dataset +
                                       Overestimated:Stats.OperatingSystemNumClust + 
                                         Overestimated:Demo.expreadnetvis +
                                       (1|Demo.ResponseID), data=temp, REML = T)

summary(graph.numclust.lmer.full.int.5)

anova(graph.numclust.lmer.full.int.5)

anova(graph.numclust.lmer.full.int.3,graph.numclust.lmer.full.int.5)

# keep int.5

graph.numclust.lmer.full.int.6 <- lmer(LogError ~ ConditionColor + Dataset + 
                                       Overestimated + 
                                       Stats.OperatingSystemNumClust + 
                                       Demo.expreadnetvis +
                                       ConditionColor:Dataset +
                                       Overestimated:Stats.OperatingSystemNumClust + 
                                         Overestimated:Demo.expreadnetvis +
                                         Stats.OperatingSystemNumClust:Demo.expreadnetvis +
                                       (1|Demo.ResponseID), data=temp, REML = T)

summary(graph.numclust.lmer.full.int.6)

anova(graph.numclust.lmer.full.int.6)

anova(graph.numclust.lmer.full.int.5,graph.numclust.lmer.full.int.6)

# keep int.6

```


```{r, cache=TRUE}

rand(graph.numclust.lmer.full.int.6)

# result shows that random effects of participant are significant (p=2e-10)

#ranef(graph.avgdeg.lmer.SP)

# displays the random effects; not that useful

# unlike lme(), lmer() doesn't allow for heterogeneous error variance structures (the "weights")


```

```{r}

plot(graph.numclust.lmer.full.int.6)

plot(graph.numclust.lmer.full.int.6, resid(., scaled=TRUE) ~ fitted(.), abline = 0)

plot(graph.numclust.lmer.full.int.6, resid(.) ~ fitted(.) | ConditionColor, abline = 0)

plot(graph.numclust.lmer.full.int.6, resid(., scaled=TRUE) ~ fitted(.) | Dataset, abline = 0)

plot(graph.numclust.lmer.full.int.6, LogError ~ fitted(.), abline = c(0,1))



```

```{r}

graph.numclust.lmer.full.int.6.f <- fortify(graph.numclust.lmer.full.int.6)

ggplot(graph.numclust.lmer.full.int.6.f, aes(.fitted,.resid)) + 
  geom_point() +
  #facet_grid(.~Sex) + 
  geom_hline(yintercept=0)

ggplot(graph.numclust.lmer.full.int.6.f, aes(.fitted,LogError)) + 
  geom_point() +
  geom_abline(aes(slope = 1, intercept = 0))


```

```{r, eval=FALSE}

# TO DO: check out interpretation for these plots??

library(lattice)

prof <-  profile(graph.numclust.lmer.full.int.6, optimizer="Nelder_Mead", which="beta_")

prof.CI <- confint(prof)

#CI2 <- confint(graph.avgdeg.lmer.SP, maxpts = 8)

xyplot(prof)

xyplot(prof, absVal = TRUE)

xyplot(prof, conf = c(0.95, 0.99), main = "95% and 99% profile() intervals")

# can also apply logProf() and varianceProf() to profile object

densityplot(prof)

splom(prof)

```

```{r, eval=FALSE}

# doesn't make sense for continuous predictor???

lsm.condition <- lsmeansLT(graph.numclust.lmer.full.int.6, test.effs = "Condition")

plot(lsm.condition)

lsm.condition.df <- as_data_frame(lsm.condition$lsmeans.table)

lsm.condition.df

lsm.task.df$Task <- factor(lsm.task.df$Task, levels=lsm.task.df %>% arrange(desc(Estimate)) %>% select(Task) %>% unlist())

lsm.task.df %>% arrange(desc(Estimate))


ggplot(lsm.task.df) +
  geom_point(aes(x=Task,y=Estimate, color=`p-value`<.01)) +
  geom_errorbar(aes(x=Task,ymax=`Upper CI`,ymin=`Lower CI`), width=.2) +
  coord_flip()

# TO DO: add a color scale so TRUE/FALSE values are always same color across all plots


```



```{r, eval=FALSE}
# old code, used lmertest, but that is deprecated
# doesn't make sense for continuous predictor???

difflsm.task <- difflsmeans(graph.numclust.lmer.full.int.6, test.effs = "ConditionColor")

plot(difflsm.task)

difflsm.task.df <- as_data_frame(difflsm.task$diffs.lsmeans.table)

difflsm.task.df

difflsm.task.df <- difflsm.task.df %>% mutate(Pair=rownames(.)) %>% separate(Pair, c("del","Pair"), sep=5) %>% select(-del) %>% separate(Pair, c("From", "del", "To"), sep="[ ]", remove=FALSE) %>% select(-del)

difflsm.task.df$Pair <- factor(difflsm.task.df$Pair, levels=difflsm.task.df %>% arrange(desc(Estimate)) %>% select(Pair) %>% unlist())

difflsm.task.df %>% arrange(desc(Estimate))

ggplot(difflsm.task.df) +
  geom_point(aes(x=Pair,y=Estimate, color=`p-value`<.01)) +
  geom_errorbar(aes(x=Pair,ymax=`Upper CI`,ymin=`Lower CI`), width=.5) +
  geom_hline(aes(yintercept=0)) +
  coord_flip()

ggplot(difflsm.task.df) +
  geom_tile(aes(x=To,y=From,fill=Estimate)) +
    scale_fill_distiller(type="div", palette=4)

ggplot(difflsm.task.df) +
  geom_count(aes(x=To,y=From,size=abs(Estimate),fill=Estimate, color=`p-value`<.01), shape=21) +
  scale_fill_distiller(type="div", palette=4) +
  scale_color_manual(values=c("grey90","black"))
  



```



### Degree of Highest Degree Node

#### lme4

```{r, cache=TRUE}

# Condition

graph.numhd.lmer.cond <- lmer(LogError ~ Condition + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer.cond) # Color and Phrasing very significant, Size not at all

anova(graph.numhd.lmer.cond)

# Condition is significant (p=2.557e-06); trying Ctrl_dummy

graph.numhd.lmer.ctrldummy <- lmer(LogError ~ Ctrl_dummy + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer.ctrldummy)

anova(graph.numhd.lmer.ctrldummy)

# Ctrl_dummy is significant (p=0.000624)

graph.numhd.lmer.condphr <- lmer(LogError ~ ConditionPhrasing + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer.condphr) 

anova(graph.numhd.lmer.condphr)

# ConditionPhrasing is significant (p=0.003696)

graph.numhd.lmer.condgr <- lmer(LogError ~ ConditionGraphics + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer.condgr) 

anova(graph.numhd.lmer.condgr)

# ConditionGraphics is significant (p=0.001828)

graph.numhd.lmer.condcol <- lmer(LogError ~ ConditionColor + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer.condcol) 

anova(graph.numhd.lmer.condcol)

# ConditionColor is significant (p=0.002186)


graph.numhd.lmer.dataset <- lmer(LogError ~ Dataset + (1|Demo.ResponseID), data = graphics_numhighdeg, REML = T)

lmsum <- summary(graph.numhd.lmer.dataset)
lmsum
#names(lmsum)

anova(graph.numhd.lmer.dataset)

# Dataset is significant (p < 1.3e-12); trying QuestionOrder

graph.numhd.lmer <- lmer(LogError ~ QuestionOrder + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer)

anova(graph.numhd.lmer)

# QuestionOrder is not significant; trying DatasetOrder

graph.numhd.lmer.dataord <- lmer(LogError ~ DatasetOrder + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer.dataord)

anova(graph.numhd.lmer.dataord)

# DatasetOrder is significant (p=0.005725); trying DatasetDuration

graph.numhd.lmer <- lmer(LogError ~ DatasetDuration + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer)

anova(graph.numhd.lmer)

# DatasetDuration is barely not significant (p=0.05675); trying DatasetStartTime

graph.numhd.lmer <- lmer(LogError ~ DatasetStartTime + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer)

anova(graph.numhd.lmer)

# DatasetStartTime is not significant; trying TaskOrder

graph.numhd.lmer <- lmer(LogError ~ TaskOrder + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer)

anova(graph.numhd.lmer)

# TaskOrder is not significant; trying CorrectAnswer

graph.numhd.lmer <- lmer(LogError ~ CorrectAnswer + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer)

anova(graph.numhd.lmer)

# CorrectAnswer is barely not significant (p = 0.05447); trying Underestimated

graph.numhd.lmer.underest <- lmer(LogError ~ Underestimated + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer.underest)

anova(graph.numhd.lmer.underest)

# Underestimated is highly significant (p = 6.661e-16); trying Overestimated

graph.numhd.lmer.overest <- lmer(LogError ~ Overestimated + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer.overest)

anova(graph.numhd.lmer.overest)

# Overestimated is highly significant (p = 1.165e); trying Stats.Q_TotalDuration

graph.numhd.lmer <- lmer(LogError ~ Stats.Q_TotalDuration + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer)

anova(graph.numhd.lmer)

# Stats.Q_TotalDuration is not significant; trying Stats.dataset_count

graph.numhd.lmer <- lmer(LogError ~ Stats.dataset_count + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer)

anova(graph.numhd.lmer)

# Stats.dataset_count is not significant; trying Stats.OperatingSystem

graph.numhd.lmer <- lmer(LogError ~ Stats.OperatingSystem + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer) # nothing significant

anova(graph.numhd.lmer)

# Stats.OperatingSystem is not significant (skipping combinations); trying StatsNumPixels

graph.numhd.lmer.pixels <- lmer(LogError ~ StatsNumPixels + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer.pixels)

anova(graph.numhd.lmer.pixels)

# StatsNumPixels is barely significant (p=0.02101); trying Demo.age

graph.numhd.lmer.age <- lmer(LogError ~ Demo.age + (1|Demo.ResponseID), data=graphics_numhighdeg %>% filter(!(is.na(Demo.age))), REML = T)

summary(graph.numhd.lmer.age)

anova(graph.numhd.lmer.age)

# Demo.age is significant (p=0.0159); trying Demo.gender

graph.numhd.lmer <- lmer(LogError ~ Demo.gender + (1|Demo.ResponseID), data=graphics_numhighdeg %>% filter(!(is.na(Demo.gender))), REML = T)

summary(graph.numhd.lmer)

anova(graph.numhd.lmer)

# Demo.gender is not significant; trying Demo.lang

graph.numhd.lmer <- lmer(LogError ~ Demo.lang + (1|Demo.ResponseID), data=graphics_numhighdeg %>% filter(!(is.na(Demo.lang))), REML = T)

summary(graph.numhd.lmer)

anova(graph.numhd.lmer)

# Demo.lang is not significant; trying Demo.educ

graph.numhd.lmer <- lmer(LogError ~ Demo.educ + (1|Demo.ResponseID), data=graphics_numhighdeg %>% filter(!(is.na(Demo.educ))), REML = T)

summary(graph.numhd.lmer)

anova(graph.numhd.lmer)

# Demo.educ is not significant; trying Demo.acfield

graph.numhd.lmer <- lmer(LogError ~ Demo.acfield + (1|Demo.ResponseID), data=graphics_numhighdeg %>% filter(!(is.na(Demo.acfield))), REML = T)

summary(graph.numhd.lmer) # nothing significant

anova(graph.numhd.lmer)

# Demo.acfield is not significant (skipping groups); trying Demo.dailytech_Computer

graph.numhd.lmer <- lmer(LogError ~ Demo.dailytech_Computer + (1|Demo.ResponseID), data=graphics_numhighdeg %>% filter(!(is.na(Demo.dailytech_Computer))), REML = T)

summary(graph.numhd.lmer)

anova(graph.numhd.lmer)

# Demo.dailytech_Computer is not significant; trying Demo.dailytech_Tablet

graph.numhd.lmer <- lmer(LogError ~ Demo.dailytech_Tablet + (1|Demo.ResponseID), data=graphics_numhighdeg %>% filter(!(is.na(Demo.dailytech_Tablet))), REML = T)

summary(graph.numhd.lmer)

anova(graph.numhd.lmer)

# Demo.dailytech_Computer is not significant; trying Demo.dailytech_SmartPhone

graph.numhd.lmer <- lmer(LogError ~ Demo.dailytech_SmartPhone + (1|Demo.ResponseID), data=graphics_numhighdeg %>% filter(!(is.na(Demo.dailytech_SmartPhone))), REML = T)

summary(graph.numhd.lmer)

anova(graph.numhd.lmer)

# Demo.dailytech_SmartPhone is not significant; trying Demo.weeklygaming

graph.numhd.lmer <- lmer(LogError ~ Demo.weeklygaming + (1|Demo.ResponseID), data=graphics_numhighdeg %>% filter(!(is.na(Demo.weeklygaming))), REML = T)

summary(graph.numhd.lmer)

anova(graph.numhd.lmer)

# Demo.weeklygaming is not significant; trying Demo.expdataanal

graph.numhd.lmer <- lmer(LogError ~ Demo.expdataanal + (1|Demo.ResponseID), data=graphics_numhighdeg %>% filter(!(is.na(Demo.expdataanal))), REML = T)

summary(graph.numhd.lmer)

anova(graph.numhd.lmer)

# Demo.expdataanal is not significant; trying Demo.expdatavis

graph.numhd.lmer <- lmer(LogError ~ Demo.expdatavis + (1|Demo.ResponseID), data=graphics_numhighdeg %>% filter(!(is.na(Demo.expdatavis))), REML = T)

summary(graph.numhd.lmer)

anova(graph.numhd.lmer)

# Demo.expdatavis is not significant; trying Demo.expreadnetvis

graph.numhd.lmer <- lmer(LogError ~ Demo.expreadnetvis + (1|Demo.ResponseID), data=graphics_numhighdeg %>% filter(!(is.na(Demo.expreadnetvis))), REML = T)

summary(graph.numhd.lmer)

anova(graph.numhd.lmer)

# Demo.expreadnetvis is not significant; trying Demo.expreadnetvis.alot

graph.numhd.lmer <- lmer(LogError ~ Demo.expreadnetvis.alot + (1|Demo.ResponseID), data=graphics_numhighdeg %>% filter(!(is.na(Demo.expreadnetvis.alot))), REML = T)

summary(graph.numhd.lmer)

anova(graph.numhd.lmer)

# Demo.expreadnetvis.alot is not significant; trying Demo.expcreatenetvis

graph.numhd.lmer <- lmer(LogError ~ Demo.expcreatenetvis + (1|Demo.ResponseID), data=graphics_numhighdeg %>% filter(!(is.na(Demo.expcreatenetvis))), REML = T)

summary(graph.numhd.lmer)

anova(graph.numhd.lmer)

# Demo.expcreatenetvis is not significant; trying Demo.expcreatenetvis.alot

graph.numhd.lmer <- lmer(LogError ~ Demo.expcreatenetvis.alot + (1|Demo.ResponseID), data=graphics_numhighdeg %>% filter(!(is.na(Demo.expcreatenetvis.alot))), REML = T)

summary(graph.numhd.lmer) # doesn't reach significance

anova(graph.numhd.lmer)

# Demo.expcreatenetvis.alot is not significant; trying AvgDeg

graph.numhd.lmer.avgdeg <- lmer(LogError ~ AvgDeg + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer.avgdeg)

anova(graph.numhd.lmer.avgdeg)

# AvgDeg is significant (p=6.871e-08); trying Density

graph.numhd.lmer.dens <- lmer(LogError ~ Density + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer.dens)

anova(graph.numhd.lmer.dens)

# Density is significant (p=1.913e-07); trying LargeClust1

graph.numhd.lmer.lgclust <- lmer(LogError ~ LargeClust1 + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer.lgclust)

anova(graph.numhd.lmer.lgclust)

# LargeClust1 is significant (p=5.644e-08); trying Modularity

graph.numhd.lmer.mod <- lmer(LogError ~ Modularity + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer.mod)

anova(graph.numhd.lmer.mod)

# Modularity is significant (p=0.000103); trying NumClust

graph.numhd.lmer.numclust <- lmer(LogError ~ NumClust + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer.numclust)

anova(graph.numhd.lmer.numclust)

# NumClust is significant (p=0.0008824); trying NumHighDegree

graph.numhd.lmer <- lmer(LogError ~ NumHighDegree + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer)

anova(graph.numhd.lmer)

# NumHighDegree is not quite significant (p=0.05447); trying NumLinks

graph.numhd.lmer <- lmer(LogError ~ NumLinks + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer)

anova(graph.numhd.lmer)

# NumLinks is not significant; trying NumNodes

graph.numhd.lmer.numnodes <- lmer(LogError ~ NumNodes + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer.numnodes)

anova(graph.numhd.lmer.numnodes)

# NumNodes is significant (p=0.0009184); trying NumNodesClust1

graph.numhd.lmer <- lmer(LogError ~ NumNodesClust1 + (1|Demo.ResponseID), data=graphics_numhighdeg, REML = T)

summary(graph.numhd.lmer)

anova(graph.numhd.lmer)

# NumNodesClust1 is not quite significant (p=0.05285); 


```

```{r}

# combinations of individual predictors

temp <- graphics_numhighdeg %>% dplyr::select(
  Demo.ResponseID, LogError, Condition, Ctrl_dummy, ConditionPhrasing, ConditionGraphics, ConditionColor, Dataset, DatasetOrder, Underestimated, Overestimated, StatsNumPixels, Demo.age, AvgDeg, Density, LargeClust1, Modularity, NumClust, NumNodes) %>% drop_na()

temp <- temp %>% mutate(StatsNumPixels=scale(StatsNumPixels))

graph.numhd.lmer.full <- lmer(LogError ~ Condition + 
                                Dataset +
                                DatasetOrder +
                                Overestimated +
                                StatsNumPixels +
                                (1|Demo.ResponseID), 
                              data=temp, REML = T)

summary(graph.numhd.lmer.full)

anova(graph.numhd.lmer.full)

```

```{r}

# interactions

graph.numhd.lmer.full.int <- lmer(LogError ~ Condition + 
                                    Dataset +
                                    DatasetOrder +
                                    Overestimated +
                                    StatsNumPixels +
                                    Condition:Dataset +
                                    (1|Demo.ResponseID), 
                                  data=temp, REML = T)

summary(graph.numhd.lmer.full.int)

anova(graph.numhd.lmer.full.int)

anova(graph.numhd.lmer.full.int,graph.numhd.lmer.full)

# definitely keep the interaction

graph.numhd.lmer.full.int.2 <- lmer(LogError ~ Condition + 
                                    Dataset +
                                    DatasetOrder +
                                    Overestimated +
                                    StatsNumPixels +
                                    Condition:Dataset +
                                      Dataset:Overestimated +
                                    (1|Demo.ResponseID), 
                                  data=temp, REML = T)

summary(graph.numhd.lmer.full.int.2)

anova(graph.numhd.lmer.full.int.2)

anova(graph.numhd.lmer.full.int.2,graph.numhd.lmer.full.int)

graph.numhd.lmer.full.int.3 <- lmer(LogError ~ Condition + 
                                    Dataset +
                                    DatasetOrder +
                                    Overestimated +
                                    StatsNumPixels +
                                    Condition:Dataset +
                                      Dataset:Overestimated +
                                      DatasetOrder:Overestimated +
                                    (1|Demo.ResponseID), 
                                  data=temp, REML = T)

summary(graph.numhd.lmer.full.int.3)

anova(graph.numhd.lmer.full.int.3)

anova(graph.numhd.lmer.full.int.3,graph.numhd.lmer.full.int.2)

# keeping graph.numhd.lmer.full.int.3

graph.numhd.lmer.full.int.4 <- lmer(LogError ~ Condition + 
                                    Dataset +
                                    Condition:Dataset +
                                      Dataset:Overestimated +
                                      DatasetOrder:Overestimated +
                                    (1|Demo.ResponseID), 
                                  data=temp, REML = T)

summary(graph.numhd.lmer.full.int.4)

anova(graph.numhd.lmer.full.int.4)

anova(graph.numhd.lmer.full.int.4, graph.numhd.lmer.full.int.3)

# no significant difference and 4 is way simpler, so keeping 4

```

```{r, cache=TRUE}

rand(graph.numhd.lmer.full.int.4)

# result shows that random effects of participant are *not* significant (p=1)

#ranef(graph.numhd.lmer.full.int.4)

# displays the random effects; not that useful

# unlike lme(), lmer() doesn't allow for heterogeneous error variance structures (the "weights")


```

```{r}

plot(graph.numhd.lmer.full.int.4)

plot(graph.numhd.lmer.full.int.4, resid(., scaled=TRUE) ~ fitted(.), abline = 0)

plot(graph.numhd.lmer.full.int.4, resid(.) ~ fitted(.) | Condition, abline = 0)

plot(graph.numhd.lmer.full.int.4, resid(., scaled=TRUE) ~ fitted(.) | Condition, abline = 0)

plot(graph.numhd.lmer.full.int.4, LogError ~ fitted(.), abline = c(0,1))



```

```{r}

graph.numhd.lmer.full.int.4.f <- fortify(graph.numhd.lmer.full.int.4)

ggplot(graph.numhd.lmer.full.int.4.f, aes(.fitted,.resid)) + 
  geom_point() +
  #facet_grid(.~Sex) + 
  geom_hline(yintercept=0)

ggplot(graph.numhd.lmer.full.int.4.f, aes(.fitted,LogError)) + 
  geom_point() +
  geom_abline(aes(slope = 1, intercept = 0))


```

```{r, eval=FALSE}

# TO DO: check out interpretation for these plots??

prof <-  profile(graph.numhd.lmer.full.int.4, optimizer="Nelder_Mead", which="beta_")

prof.CI <- confint(prof)

CI2 <- confint(graph.numhd.lmer.full.int.4, maxpts = 8)

xyplot(prof)

xyplot(prof, absVal = TRUE)

xyplot(prof, conf = c(0.95, 0.99), main = "95% and 99% profile() intervals")

# can also apply logProf() and varianceProf() to profile object

densityplot(prof)

splom(prof)

```

#### Least Squares Means

Do for each categorical predictor. Final predictors: Condition, Dataset, Condition:Dataset, Dataset:Underestimated, DatasetOrder:Underestimated

##### Condition

```{r}

# trying lmerTest::lsmeansLT

# note = lmerTest::lsmeans will only report lsmeans for factor variables and is deprecated

graph.numhd.lsmlt.cond.2 <- lsmeansLT(graph.numhd.lmer.full.int.4, test.effs = "Condition")

plot(graph.numhd.lsmlt.cond.2) # not a completely terrible style, but not sorted properly

graph.numhd.lsmlt.cond.2.df <- as_data_frame(graph.numhd.lsmlt.cond.2$lsmeans.table)

graph.numhd.lsmlt.cond.2.df

graph.numhd.lsmlt.cond.2.df$Condition <- factor(graph.numhd.lsmlt.cond.2.df$Condition, levels=graph.numhd.lsmlt.cond.2.df %>% arrange(desc(Estimate)) %>% dplyr::select(Condition) %>% unlist())

graph.numhd.lsmlt.cond.2.df %>% arrange(desc(Estimate))

graph.numhd.lsmlt.cond.2.df <- graph.numhd.lsmlt.cond.2.df %>% 
  mutate(sig.levels = factor(case_when(
    `p-value` < .0001 ~ sig.level.names[1],
    `p-value` < .001 ~ sig.level.names[2],
    `p-value` < .01 ~ sig.level.names[3],
    `p-value` < .05 ~ sig.level.names[4],
    TRUE ~ sig.level.names[5]
    )
  ,levels=sig.level.names,ordered=TRUE))

graph.numhd.lsmlt.cond.2.df

ggplot(graph.numhd.lsmlt.cond.2.df) +
  geom_errorbar(aes(x=Condition,ymax=`Upper CI`,ymin=`Lower CI`), width=.2) +
  geom_point(aes(x=Condition,y=Estimate, fill=sig.levels), shape=21, size=7) +
  scale_fill_manual("Significance Levels", values=sig.colors) +
  coord_flip()

```

```{r}

# LSMeans Difference data

graph.numhd.difflsmlt.cond <- difflsmeans(graph.numhd.lmer.full.int.4, test.effs = "Condition")

plot(graph.numhd.difflsmlt.cond)

graph.numhd.difflsmlt.cond.df <- as_data_frame(graph.numhd.difflsmlt.cond$diffs.lsmeans.table, rownames="Pair")

graph.numhd.difflsmlt.cond.df

graph.numhd.difflsmlt.cond.df <- graph.numhd.difflsmlt.cond.df %>% mutate(Pair=sub("Condition ","",Pair)) %>% separate(Pair, c("From", "del", "To"), sep="[ ]", remove=FALSE) %>% dplyr::select(-del)

copy <- graph.numhd.difflsmlt.cond.df %>% rename(From=To,To=From)

graph.numhd.difflsmlt.cond.df <- bind_rows(graph.numhd.difflsmlt.cond.df,copy)

graph.numhd.difflsmlt.cond.df$Pair <- factor(graph.numhd.difflsmlt.cond.df$Pair, levels=graph.numhd.difflsmlt.cond.df %>% arrange(desc(Estimate)) %>% dplyr::select(Pair) %>% distinct() %>% unlist())

cond.lev <- c("Ctrl","Phr","Col","Siz")

graph.numhd.difflsmlt.cond.df$From <- factor(graph.numhd.difflsmlt.cond.df$From, levels=cond.lev)
graph.numhd.difflsmlt.cond.df$To <- factor(graph.numhd.difflsmlt.cond.df$To, levels=cond.lev)

graph.numhd.difflsmlt.cond.df %>% arrange(desc(Estimate))

graph.numhd.difflsmlt.cond.df <- graph.numhd.difflsmlt.cond.df %>% 
  mutate(sig.levels = factor(case_when(
    `p-value` < .0001 ~ sig.level.names[1],
    `p-value` < .001 ~ sig.level.names[2],
    `p-value` < .01 ~ sig.level.names[3],
    `p-value` < .05 ~ sig.level.names[4],
    TRUE ~ sig.level.names[5]
    )
  ,levels=sig.level.names,ordered=TRUE))

ggplot(graph.numhd.difflsmlt.cond.df) +
  geom_errorbar(aes(x=Pair,ymax=`Upper CI`,ymin=`Lower CI`), width=.5) +
  geom_point(aes(x=Pair,y=Estimate, fill=sig.levels), shape=21, size=7) +
  scale_fill_manual("Significance Levels", values=sig.colors) +
  coord_flip()

ggplot(graph.numhd.difflsmlt.cond.df) +
  geom_errorbar(aes(x=Pair,ymax=`Upper CI`,ymin=`Lower CI`), width=.5) +
  geom_point(aes(x=Pair,y=Estimate, fill=sig.levels), shape=21, size=7) +
  geom_hline(aes(yintercept=0)) +
  scale_fill_manual("Significance Levels", values=sig.colors) +
  coord_flip()

ggplot(graph.numhd.difflsmlt.cond.df) +
  geom_tile(aes(x=To,y=ordered(From,levels=rev(cond.lev)),fill=sig.levels), color="black") +
  scale_fill_manual("Significance Levels", values=sig.colors) +
  scale_x_discrete(drop=FALSE, position = "top") +
  scale_y_discrete(drop=FALSE, name="From")

ggplot(graph.numhd.difflsmlt.cond.df) +
  geom_count(aes(x=To,y=ordered(From,levels=rev(cond.lev)),size=abs(Estimate),fill=sig.levels), shape=21, color="black") +
  scale_fill_manual("Significance Levels", values=sig.colors) +
  scale_x_discrete(drop=FALSE, position = "top") +
  scale_y_discrete(drop=FALSE, name="From")
  
```

```{r}
# trying to use emmeans package for lsmeans table

# can use ref_grid to see if emmeans is finding nestings within variables, which can cause problems(?)
# ref_grid(graph.numhd.lmer.full.int.4)
# unfortunately, considers Overestimated nested in Dataset because I didn't include 
# Overestimated as a fixed effect; can use nesting = NULL to ignore this auto-detection of nesting

# also want to check if any combination of two factors has zeroes in the cells
# with(graphics_numhighdeg, table(Dataset,Overestimated))
# ref_grid(graph.numhd.lmer.full.int.4) @ grid; .wgt. is number of observations

graph.numhd.emm.condition <- emmeans(graph.numhd.lmer.full.int.4, "Condition", nesting = NULL)
#graph.numhd.emm.condition <- emmeans(graph.numhd.lmer.full.int.4, "Condition", lmer.df = "satterthwaite")

graph.numhd.emm.condition

graph.numhd.emm.condition.df <- as.data.frame(graph.numhd.emm.condition)

graph.numhd.emm.condition.df

emmip(graph.numhd.lmer.full.int.4, ~Condition, CIs = TRUE)
emmip(graph.numhd.emm.condition, ~Condition, CIs = TRUE)
plot(graph.numhd.emm.condition)
#plot(graph.numhd.emm.condition, comparisons = TRUE)

# From: https://cran.r-project.org/web/packages/emmeans/vignettes/comparisons.html
# The blue bars are confidence intervals for the EMMs, and the red arrows are for the comparisons among them. If an arrow from one mean overlaps an arrow from another group, the difference is not significant, based on the adjust setting (which defaults to "tukey"). (Note: Don’t ever use confidence intervals for EMMs to perform comparisons; they can be very misleading.)

# TO DO : can't figure out how to extract data about the arrows in order to reproduce the graph

#xtable::xtable(graph.numhd.emm.condition)

full.cld <- cld(graph.numhd.emm.condition,
           details=TRUE,
           #alpha=0.01,
           #by="Dataset",
           #Letters="|||||||||||||||||||",
           sort=TRUE
           )
graph.numhd.emm.condition.cld <- full.cld$emmeans

graph.numhd.emm.condition.cld %>% dplyr::select(Condition,.group)

graph.numhd.emm.condition.cld

graph.numhd.emm.condition.cld$Condition <- factor(graph.numhd.emm.condition.cld$Condition, levels=graph.numhd.emm.condition.cld %>% arrange(desc(emmean)) %>% dplyr::select(Condition) %>% unlist())

graph.numhd.emm.condition.cld %>% arrange(desc(emmean))

ggplot(graph.numhd.emm.condition.cld) +
  #geom_point(aes(x=Condition,y=emmean), shape=21, size=7) +
  geom_errorbar(aes(x=Condition,ymax=upper.CL,ymin=lower.CL), width=.2) +
  geom_point(aes(x=Condition,y=emmean), size=7) +
  #scale_fill_manual("Significance Levels", values=sig.colors) +
  coord_flip()


#plot(ref_grid(graph.numhd.lmer.full.int.4), by="Condition") 
# try to figure this out? maybe only works on the interaction?

```

```{r}

graph.numhd.emm.condition.pairs <- as.data.frame(pairs(graph.numhd.emm.condition)) 
graph.numhd.emm.condition.pairs
# for some reason, full.cld$comparisons returns estimates that are all positive; 
# pairs(graph.numhd.emm.condition) has both negative and positive estimates
# and joins better to confint()

pairs.CI <- confint(pairs(graph.numhd.emm.condition))

graph.numhd.emm.condition.pairs <- full_join(graph.numhd.emm.condition.pairs, pairs.CI)

#graph.numhd.diffemm.condition <- emmeans(graph.numhd.lmer.full.int.4, pairwise ~ Condition)
#graph.numhd.diffemm.condition$contrasts
#contrast(graph.numhd.emm.condition)
#confint(graph.numhd.emm.condition)
#pairs(graph.numhd.emm.condition, details=TRUE)
#confint(contrast(graph.numhd.emm.condition))
#confint(pairs(graph.numhd.emm.condition))
#coef(pairs(graph.numhd.emm.condition))


plot(pairs(graph.numhd.emm.condition))
plot(pairs(graph.numhd.emm.condition), comparisons = TRUE)


graph.numhd.emm.condition.pairs <- graph.numhd.emm.condition.pairs %>% 
  mutate(sig.levels = factor(case_when(
    p.value < .0001 ~ sig.level.names[1],
    p.value < .001 ~ sig.level.names[2],
    p.value < .01 ~ sig.level.names[3],
    p.value < .05 ~ sig.level.names[4],
    TRUE ~ sig.level.names[5]
    )
  ,levels=sig.level.names,ordered=TRUE))

graph.numhd.emm.condition.pairs$contrast <- factor(graph.numhd.emm.condition.pairs$contrast, levels=graph.numhd.emm.condition.pairs %>% arrange(desc(estimate)) %>% dplyr::select(contrast) %>% distinct() %>% unlist())

graph.numhd.emm.condition.pairs <- graph.numhd.emm.condition.pairs %>% separate(contrast, c("From", "del", "To"), sep="[ ]", remove=FALSE)

ggplot(graph.numhd.emm.condition.pairs) +
  geom_errorbar(aes(x=contrast,ymax=upper.CL,ymin=lower.CL), width=.5) +
  geom_point(aes(x=contrast,y=estimate, fill=sig.levels), shape=21, size=7) +
  scale_fill_manual("Significance Levels", values=sig.colors) +
  coord_flip()

ggplot(graph.numhd.emm.condition.pairs) +
  geom_errorbar(aes(x=contrast,ymax=upper.CL,ymin=lower.CL), width=.5) +
  geom_point(aes(x=contrast,y=estimate, fill=sig.levels), shape=21, size=7) +
  geom_hline(aes(yintercept=0)) +
  scale_fill_manual("Significance Levels", values=sig.colors) +
  coord_flip()

```

```{r, eval=FALSE}

# try a network of the pairwise significance values?  bleh...
# using igraph

graph <- graph_from_data_frame(graph.numhd.emm.condition.pairs %>% dplyr::select(-contrast,-del), directed=TRUE)

E(graph)$width <- abs(E(graph)$estimate)*50
E(graph)$edge.color <- sig.colors[E(graph)$sig.levels]

graph

plot(graph, 
     edge.arrow.size=.5,
     vertex.frame.color="#555555")

```

```{r}

# using ggraph and tidygraph

graph <- graph_from_data_frame(graph.numhd.emm.condition.pairs %>% dplyr::select(-contrast,-del), directed=TRUE)

# plot using ggraph
ggraph(graph, layout = 'kk') +
  geom_edge_link(aes(start_cap = label_rect(node1.name),
                       end_cap = label_rect(node2.name),
                     color=factor(sig.level.names[sig.levels]),
                     edge_width=.5/sig.levels
                     ), 
                   arrow = arrow(length = unit(4, 'mm')))+
  geom_node_text(label = vertex_attr(graph,"name")) +
  scale_edge_color_manual("Significance Levels", values=sig.colors) +
  scale_edge_width_continuous(labels=rev(sig.level.names)) +
  theme_graph()

```


```{r}

copy <- graph.numhd.emm.condition.pairs %>% rename(From=To,To=From)

graph.numhd.emm.condition.pairs.compl <- bind_rows(graph.numhd.emm.condition.pairs,copy)


cond.lev <- c("Ctrl","Phr","Col","Siz")

graph.numhd.emm.condition.pairs.compl$From <- factor(graph.numhd.emm.condition.pairs.compl$From, levels=cond.lev)
graph.numhd.emm.condition.pairs.compl$To <- factor(graph.numhd.emm.condition.pairs.compl$To, levels=cond.lev)

graph.numhd.emm.condition.pairs.compl %>% arrange(desc(estimate))

ggplot(graph.numhd.emm.condition.pairs.compl) +
  geom_tile(aes(x=To,y=ordered(From,levels=rev(cond.lev)),fill=sig.levels), color="black") +
  scale_fill_manual("Significance Levels", values=sig.colors) +
  scale_x_discrete(drop=FALSE, position = "top") +
  scale_y_discrete(drop=FALSE, name="From")

ggplot(graph.numhd.emm.condition.pairs.compl) +
  geom_count(aes(x=To,y=ordered(From,levels=rev(cond.lev)),size=abs(estimate),fill=sig.levels), shape=21, color="black") +
  scale_fill_manual("Significance Levels", values=sig.colors) +
  scale_x_discrete(drop=FALSE, position = "top") +
  scale_y_discrete(drop=FALSE, name="From")

ggplot(graph.numhd.emm.condition.pairs.compl) +
  geom_tile(aes(x=To,y=ordered(From,levels=rev(cond.lev)),fill=estimate)) +
    scale_fill_distiller(type="div", palette=4)

ggplot(graph.numhd.emm.condition.pairs.compl) +
  geom_count(aes(x=To,y=ordered(From,levels=rev(cond.lev)),size=abs(estimate),fill=estimate, color=p.value<.01), shape=21) +
  scale_fill_distiller(type="div", palette=4) +
  scale_color_manual(values=c("grey90","black"))


```


##### Condition:Dataset

```{r}
#graph.numhd.diffemm.conddata <- emmeans(graph.numhd.lmer.full.int.4, pairwise ~ Dataset | Condition)

#graph.numhd.diffemm.conddata

```

### Number of Links

#### lme4

```{r, cache=TRUE}

# Condition

graph.numlinks.lmer <- lmer(LogError ~ Condition + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Condition not significant; trying Ctrl_dummy

graph.numlinks.lmer <- lmer(LogError ~ Ctrl_dummy + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Ctrl_dummy not significant; trying Dataset

graph.numlinks.lmer.dataset <- lmer(LogError ~ Dataset + (1|Demo.ResponseID), data = graphics_numlinks, REML = T)

lmsum <- summary(graph.numlinks.lmer.dataset)
lmsum
#names(lmsum)

anova(graph.numlinks.lmer.dataset)

# Dataset is significant (p < 2.2e-16); trying QuestionOrder

graph.numlinks.lmer <- lmer(LogError ~ QuestionOrder + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# QuestionOrder is not significant; trying DatasetOrder

graph.numlinks.lmer <- lmer(LogError ~ DatasetOrder + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# DatasetOrder is not significant; trying DatasetDuration

graph.numlinks.lmer <- lmer(LogError ~ DatasetDuration + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# DatasetDuration is not significant; trying DatasetStartTime

graph.numlinks.lmer <- lmer(LogError ~ DatasetStartTime + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# DatasetStartTime is not significant; trying TaskOrder

graph.numlinks.lmer <- lmer(LogError ~ TaskOrder + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# TaskOrder is not significant; trying CorrectAnswer

graph.numlinks.lmer.correct <- lmer(LogError ~ CorrectAnswer + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer.correct)

anova(graph.numlinks.lmer.correct)

# CorrectAnswer is highly significant (p = 0.0001083); trying Underestimated

graph.numlinks.lmer.underest <- lmer(LogError ~ Underestimated + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer.underest)

anova(graph.numlinks.lmer.underest)

# Underestimated is highly significant (p < 2.2e-16); trying Stats.Q_TotalDuration

graph.numlinks.lmer <- lmer(LogError ~ Stats.Q_TotalDuration + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Stats.Q_TotalDuration is barely not signficnat (p=0.05637); trying Stats.dataset_count

graph.numlinks.lmer <- lmer(LogError ~ Stats.dataset_count + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Stats.dataset_count is not signficant; trying Stats.OperatingSystem

graph.numlinks.lmer <- lmer(LogError ~ Stats.OperatingSystem + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Stats.OperatingSystem is not signficant; trying Stats.OperatingSystemCombined

graph.numlinks.lmer <- lmer(LogError ~ Stats.OperatingSystemCombined + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Stats.OperatingSystemCombined is not signficant (though Mac and Windows are almost); trying Stats.OperatingSystemCombined2

graph.numlinks.lmer <- lmer(LogError ~ Stats.OperatingSystemCombined2 + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Stats.OperatingSystemCombined2 is not signficant; trying Stats.OperatingSystemCombined3

graph.numlinks.lmer <- lmer(LogError ~ Stats.OperatingSystemCombined3 + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Stats.OperatingSystemCombined3 is not signficant; trying Stats.OperatingSystemCombined4

graph.numlinks.lmer <- lmer(LogError ~ Stats.OperatingSystemCombined4 + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Stats.OperatingSystemCombined4 is not signficant; trying Stats.OperatingSystemCombined5

graph.numlinks.lmer <- lmer(LogError ~ Stats.OperatingSystemCombined5 + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Stats.OperatingSystemCombined5 is not signficant; trying Stats.OperatingSystemWindows

graph.numlinks.lmer <- lmer(LogError ~ Stats.OperatingSystemWindows + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Stats.OperatingSystemWindows is not signficant; trying Stats.OperatingSystemMacintosh

graph.numlinks.lmer <- lmer(LogError ~ Stats.OperatingSystemMacintosh + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Stats.OperatingSystemMacintosh is not signficant; trying StatsNumPixels

graph.numlinks.lmer <- lmer(LogError ~ StatsNumPixels + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# StatsNumPixels is not signficant; trying Demo.age

graph.numlinks.lmer <- lmer(LogError ~ Demo.age + (1|Demo.ResponseID), data=graphics_numlinks %>% filter(!(is.na(Demo.age))), REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Demo.age is not signficant; trying Demo.gender

graph.numlinks.lmer <- lmer(LogError ~ Demo.gender + (1|Demo.ResponseID), data=graphics_numlinks %>% filter(!(is.na(Demo.gender))), REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Demo.gender is not signficant; trying Demo.lang

graph.numlinks.lmer <- lmer(LogError ~ Demo.lang + (1|Demo.ResponseID), data=graphics_numlinks %>% filter(!(is.na(Demo.lang))), REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Demo.lang is not signficant; trying Demo.educ

graph.numlinks.lmer <- lmer(LogError ~ Demo.educ + (1|Demo.ResponseID), data=graphics_numlinks %>% filter(!(is.na(Demo.educ))), REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Demo.educ is not signficant; trying Demo.acfield

graph.numlinks.lmer <- lmer(LogError ~ Demo.acfield + (1|Demo.ResponseID), data=graphics_numlinks %>% filter(!(is.na(Demo.acfield))), REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Demo.acfield is not signficant; trying Demo.acfieldGrouped

graph.numlinks.lmer <- lmer(LogError ~ Demo.acfieldGrouped + (1|Demo.ResponseID), data=graphics_numlinks %>% filter(!(is.na(Demo.acfieldGrouped))), REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Demo.acfieldGrouped is not signficant; trying Demo.dailytech_Computer

graph.numlinks.lmer.Comp <- lmer(LogError ~ Demo.dailytech_Computer + (1|Demo.ResponseID), data=graphics_numlinks %>% filter(!(is.na(Demo.dailytech_Computer))), REML = T)

summary(graph.numlinks.lmer.Comp)

anova(graph.numlinks.lmer.Comp)

# Demo.dailytech_Computer is marginally significant (p=0.04462); trying Demo.dailytech_Tablet

graph.numlinks.lmer <- lmer(LogError ~ Demo.dailytech_Tablet + (1|Demo.ResponseID), data=graphics_numlinks %>% filter(!(is.na(Demo.dailytech_Tablet))), REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Demo.dailytech_Computer is not quite significant (p=0.08993); trying Demo.dailytech_SmartPhone

graph.numlinks.lmer <- lmer(LogError ~ Demo.dailytech_SmartPhone + (1|Demo.ResponseID), data=graphics_numlinks %>% filter(!(is.na(Demo.dailytech_SmartPhone))), REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Demo.dailytech_SmartPhone is not significant; trying Demo.weeklygaming

graph.numlinks.lmer <- lmer(LogError ~ Demo.weeklygaming + (1|Demo.ResponseID), data=graphics_numlinks %>% filter(!(is.na(Demo.weeklygaming))), REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Demo.weeklygaming is not significant; trying Demo.expdataanal

graph.numlinks.lmer <- lmer(LogError ~ Demo.expdataanal + (1|Demo.ResponseID), data=graphics_numlinks %>% filter(!(is.na(Demo.expdataanal))), REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Demo.expdataanal is not significant; trying Demo.expdatavis

graph.numlinks.lmer <- lmer(LogError ~ Demo.expdatavis + (1|Demo.ResponseID), data=graphics_numlinks %>% filter(!(is.na(Demo.expdatavis))), REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Demo.expdatavis is not significant; trying Demo.expreadnetvis

graph.numlinks.lmer <- lmer(LogError ~ Demo.expreadnetvis + (1|Demo.ResponseID), data=graphics_numlinks %>% filter(!(is.na(Demo.expreadnetvis))), REML = T)

summary(graph.numlinks.lmer) # one level is significantly different from reference; maybe "A little"?

anova(graph.numlinks.lmer)

# Demo.expreadnetvis is not significant; trying Demo.expreadnetvis.alot

graph.numlinks.lmer <- lmer(LogError ~ Demo.expreadnetvis.alot + (1|Demo.ResponseID), data=graphics_numlinks %>% filter(!(is.na(Demo.expreadnetvis.alot))), REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Demo.expreadnetvis.alot is not significant; trying Demo.expcreatenetvis

graph.numlinks.lmer <- lmer(LogError ~ Demo.expcreatenetvis + (1|Demo.ResponseID), data=graphics_numlinks %>% filter(!(is.na(Demo.expcreatenetvis))), REML = T)

summary(graph.numlinks.lmer) # a lot may be marginally significant

anova(graph.numlinks.lmer)

# Demo.expcreatenetvis is not significant; trying Demo.expcreatenetvis.alot

graph.numlinks.lmer <- lmer(LogError ~ Demo.expcreatenetvis.alot + (1|Demo.ResponseID), data=graphics_numlinks %>% filter(!(is.na(Demo.expcreatenetvis.alot))), REML = T)

summary(graph.numlinks.lmer) # doesn't reach significance

anova(graph.numlinks.lmer)

# Demo.expcreatenetvis is not significant; trying Demo.expcreatenetvis.alot

graph.numlinks.lmer <- lmer(LogError ~ Demo.expcreatenetvis.alot + (1|Demo.ResponseID), data=graphics_numlinks %>% filter(!(is.na(Demo.expcreatenetvis.alot))), REML = T)

summary(graph.numlinks.lmer) # doesn't reach significance

anova(graph.numlinks.lmer)

# Demo.expcreatenetvis.alot is not significant; trying Attempt

graph.numlinks.lmer <- lmer(LogError ~ Attempt + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# Attempt is not significant; trying AvgDeg

graph.numlinks.lmer.avgdeg <- lmer(LogError ~ AvgDeg + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer.avgdeg)

anova(graph.numlinks.lmer.avgdeg)

# AvgDeg is significant (p=1.377e-14); trying Density

graph.numlinks.lmer.dens <- lmer(LogError ~ Density + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer.dens)

anova(graph.numlinks.lmer.dens)

# Density is significant (p=7.55e-15); trying LargeClust1

graph.numlinks.lmer.lgclust <- lmer(LogError ~ LargeClust1 + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer.lgclust)

anova(graph.numlinks.lmer.lgclust)

# LargeClust1 is significant (p=6.75e-14); trying Modularity

graph.numlinks.lmer.mod <- lmer(LogError ~ Modularity + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer.mod)

anova(graph.numlinks.lmer.mod)

# Modularity is significant (p=6.75e-14); trying NumClust

graph.numlinks.lmer.numclust <- lmer(LogError ~ NumClust + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer.numclust)

anova(graph.numlinks.lmer.numclust)

# NumClust is significant (p=8.952e-05); trying NumHighDegree

graph.numlinks.lmer.numhighdeg <- lmer(LogError ~ NumHighDegree + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer.numhighdeg)

anova(graph.numlinks.lmer.numhighdeg)

# NumHighDegree is significant (p=8.749e-14); trying NumLinks

graph.numlinks.lmer <- lmer(LogError ~ NumLinks + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer)

anova(graph.numlinks.lmer)

# NumLinks is not significant; trying NumNodes

graph.numlinks.lmer.numnodes <- lmer(LogError ~ NumNodes + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer.numnodes)

anova(graph.numlinks.lmer.numnodes)

# NumNodes is significant (p=2.973-e05); trying NumNodesClust1

graph.numlinks.lmer.sizeclust1 <- lmer(LogError ~ NumNodesClust1 + (1|Demo.ResponseID), data=graphics_numlinks, REML = T)

summary(graph.numlinks.lmer.sizeclust1)

anova(graph.numlinks.lmer.sizeclust1)

# NumNodesClust1 is significant (p=0.0001754); 


```

```{r, cache=TRUE}

rand(graph.avgdeg.lmer.SP)

# result shows that random effects of participant are significant (p=0.002)

anova(graph.avgdeg.lmer.SP)

# SmartPhone significant, < 0.01

#ranef(graph.avgdeg.lmer.SP)

# displays the random effects; not that useful

# unlike lme(), lmer() doesn't allow for heterogeneous error variance structures (the "weights")


```

```{r}

plot(graph.avgdeg.lmer.SP)

plot(graph.avgdeg.lmer.SP, resid(., scaled=TRUE) ~ fitted(.), abline = 0)

plot(graph.avgdeg.lmer.SP, resid(.) ~ fitted(.) | Task, abline = 0)

plot(graph.avgdeg.lmer.SP, resid(., scaled=TRUE) ~ fitted(.) | Task, abline = 0)

plot(graph.avgdeg.lmer.SP, LogError ~ fitted(.), abline = c(0,1))



```

```{r}

graph.avgdeg.lmer.SP.f <- fortify(graph.avgdeg.lmer.SP)

ggplot(graph.avgdeg.lmer.SP.f, aes(.fitted,.resid)) + 
  geom_point() +
  #facet_grid(.~Sex) + 
  geom_hline(yintercept=0)

ggplot(graph.avgdeg.lmer.SP.f, aes(.fitted,LogError)) + 
  geom_point() +
  geom_abline(aes(slope = 1, intercept = 0))


```

```{r}

# TO DO: check out interpretation for these plots??

library(lattice)

prof <-  profile(graph.avgdeg.lmer.SP, optimizer="Nelder_Mead", which="beta_")

prof.CI <- confint(prof)

#CI2 <- confint(graph.avgdeg.lmer.SP, maxpts = 8)

xyplot(prof)

xyplot(prof, absVal = TRUE)

xyplot(prof, conf = c(0.95, 0.99), main = "95% and 99% profile() intervals")

# can also apply logProf() and varianceProf() to profile object

densityplot(prof)

splom(prof)

```

```{r, eval=FALSE}

# doesn't make sense for continuous predictor???

lsm.task <- lsmeansLT(model.fit.lmer, test.effs = "Task")

plot(lsm.task)

lsm.task.df <- as_data_frame(lsm.task$lsmeans.table)

lsm.task.df

lsm.task.df$Task <- factor(lsm.task.df$Task, levels=lsm.task.df %>% arrange(desc(Estimate)) %>% select(Task) %>% unlist())

lsm.task.df %>% arrange(desc(Estimate))


ggplot(lsm.task.df) +
  geom_point(aes(x=Task,y=Estimate, color=`p-value`<.01)) +
  geom_errorbar(aes(x=Task,ymax=`Upper CI`,ymin=`Lower CI`), width=.2) +
  coord_flip()

# TO DO: add a color scale so TRUE/FALSE values are always same color across all plots


```



```{r, eval=FALSE}

# doesn't make sense for continuous predictor???

difflsm.task <- difflsmeans(model.fit.lmer, test.effs = "Task")

plot(difflsm.task)

difflsm.task.df <- as_data_frame(difflsm.task$diffs.lsmeans.table)

difflsm.task.df

difflsm.task.df <- difflsm.task.df %>% mutate(Pair=rownames(.)) %>% separate(Pair, c("del","Pair"), sep=5) %>% select(-del) %>% separate(Pair, c("From", "del", "To"), sep="[ ]", remove=FALSE) %>% select(-del)

difflsm.task.df$Pair <- factor(difflsm.task.df$Pair, levels=difflsm.task.df %>% arrange(desc(Estimate)) %>% select(Pair) %>% unlist())

difflsm.task.df %>% arrange(desc(Estimate))

ggplot(difflsm.task.df) +
  geom_point(aes(x=Pair,y=Estimate, color=`p-value`<.01)) +
  geom_errorbar(aes(x=Pair,ymax=`Upper CI`,ymin=`Lower CI`), width=.5) +
  geom_hline(aes(yintercept=0)) +
  coord_flip()

ggplot(difflsm.task.df) +
  geom_tile(aes(x=To,y=From,fill=Estimate)) +
    scale_fill_distiller(type="div", palette=4)

ggplot(difflsm.task.df) +
  geom_count(aes(x=To,y=From,size=abs(Estimate),fill=Estimate, color=`p-value`<.01), shape=21) +
  scale_fill_distiller(type="div", palette=4) +
  scale_color_manual(values=c("grey90","black"))
  



```


### Number of Nodes

#### lme4

```{r, cache=TRUE}

# Condition

graph.numnodes.lmer <- lmer(LogError ~ Condition + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Condition not significant; trying Ctrl_dummy

graph.numnodes.lmer <- lmer(LogError ~ Ctrl_dummy + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Ctrl_dummy not significant; trying Dataset

graph.numnodes.lmer.dataset <- lmer(LogError ~ Dataset + (1|Demo.ResponseID), data = graphics_numnodes, REML = T)

lmsum <- summary(graph.numnodes.lmer.dataset)
lmsum
#names(lmsum)

anova(graph.numnodes.lmer.dataset)

# Dataset is significant (p < 2.2e-16); trying QuestionOrder

graph.numnodes.lmer <- lmer(LogError ~ QuestionOrder + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# QuestionOrder is not significant; trying DatasetOrder

graph.numnodes.lmer <- lmer(LogError ~ DatasetOrder + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# DatasetOrder is not significant; trying DatasetDuration

graph.numnodes.lmer <- lmer(LogError ~ DatasetDuration + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# DatasetDuration is not significant; trying DatasetStartTime

graph.numnodes.lmer <- lmer(LogError ~ DatasetStartTime + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# DatasetStartTime is not significant; trying TaskOrder

graph.numnodes.lmer <- lmer(LogError ~ TaskOrder + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# TaskOrder is not significant; trying CorrectAnswer

graph.numnodes.lmer.correct <- lmer(LogError ~ CorrectAnswer + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer.correct)

anova(graph.numnodes.lmer.correct)

# CorrectAnswer is highly significant (p = 0.0001083); trying Underestimated

graph.numnodes.lmer.underest <- lmer(LogError ~ Underestimated + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer.underest)

anova(graph.numnodes.lmer.underest)

# Underestimated is highly significant (p < 2.2e-16); trying Stats.Q_TotalDuration

graph.numnodes.lmer <- lmer(LogError ~ Stats.Q_TotalDuration + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Stats.Q_TotalDuration is barely not signficnat (p=0.05637); trying Stats.dataset_count

graph.numnodes.lmer <- lmer(LogError ~ Stats.dataset_count + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Stats.dataset_count is not signficant; trying Stats.OperatingSystem

graph.numnodes.lmer <- lmer(LogError ~ Stats.OperatingSystem + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Stats.OperatingSystem is not signficant; trying Stats.OperatingSystemCombined

graph.numnodes.lmer <- lmer(LogError ~ Stats.OperatingSystemCombined + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Stats.OperatingSystemCombined is not signficant (though Mac and Windows are almost); trying Stats.OperatingSystemCombined2

graph.numnodes.lmer <- lmer(LogError ~ Stats.OperatingSystemCombined2 + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Stats.OperatingSystemCombined2 is not signficant; trying Stats.OperatingSystemCombined3

graph.numnodes.lmer <- lmer(LogError ~ Stats.OperatingSystemCombined3 + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Stats.OperatingSystemCombined3 is not signficant; trying Stats.OperatingSystemCombined4

graph.numnodes.lmer <- lmer(LogError ~ Stats.OperatingSystemCombined4 + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Stats.OperatingSystemCombined4 is not signficant; trying Stats.OperatingSystemCombined5

graph.numnodes.lmer <- lmer(LogError ~ Stats.OperatingSystemCombined5 + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Stats.OperatingSystemCombined5 is not signficant; trying Stats.OperatingSystemWindows

graph.numnodes.lmer <- lmer(LogError ~ Stats.OperatingSystemWindows + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Stats.OperatingSystemWindows is not signficant; trying Stats.OperatingSystemMacintosh

graph.numnodes.lmer <- lmer(LogError ~ Stats.OperatingSystemMacintosh + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Stats.OperatingSystemMacintosh is not signficant; trying StatsNumPixels

graph.numnodes.lmer <- lmer(LogError ~ StatsNumPixels + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# StatsNumPixels is not signficant; trying Demo.age

graph.numnodes.lmer <- lmer(LogError ~ Demo.age + (1|Demo.ResponseID), data=graphics_numnodes %>% filter(!(is.na(Demo.age))), REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Demo.age is not signficant; trying Demo.gender

graph.numnodes.lmer <- lmer(LogError ~ Demo.gender + (1|Demo.ResponseID), data=graphics_numnodes %>% filter(!(is.na(Demo.gender))), REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Demo.gender is not signficant; trying Demo.lang

graph.numnodes.lmer <- lmer(LogError ~ Demo.lang + (1|Demo.ResponseID), data=graphics_numnodes %>% filter(!(is.na(Demo.lang))), REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Demo.lang is not signficant; trying Demo.educ

graph.numnodes.lmer <- lmer(LogError ~ Demo.educ + (1|Demo.ResponseID), data=graphics_numnodes %>% filter(!(is.na(Demo.educ))), REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Demo.educ is not signficant; trying Demo.acfield

graph.numnodes.lmer <- lmer(LogError ~ Demo.acfield + (1|Demo.ResponseID), data=graphics_numnodes %>% filter(!(is.na(Demo.acfield))), REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Demo.acfield is not signficant; trying Demo.acfieldGrouped

graph.numnodes.lmer <- lmer(LogError ~ Demo.acfieldGrouped + (1|Demo.ResponseID), data=graphics_numnodes %>% filter(!(is.na(Demo.acfieldGrouped))), REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Demo.acfieldGrouped is not signficant; trying Demo.dailytech_Computer

graph.numnodes.lmer.Comp <- lmer(LogError ~ Demo.dailytech_Computer + (1|Demo.ResponseID), data=graphics_numnodes %>% filter(!(is.na(Demo.dailytech_Computer))), REML = T)

summary(graph.numnodes.lmer.Comp)

anova(graph.numnodes.lmer.Comp)

# Demo.dailytech_Computer is marginally significant (p=0.04462); trying Demo.dailytech_Tablet

graph.numnodes.lmer <- lmer(LogError ~ Demo.dailytech_Tablet + (1|Demo.ResponseID), data=graphics_numnodes %>% filter(!(is.na(Demo.dailytech_Tablet))), REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Demo.dailytech_Computer is not quite significant (p=0.08993); trying Demo.dailytech_SmartPhone

graph.numnodes.lmer <- lmer(LogError ~ Demo.dailytech_SmartPhone + (1|Demo.ResponseID), data=graphics_numnodes %>% filter(!(is.na(Demo.dailytech_SmartPhone))), REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Demo.dailytech_SmartPhone is not significant; trying Demo.weeklygaming

graph.numnodes.lmer <- lmer(LogError ~ Demo.weeklygaming + (1|Demo.ResponseID), data=graphics_numnodes %>% filter(!(is.na(Demo.weeklygaming))), REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Demo.weeklygaming is not significant; trying Demo.expdataanal

graph.numnodes.lmer <- lmer(LogError ~ Demo.expdataanal + (1|Demo.ResponseID), data=graphics_numnodes %>% filter(!(is.na(Demo.expdataanal))), REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Demo.expdataanal is not significant; trying Demo.expdatavis

graph.numnodes.lmer <- lmer(LogError ~ Demo.expdatavis + (1|Demo.ResponseID), data=graphics_numnodes %>% filter(!(is.na(Demo.expdatavis))), REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Demo.expdatavis is not significant; trying Demo.expreadnetvis

graph.numnodes.lmer <- lmer(LogError ~ Demo.expreadnetvis + (1|Demo.ResponseID), data=graphics_numnodes %>% filter(!(is.na(Demo.expreadnetvis))), REML = T)

summary(graph.numnodes.lmer) # one level is significantly different from reference; maybe "A little"?

anova(graph.numnodes.lmer)

# Demo.expreadnetvis is not significant; trying Demo.expreadnetvis.alot

graph.numnodes.lmer <- lmer(LogError ~ Demo.expreadnetvis.alot + (1|Demo.ResponseID), data=graphics_numnodes %>% filter(!(is.na(Demo.expreadnetvis.alot))), REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Demo.expreadnetvis.alot is not significant; trying Demo.expcreatenetvis

graph.numnodes.lmer <- lmer(LogError ~ Demo.expcreatenetvis + (1|Demo.ResponseID), data=graphics_numnodes %>% filter(!(is.na(Demo.expcreatenetvis))), REML = T)

summary(graph.numnodes.lmer) # a lot may be marginally significant

anova(graph.numnodes.lmer)

# Demo.expcreatenetvis is not significant; trying Demo.expcreatenetvis.alot

graph.numnodes.lmer <- lmer(LogError ~ Demo.expcreatenetvis.alot + (1|Demo.ResponseID), data=graphics_numnodes %>% filter(!(is.na(Demo.expcreatenetvis.alot))), REML = T)

summary(graph.numnodes.lmer) # doesn't reach significance

anova(graph.numnodes.lmer)

# Demo.expcreatenetvis is not significant; trying Demo.expcreatenetvis.alot

graph.numnodes.lmer <- lmer(LogError ~ Demo.expcreatenetvis.alot + (1|Demo.ResponseID), data=graphics_numnodes %>% filter(!(is.na(Demo.expcreatenetvis.alot))), REML = T)

summary(graph.numnodes.lmer) # doesn't reach significance

anova(graph.numnodes.lmer)

# Demo.expcreatenetvis.alot is not significant; trying Attempt

graph.numnodes.lmer <- lmer(LogError ~ Attempt + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# Attempt is not significant; trying AvgDeg

graph.numnodes.lmer.avgdeg <- lmer(LogError ~ AvgDeg + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer.avgdeg)

anova(graph.numnodes.lmer.avgdeg)

# AvgDeg is significant (p=1.377e-14); trying Density

graph.numnodes.lmer.dens <- lmer(LogError ~ Density + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer.dens)

anova(graph.numnodes.lmer.dens)

# Density is significant (p=7.55e-15); trying LargeClust1

graph.numnodes.lmer.lgclust <- lmer(LogError ~ LargeClust1 + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer.lgclust)

anova(graph.numnodes.lmer.lgclust)

# LargeClust1 is significant (p=6.75e-14); trying Modularity

graph.numnodes.lmer.mod <- lmer(LogError ~ Modularity + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer.mod)

anova(graph.numnodes.lmer.mod)

# Modularity is significant (p=6.75e-14); trying NumClust

graph.numnodes.lmer.numclust <- lmer(LogError ~ NumClust + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer.numclust)

anova(graph.numnodes.lmer.numclust)

# NumClust is significant (p=8.952e-05); trying NumHighDegree

graph.numnodes.lmer.numhighdeg <- lmer(LogError ~ NumHighDegree + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer.numhighdeg)

anova(graph.numnodes.lmer.numhighdeg)

# NumHighDegree is significant (p=8.749e-14); trying NumLinks

graph.numnodes.lmer <- lmer(LogError ~ NumLinks + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer)

anova(graph.numnodes.lmer)

# NumLinks is not significant; trying NumNodes

graph.numnodes.lmer.numnodes <- lmer(LogError ~ NumNodes + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer.numnodes)

anova(graph.numnodes.lmer.numnodes)

# NumNodes is significant (p=2.973-e05); trying NumNodesClust1

graph.numnodes.lmer.sizeclust1 <- lmer(LogError ~ NumNodesClust1 + (1|Demo.ResponseID), data=graphics_numnodes, REML = T)

summary(graph.numnodes.lmer.sizeclust1)

anova(graph.numnodes.lmer.sizeclust1)

# NumNodesClust1 is significant (p=0.0001754); 


```

```{r, cache=TRUE}

rand(graph.avgdeg.lmer.SP)

# result shows that random effects of participant are significant (p=0.002)

anova(graph.avgdeg.lmer.SP)

# SmartPhone significant, < 0.01

#ranef(graph.avgdeg.lmer.SP)

# displays the random effects; not that useful

# unlike lme(), lmer() doesn't allow for heterogeneous error variance structures (the "weights")


```

```{r}

plot(graph.avgdeg.lmer.SP)

plot(graph.avgdeg.lmer.SP, resid(., scaled=TRUE) ~ fitted(.), abline = 0)

plot(graph.avgdeg.lmer.SP, resid(.) ~ fitted(.) | Task, abline = 0)

plot(graph.avgdeg.lmer.SP, resid(., scaled=TRUE) ~ fitted(.) | Task, abline = 0)

plot(graph.avgdeg.lmer.SP, LogError ~ fitted(.), abline = c(0,1))



```

```{r}

graph.avgdeg.lmer.SP.f <- fortify(graph.avgdeg.lmer.SP)

ggplot(graph.avgdeg.lmer.SP.f, aes(.fitted,.resid)) + 
  geom_point() +
  #facet_grid(.~Sex) + 
  geom_hline(yintercept=0)

ggplot(graph.avgdeg.lmer.SP.f, aes(.fitted,LogError)) + 
  geom_point() +
  geom_abline(aes(slope = 1, intercept = 0))


```

```{r}

# TO DO: check out interpretation for these plots??

library(lattice)

prof <-  profile(graph.avgdeg.lmer.SP, optimizer="Nelder_Mead", which="beta_")

prof.CI <- confint(prof)

#CI2 <- confint(graph.avgdeg.lmer.SP, maxpts = 8)

xyplot(prof)

xyplot(prof, absVal = TRUE)

xyplot(prof, conf = c(0.95, 0.99), main = "95% and 99% profile() intervals")

# can also apply logProf() and varianceProf() to profile object

densityplot(prof)

splom(prof)

```

```{r, eval=FALSE}

# doesn't make sense for continuous predictor???

lsm.task <- lsmeansLT(model.fit.lmer, test.effs = "Task")

plot(lsm.task)

lsm.task.df <- as_data_frame(lsm.task$lsmeans.table)

lsm.task.df

lsm.task.df$Task <- factor(lsm.task.df$Task, levels=lsm.task.df %>% arrange(desc(Estimate)) %>% select(Task) %>% unlist())

lsm.task.df %>% arrange(desc(Estimate))


ggplot(lsm.task.df) +
  geom_point(aes(x=Task,y=Estimate, color=`p-value`<.01)) +
  geom_errorbar(aes(x=Task,ymax=`Upper CI`,ymin=`Lower CI`), width=.2) +
  coord_flip()

# TO DO: add a color scale so TRUE/FALSE values are always same color across all plots


```



```{r, eval=FALSE}

# doesn't make sense for continuous predictor???

difflsm.task <- difflsmeans(model.fit.lmer, test.effs = "Task")

plot(difflsm.task)

difflsm.task.df <- as_data_frame(difflsm.task$diffs.lsmeans.table)

difflsm.task.df

difflsm.task.df <- difflsm.task.df %>% mutate(Pair=rownames(.)) %>% separate(Pair, c("del","Pair"), sep=5) %>% select(-del) %>% separate(Pair, c("From", "del", "To"), sep="[ ]", remove=FALSE) %>% select(-del)

difflsm.task.df$Pair <- factor(difflsm.task.df$Pair, levels=difflsm.task.df %>% arrange(desc(Estimate)) %>% select(Pair) %>% unlist())

difflsm.task.df %>% arrange(desc(Estimate))

ggplot(difflsm.task.df) +
  geom_point(aes(x=Pair,y=Estimate, color=`p-value`<.01)) +
  geom_errorbar(aes(x=Pair,ymax=`Upper CI`,ymin=`Lower CI`), width=.5) +
  geom_hline(aes(yintercept=0)) +
  coord_flip()

ggplot(difflsm.task.df) +
  geom_tile(aes(x=To,y=From,fill=Estimate)) +
    scale_fill_distiller(type="div", palette=4)

ggplot(difflsm.task.df) +
  geom_count(aes(x=To,y=From,size=abs(Estimate),fill=Estimate, color=`p-value`<.01), shape=21) +
  scale_fill_distiller(type="div", palette=4) +
  scale_color_manual(values=c("grey90","black"))
  



```



